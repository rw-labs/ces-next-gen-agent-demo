=== ./server/core/session_state.py ===
from typing import Any, Dict, Optional

from config.config import USE_TTS
from google.adk.agents import Agent, LiveRequestQueue
from google.adk.artifacts.in_memory_artifact_service import InMemoryArtifactService
from google.adk.events import Event
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService

from .logger import logger


class SessionState:
    """
    Represents the state of a user/agent session, encapsulating the agent, services, and context.

    This class manages the lifecycle of a user/agent session, including agent setup,
    service initialization, context management, and tracking of session events.
    It provides methods to access and initialize session services and artifact services,
    and to manage the runner and live request queue.

    Attributes:
        agent (Agent): The agent associated with the session.
        app_name (str): The name of the application associated with the session.
        user_id (str): The unique user identifier for the session.
        session_service_type (str): The type of session service to use (e.g., "in_memory").
        artifact_service_type (str): The type of artifact service to use (e.g., "in_memory").
        session_service (Optional[Any]): The initialized session service object.
        artifact_service (Optional[Any]): The initialized artifact service object.
        session (Optional[Any]): The session object created by the session service.
        context (Optional[Dict[str, Any]]): The session context data.
        num_agents (int): The number of agents involved in the session.
        num_agents_set (bool): Flag indicating if the number of agents has been determined.
        runner (Runner): The runner object for executing the agent.
        live_request_queue (LiveRequestQueue): The queue for handling live requests.
        events (Optional[Any]): The event generator for the session.
        is_receiving_response (bool): Flag indicating if the session is currently receiving a response.
        interrupted (bool): Flag indicating if the session has been interrupted.
        current_audio_stream (Optional[Any]): The current audio stream object (if any).
        received_model_response (bool): Flag indicating if a model response has been received in the current turn.
    """

    def __init__(
        self,
        agent: Agent,
        app_name: str = "agent app",
        user_id: str = "userX",
        session_service: str = "in_memory",
        artifact_service: str = "in_memory",
        context: Dict[str, Any] = None,
    ):
        self.agent = agent
        self.app_name = app_name
        self.user_id = user_id
        self.session_service_type = session_service
        self.artifact_service_type = artifact_service
        self.session_service = None
        self.artifact_service = None
        self.session = None
        self.context = context
        self.num_agents = 1
        self.num_agents_set = False
        self.runner = None  # Will be set in async setup
        self.live_request_queue = LiveRequestQueue()
        self.events = None

        self.is_receiving_response: bool = False
        self.interrupted: bool = False
        # self.current_tool_execution: Optional[asyncio.Task] = None
        self.current_audio_stream: Optional[Any] = None
        # genai_session: Optional[Any] = None
        self.received_model_response: bool = (
            False  # Track if we've received a model response in current turn
        )

    @classmethod
    async def create(
        cls,
        agent: Agent,
        app_name: str = "agent app",
        user_id: str = "userX",
        session_service: str = "in_memory",
        artifact_service: str = "in_memory",
        context: Dict[str, Any] = None,
    ):
        self = cls(agent, app_name, user_id, session_service, artifact_service, context)
        self.runner = await self.setup()
        return self

    def _get_session_service(self):
        """
        Retrieves or initializes the session service.

        Returns:
            Any: The initialized session service object.

        Raises:
            ValueError: If an unknown session service type is specified.
        """
        if self.session_service is None:
            if self.session_service_type == "in_memory":
                self.session_service = InMemorySessionService()
            else:
                raise ValueError(
                    f"Unknown session_service: {self.session_service_type}"
                )
        return self.session_service

    def _get_artifact_service(self):
        """
        Retrieves or initializes the artifact service.

        Returns:
            Any: The initialized artifact service object.

        Raises:
            ValueError: If an unknown artifact service type is specified.
        """
        if self.artifact_service is None:
            if self.artifact_service_type == "in_memory":
                self.artifact_service = InMemoryArtifactService()
            else:
                raise ValueError(
                    f"Unknown artifact_service: {self.artifact_service_type}"
                )
        return self.artifact_service

    def _set_num_agents_for_session(self, agent: Agent):
        """
        Determines the number of agents involved in the session.

        Args:
            agent (Agent): The root agent for the session.
        """
        if not self.num_agents_set:
            self.num_agents = 1 + len(agent.sub_agents)

    def log_event_output(self, event: Event):
        try:
            res = event.content.model_dump(exclude_none=True).get("parts", None)
        except Exception as e:
            logger.debug(f"e:{e}\nevent:{event}")
            return None

        if not res:
            return None

        for part in res:
            if part.get("text", None):
                if event.content.role == "model" and not event.partial:
                    logger.info(f"{event.author}: {part['text']}")
                elif event.content.role == "user":
                    logger.info(f"USER QUERY: {part['text']}")

            if part.get("function_call", None):
                logger.info(f"TOOL CALL: {part['function_call']}")

            if part.get("function_response", None):
                logger.info(f"TOOL RESULT: {part['function_response']}")

        return res

    async def setup(self):
        """
        Sets up the session, runner, and services.

        This method initializes the session service, artifact service, and runner,
        and creates a new session if one does not already exist.

        Returns:
            Runner: The initialized runner object.
        """
        self._set_num_agents_for_session(self.agent)
        session_service = self._get_session_service()
        artifact_service = self._get_artifact_service()

        if not self.session:
            if self.context:
                logger.info("Creating new session with session context")
                self.session = await session_service.create_session(
                    app_name=self.app_name, user_id=self.user_id, state=self.context
                )
            else:
                logger.info("Creating new session with no context")
                self.session = await session_service.create_session(
                    app_name=self.app_name,
                    user_id=self.user_id,
                )

        if USE_TTS:
            return Runner(
                app_name=self.app_name,
                agent=self.agent,
                artifact_service=self.artifact_service,
                session_service=self.session_service,
            )
        else:
            return Runner(
                app_name=self.app_name,
                agent=self.agent,
                artifact_service=self.artifact_service,
                session_service=self.session_service,
            )
=== ./server/core/agent_factory.py ===
from config.config import DEMO_TYPE

from core.agents.teg.context import TegContext

from core.agents.teg.teg_assist import create_teg_agent


from .logger import logger


def get_agent_config(session_id: str):
    agent_config = {"app_name": None, "root_agent": None, "context": None}

    # --- Add Teg Option ---
    if DEMO_TYPE == "teg":
        agent_config["app_name"] = "teg_ai_assistant"
        agent_config["context"] = TegContext.CUSTOMER_PROFILE
        agent_config["context"]["session_id"] = session_id # Add session_id to context
        agent_config["root_agent"] = create_teg_agent()
    # --- End Teg Option ---

    else:
        raise ValueError(f"Unknown DEMO_TYPE: `{DEMO_TYPE}`")

    logger.info(f"Loading `{DEMO_TYPE}` Agent: {agent_config['app_name']}")

    return agent_config
=== ./server/core/websocket_handler.py ===
# ./server/core/websocket_handler.py
"""
WebSocket message handling using aiohttp.web.WebSocketResponse.
Handles communication between the client/frontend and the live Agent.
"""

import asyncio
import base64
import json
from typing import Any, Dict, Optional

from aiohttp import WSCloseCode, WSMsgType, web
from config.config import (
    MODEL,
    MODEL_LANGUAGE,
    PROMPT_LANGUAGE,
    RUN_CONFIG,
    TTS_CLIENT,
    TTS_CONFIG,
    USE_TTS,
    VOICE,
)
from core.agent_factory import get_agent_config
from google.adk.agents import Agent
from google.cloud import texttospeech_v1beta1 as texttospeech
from google.genai import types as google_types
from websockets.exceptions import (
    ConnectionClosedError as WebsocketsConnectionClosedError,
)

from .logger import logger
from .session_state import SessionState

# --- Server-Side Buffer Configuration ---
TARGET_SAMPLE_RATE = 24000  # Matches client and API
BYTES_PER_SAMPLE = 2  # For 16-bit PCM
SERVER_BUFFER_DURATION_S = 0.3  # Target duration to send (e.g., 200ms)
SERVER_BUFFER_TIMEOUT_S = (
    0.25  # Max time to wait before sending incomplete buffer (must be < duration)
)
SERVER_BUFFER_MAX_SIZE_BYTES = int(
    TARGET_SAMPLE_RATE * SERVER_BUFFER_DURATION_S * BYTES_PER_SAMPLE
)
# --- End Configuration ---


# Global session storage
ACTIVE_SESSIONS: Dict[str, SessionState] = {}


# --- Session Management (Unchanged) ---
async def create_session(
    session_id: str, agent: Agent, app_name: str, context: Dict[str, Any]
) -> SessionState:
    """Creates and stores a new session."""
    logger.info(f"Creating session {session_id} for app {app_name}")
    session = await SessionState.create(
        agent=agent, app_name=app_name, user_id=session_id, context=context
    )

    # Start the agent's live runner
    session.events = session.runner.run_live(
        session=session.session,
        live_request_queue=session.live_request_queue,
        run_config=RUN_CONFIG,
    )
    logger.info(f"Agent live runner started for session {session_id}")

    ACTIVE_SESSIONS[session_id] = session
    return session


def get_session(session_id: str) -> Optional[SessionState]:
    """Retrieves an existing session."""
    return ACTIVE_SESSIONS.get(session_id)


def remove_session(session_id: str) -> None:
    """Removes a session."""
    if session_id in ACTIVE_SESSIONS:
        logger.info(f"Removing session {session_id}")
        del ACTIVE_SESSIONS[session_id]
    else:
        logger.warning(f"Attempted to remove non-existent session {session_id}")


# --- WebSocket Communication Helpers (Adapted for aiohttp) ---


async def send_json_message(
    websocket: web.WebSocketResponse, message_type: str, data: Any
) -> None:
    """Sends a JSON message over the WebSocket."""
    if websocket.closed:
        logger.warning(f"Attempted to send {message_type} message on closed websocket.")
        return
    try:
        payload = {"type": message_type, "data": data}
        # logger.debug(f"Sending WebSocket JSON: {payload}") # Can be very verbose
        await websocket.send_json(payload)
    except ConnectionResetError:
        logger.warning(f"Connection reset while sending {message_type} message.")
    except Exception as e:
        logger.exception(f"Failed to send WebSocket JSON message ({message_type}): {e}")


async def send_error_message(
    websocket: web.WebSocketResponse, error_data: dict
) -> None:
    """Sends a formatted error message to the client."""
    await send_json_message(websocket, "error", error_data)


async def send_buffered_audio(
    websocket: Any,
    audio_buffer: bytearray,
    last_send_time: float,
    force_send: bool = False,
) -> float:
    """
    Sends the content of the audio buffer if conditions are met.
    Args:
        websocket: The websocket connection.
        audio_buffer: The bytearray buffer holding audio data.
        last_send_time: The timestamp of the last buffer send.
        force_send: If True, sends the buffer regardless of size/timeout (for cleanup).
    Returns:
        The timestamp when the buffer was sent (or the original last_send_time if not sent).
    """
    now = asyncio.get_event_loop().time()
    should_send = False
    reason = ""

    if len(audio_buffer) == 0:
        return last_send_time  # Nothing to send

    # Check conditions for sending
    if len(audio_buffer) >= SERVER_BUFFER_MAX_SIZE_BYTES:
        should_send = True
        reason = (
            f"size threshold ({len(audio_buffer)} >= {SERVER_BUFFER_MAX_SIZE_BYTES})"
        )
    elif (now - last_send_time) >= SERVER_BUFFER_TIMEOUT_S:
        should_send = True
        reason = f"timeout ({(now - last_send_time) * 1000:.1f}ms >= {SERVER_BUFFER_TIMEOUT_S * 1000:.1f}ms)"
    elif force_send:
        should_send = True
        reason = "force send"

    if should_send:
        logger.debug(
            f"Server buffer sending: Reason={reason}, Size={len(audio_buffer)} bytes"
        )
        try:
            # Send a copy and clear original buffer immediately
            data_to_send = bytes(audio_buffer)
            audio_buffer.clear()
            # Update time *before* await, assuming send attempt will proceed
            last_send_time = now

            # --- decode and send the audio
            audio_base64 = base64.b64encode(data_to_send).decode("utf-8")
            await send_json_message(websocket, "audio", audio_base64)

            logger.debug("Server buffer sent successfully.")

        except Exception as send_err:
            logger.error(
                f"Error sending buffered audio: {send_err} (Client likely disconnected)"
            )
            # Buffer was already cleared, just log the error
            # Reset last_send_time to avoid potential rapid retries if connection persists but fails
            last_send_time = now
        return now  # Return the time send was initiated

    return last_send_time  # Return original time if not sent


# --- Session Cleanup (Adapted for clarity) ---


async def cleanup_session(session: Optional[SessionState], session_id: str) -> None:
    """Cleans up session resources."""
    logger.info(f"Starting cleanup for session {session_id}")
    if session:
        if session.session:
            try:
                logger.info(
                    f"Attempting to clean up agent resources for session {session_id} (Placeholder)"
                )
                pass  # Replace with actual cleanup logic
            except Exception as e:
                logger.error(
                    f"Error during agent resource cleanup for session {session_id}: {e}"
                )
        else:
            logger.warning(
                f"No active agent session object found for cleanup in session {session_id}"
            )

    # Remove session from active sessions *after* attempting cleanup
    remove_session(session_id)
    logger.info(f"Session {session_id} removed from active sessions.")


# --- Agent Response Handling (Adapted for aiohttp) ---


async def handle_agent_responses(
    websocket: web.WebSocketResponse, session: SessionState
) -> None:
    """Handles responses from the agent, forwarding data to the client."""
    session_id = session.user_id  # Get session_id for logging
    logger.info(f"[Session: {session_id}] Starting agent response handler task.")
    agent_turn_completed_normally = False

    # Buffer setup
    audio_buffer = bytearray()  # Buffer specific to this handler invocation
    last_send_time = asyncio.get_event_loop().time()
    buffer_task = None
    # End buffer setup

    # --- Define Buffer check loop ---
    async def buffer_check_loop():
        """Periodically checks if the buffer timeout requires sending."""
        nonlocal last_send_time  # Allow modification of the outer scope variable
        while True:
            # Calculate sleep duration dynamically based on last send time
            now = asyncio.get_event_loop().time()
            time_since_last_send = now - last_send_time
            sleep_duration = max(
                0.01, SERVER_BUFFER_TIMEOUT_S - time_since_last_send
            )  # Sleep at least 10ms
            await asyncio.sleep(sleep_duration)
            try:
                # Pass the current buffer and last send time
                current_last_send = await send_buffered_audio(
                    websocket, audio_buffer, last_send_time
                )
                last_send_time = current_last_send  # Update last_send_time
            except Exception as check_err:
                logger.error(f"Error in buffer_check_loop: {check_err}")
                break  # Stop the loop on error

    # --- End buffer check loop ---

    try:
        # Start the background task to handle buffer timeouts
        buffer_task = asyncio.create_task(buffer_check_loop())
        logger.debug(
            f"Session {session.user_id}: Started server-side audio buffer check loop."
        )

        full_text = ""
        async for event in session.events:
            if websocket.closed:
                logger.warning(
                    f"[Session: {session_id}] WebSocket closed during agent response handling. Exiting task."
                )
                break

            # --- Interruption ---
            if event.interrupted:
                logger.info(f"[Session: {session_id}] Agent response interrupted.")
                await send_json_message(
                    websocket,
                    "interrupted",
                    {"message": "Response interrupted by user input"},
                )

                # --- clear buffer on interruption
                if len(audio_buffer) > 0:
                    logger.debug("Clearing server audio buffer due to interruption.")
                    audio_buffer.clear()
                # --- End buffer clearing ---

                continue  # Skip processing the rest of this interrupted event

            # --- Tool Call and Result handling ---
            if event.content and event.content.parts:
                part = event.content.parts[0]
                if part.function_call:
                    # --- Flush buffer before sending non-audio message ---
                    if len(audio_buffer) > 0:
                        last_send_time = await send_buffered_audio(
                            websocket, audio_buffer, last_send_time, force_send=True
                        )
                    # --- End flush ---
                    tool = part.function_call
                    logger.info(
                        f"[Session: {session_id}] Sending tool_call: {tool.name}"
                    )
                    await send_json_message(
                        websocket, "tool_call", {"name": tool.name, "args": tool.args}
                    )

                elif part.function_response:
                    # --- Flush buffer before sending non-audio message ---
                    if len(audio_buffer) > 0:
                        last_send_time = await send_buffered_audio(
                            websocket, audio_buffer, last_send_time, force_send=True
                        )
                    # --- End flush ---
                    tool_result = part.function_response
                    logger.info(
                        f"[Session: {session_id}] Sending tool_result for: {tool_result.name}"
                    )
                    await send_json_message(
                        websocket, "tool_result", tool_result.response
                    )  # Send the actual response content

                elif part.text:
                    text_chunk = part.text
                    # --- Text and TTS handling ---
                    if not event.partial:  # Process complete text chunks
                        # --- Flush buffer before sending text/starting TTS ---
                        if len(audio_buffer) > 0:
                            last_send_time = await send_buffered_audio(
                                websocket, audio_buffer, last_send_time, force_send=True
                            )
                        # --- End flush ---
                        if USE_TTS and TTS_CLIENT:
                            if text_chunk.strip():
                                logger.info(
                                    f"[Session: {session_id}] Synthesizing TTS for chunk: '{text_chunk[:50]}...'"
                                )
                                if not TTS_CONFIG:
                                    logger.error(
                                        f"[Session: {session_id}] Cannot synthesize TTS, config unavailable."
                                    )
                                    await send_json_message(
                                        websocket, "text", text_chunk
                                    )  # Fallback to text
                                    continue

                                config_request = (
                                    texttospeech.StreamingSynthesizeRequest(
                                        streaming_config=TTS_CONFIG
                                    )
                                )

                                def request_generator():
                                    yield config_request
                                    # Send text in manageable chunks if necessary, though here we send the whole chunk
                                    yield texttospeech.StreamingSynthesizeRequest(
                                        input=texttospeech.StreamingSynthesisInput(
                                            text=text_chunk
                                        )
                                    )

                                try:
                                    streaming_responses = (
                                        TTS_CLIENT.streaming_synthesize(
                                            request_generator()
                                        )
                                    )
                                    for response in streaming_responses:
                                        if response.audio_content:
                                            # --- Append to buffer instead of sending directly ---
                                            audio_chunk_bytes = response.audio_content
                                            logger.debug(
                                                f"Session {session_id}: Received TTS audio chunk: {len(audio_chunk_bytes)} bytes"
                                            )
                                            audio_buffer.extend(audio_chunk_bytes)
                                            # Check immediately if buffer is full enough to send
                                            last_send_time = await send_buffered_audio(
                                                websocket, audio_buffer, last_send_time
                                            )
                                            # --- End buffer modification ---

                                            # audio_base64 = base64.b64encode(response.audio_content).decode('utf-8')
                                            # await send_json_message(websocket, "audio", audio_base64)

                                except Exception as tts_error:
                                    logger.exception(
                                        f"[Session: {session_id}] Error during TTS streaming: {tts_error}"
                                    )
                                    await send_json_message(
                                        websocket, "text", text_chunk
                                    )  # Fallback to text on TTS error
                        else:
                            # Send complete text if not using TTS or TTS failed
                            logger.info(
                                f"[Session: {session_id}] Sending complete text chunk: '{text_chunk[:50]}...'"
                            )
                            await send_json_message(websocket, "text", text_chunk)

                # --- Image handling ---
                elif part.inline_data and part.inline_data.mime_type.startswith(
                    "image"
                ):
                    # --- Flush buffer before sending non-audio message ---
                    if len(audio_buffer) > 0:
                        last_send_time = await send_buffered_audio(
                            websocket, audio_buffer, last_send_time, force_send=True
                        )
                    # --- End flush ---
                    logger.info(
                        f"[Session: {session_id}] Sending image data ({part.inline_data.mime_type})"
                    )
                    image_base64 = base64.b64encode(part.inline_data.data).decode(
                        "utf-8"
                    )
                    await send_json_message(
                        websocket,
                        "image",
                        f"data:{part.inline_data.mime_type};base64,{image_base64}",
                    )

                # --- Audio handling with buffering ---
                # TODO: Replace this once b/403379753 is resolved (if agent sends audio directly)
                elif part.inline_data and part.inline_data.mime_type.startswith(
                    "audio/pcm"
                ):
                    logger.debug(
                        f"[Session: {session_id}] Received direct audio data (PCM): {len(part.inline_data.data)} bytes"
                    )
                    # --- Append direct audio to buffer ---
                    audio_chunk_bytes = part.inline_data.data
                    audio_buffer.extend(audio_chunk_bytes)
                    # Check immediately if buffer is full enough to send
                    last_send_time = await send_buffered_audio(
                        websocket, audio_buffer, last_send_time
                    )
                    # --- End buffer modification ---
                    continue  # Handled direct audio

            # Yield control briefly to allow other tasks to run
            await asyncio.sleep(0)
        else:
            # Loop finished without breaking (i.e., no client disconnect)
            agent_turn_completed_normally = True

    except (WebsocketsConnectionClosedError, ConnectionRefusedError) as conn_err:
        # --- Catch specific backend connection errors ---
        logger.warning(
            f"[Session: {session_id}] Connection error while receiving agent events: {conn_err}"
        )
        logger.warning(
            f"[Session: {session_id}] This likely means the connection to the Gemini API backend was lost (e.g., RPC::DEADLINE_EXCEEDED)."
        )
        # Inform the client about the temporary issue
        await send_error_message(
            websocket,
            {
                "message": "There was a temporary issue communicating with the AI assistant.",
                "action": "Please try sending your message again.",
                "error_type": "backend_connection_error",
            },
        )
        # Do NOT re-raise. Let this task end gracefully.
    except asyncio.CancelledError:
        logger.info(f"[Session: {session_id}] Agent response handler task cancelled.")
    except Exception as e:
        logger.exception(
            f"[Session: {session_id}] Error in handle_agent_responses: {e}"
        )
        # Attempt to send an error message to the client if the websocket is still open
        await send_error_message(
            websocket,
            {
                "message": "An internal error occurred while processing the assistant's response.",
                "action": "Please try sending your message again or reconnect if issues persist.",
                "error_type": "agent_response_processing_error",
            },
        )
        # Do NOT re-raise. Let this task end gracefully.
    finally:
        logger.info(f"[Session: {session_id}] Agent response handler task finished.")
        # --- Cleanup Buffer Task and Flush Buffer ---
        if buffer_task and not buffer_task.done():
            logger.debug(f"Session {session_id}: Cancelling buffer check loop task.")
            buffer_task.cancel()
            try:
                await buffer_task  # Wait for cancellation to complete
            except asyncio.CancelledError:
                logger.debug(
                    f"Session {session_id}: Buffer check loop task successfully cancelled."
                )
            except Exception as task_cancel_err:
                logger.error(
                    f"Session {session_id}: Error awaiting cancelled buffer task: {task_cancel_err}"
                )

        # Force send any remaining audio in the buffer *after* cancelling the loop
        if len(audio_buffer) > 0:
            logger.info(
                f"Session {session_id}: Flushing remaining audio buffer ({len(audio_buffer)} bytes) in finally block."
            )
            # Use the last known send time, or current time if none exists
            final_flush_time = (
                last_send_time if last_send_time else asyncio.get_event_loop().time()
            )
            await send_buffered_audio(
                websocket, audio_buffer, final_flush_time, force_send=True
            )
        # --- End Cleanup ---

        # Only signal turn complete if the agent finished its turn normally,
        # not if it was interrupted by an error or cancellation.
        if agent_turn_completed_normally and not websocket.closed:
            logger.info(f"[Session: {session_id}] Sending turn_complete signal.")
            await send_json_message(websocket, "turn_complete", {})
        else:
            logger.info(
                f"[Session: {session_id}] Not sending turn_complete signal (error, cancellation, or client closed)."
            )


# --- Client Message Handling (Adapted for aiohttp) ---


async def handle_client_messages(
    websocket: web.WebSocketResponse, session: SessionState
) -> None:
    """Handles incoming messages from the client."""
    session_id = session.user_id
    logger.info(f"[Session: {session_id}] Starting client message handler task.")
    try:
        async for msg in websocket:
            if msg.type == WSMsgType.TEXT:
                try:
                    data = json.loads(msg.data)
                    msg_type = data.get("type")
                    msg_data = data.get("data")  # Renamed to avoid conflict

                    if not msg_type:
                        logger.warning(
                            f"[Session: {session_id}] Received message without type: {data}"
                        )
                        continue

                    if msg_type == "audio":
                        if msg_data:
                            # logger.debug(f"[Session: {session_id}] Client -> Agent: Sending audio data...")
                            session.live_request_queue.send_realtime(
                                google_types.Blob(
                                    data=base64.b64decode(msg_data),
                                    mime_type="audio/pcm",
                                )
                            )
                        else:
                            logger.warning(
                                f"[Session: {session_id}] Received audio message with no data."
                            )
                    elif msg_type == "image":
                        if msg_data:
                            logger.debug(
                                f"[Session: {session_id}] Client -> Agent: Sending image data..."
                            )
                            # Assuming base64 encoded image data after comma
                            img_content = base64.b64decode(msg_data)
                            session.live_request_queue.send_realtime(
                                google_types.Blob(
                                    data=img_content, mime_type="image/jpeg"
                                )  # Assuming JPEG, adjust if needed
                            )
                        else:
                            logger.warning(
                                f"[Session: {session_id}] Received image message with no data."
                            )
                    elif msg_type == "text":
                        if msg_data is not None:  # Allow empty strings
                            logger.info(
                                f"[Session: {session_id}] Client -> Agent: Sending text: '{msg_data[:50]}...'"
                            )
                            session.live_request_queue.send_content(
                                google_types.Content(
                                    role="user",
                                    parts=[google_types.Part.from_text(text=msg_data)],
                                )
                            )
                        else:
                            logger.warning(
                                f"[Session: {session_id}] Received text message with no data."
                            )
                    elif msg_type == "end":
                        logger.info(
                            f"[Session: {session_id}] Received end signal from client."
                        )
                        # Optionally trigger agent finalization or specific actions here
                        # session.live_request_queue.send_content(...) # Example: send a final prompt
                    else:
                        logger.warning(
                            f"[Session: {session_id}] Unsupported message type received: {msg_type}"
                        )

                except json.JSONDecodeError:
                    logger.error(
                        f"[Session: {session_id}] Received invalid JSON from client: {msg.data}"
                    )
                except Exception as e:
                    logger.exception(
                        f"[Session: {session_id}] Error processing client message: {e}"
                    )

            elif msg.type == WSMsgType.BINARY:
                logger.warning(
                    f"[Session: {session_id}] Received unexpected binary message from client."
                )
                # Handle binary data if needed, e.g., direct audio stream
                # session.live_request_queue.send_realtime(google_types.Blob(data=msg.data, mime_type='...'))

            elif msg.type == WSMsgType.ERROR:
                logger.error(
                    f"[Session: {session_id}] WebSocket connection closed with exception {websocket.exception()}"
                )
                break  # Exit loop on WebSocket error

            elif msg.type == WSMsgType.CLOSE:
                logger.info(
                    f"[Session: {session_id}] WebSocket close message received from client."
                )
                break  # Exit loop gracefully on client close

    except asyncio.CancelledError:
        logger.info(f"[Session: {session_id}] Client message handler task cancelled.")
    except Exception as e:
        # Log unexpected errors in the message handling loop
        logger.exception(
            f"[Session: {session_id}] Unexpected error in handle_client_messages: {e}"
        )
    finally:
        logger.info(f"[Session: {session_id}] Client message handler task finished.")
        # Ensure the websocket is closed from the server side if the loop exits unexpectedly
        if not websocket.closed:
            await websocket.close(
                code=WSCloseCode.GOING_AWAY, message=b"Server closing connection"
            )


# --- Main Message Handling Orchestration (Adapted for aiohttp) ---


async def handle_messages(
    websocket: web.WebSocketResponse, session: SessionState
) -> None:
    """Handles bidirectional message flow using asyncio TaskGroup."""
    session_id = session.user_id
    client_task = None
    agent_task = None

    try:
        logger.info(f"[Session: {session_id}] Starting message handling tasks.")
        async with asyncio.TaskGroup() as tg:
            client_task = tg.create_task(
                handle_client_messages(websocket, session),
                name=f"client_handler_{session_id}",
            )
            agent_task = tg.create_task(
                handle_agent_responses(websocket, session),
                name=f"agent_handler_{session_id}",
            )

        logger.info(f"[Session: {session_id}] Both message handling tasks completed.")

    except* asyncio.CancelledError:
        logger.info(f"[Session: {session_id}] Message handling task group cancelled.")
        # Tasks are automatically cancelled by TaskGroup context exit
    except* Exception as eg:
        logger.error(
            f"[Session: {session_id}] Error occurred within message handling TaskGroup: {eg.exceptions}"
        )
        # Check for specific errors like quota exceeded
        handled = False
        for exc in eg.exceptions:
            if "Quota exceeded" in str(exc):  # Simple string check, adjust if needed
                logger.warning(
                    f"[Session: {session_id}] Quota exceeded error detected."
                )
                await send_error_message(
                    websocket,
                    {
                        "message": "Quota exceeded.",
                        "action": "Please wait a moment and try again.",
                        "error_type": "quota_exceeded",
                    },
                )
                # Optionally send a text message as well
                await send_json_message(
                    websocket,
                    "text",
                    "⚠️ Quota exceeded. Please wait a moment and try again.",
                )
                handled = True
                break  # Stop checking once handled

        if not handled:
            logger.exception(
                f"[Session: {session_id}] Unhandled error in message handling TaskGroup."
            )
            # Send a generic error if the connection is still open
            await send_error_message(
                websocket,
                {
                    "message": "An internal error occurred during message handling.",
                    "action": "Please try reconnecting.",
                    "error_type": "task_group_error",
                },
            )
        # Task cancellation is handled by TaskGroup context exit
    finally:
        logger.info(f"[Session: {session_id}] Exiting handle_messages function.")
        # Ensure tasks are cancelled if the function exits unexpectedly outside the TaskGroup block
        # (though TaskGroup usually handles this)
        if client_task and not client_task.done():
            client_task.cancel()
        if agent_task and not agent_task.done():
            agent_task.cancel()
        # Ensure websocket is closed if not already
        if not websocket.closed:
            logger.warning(
                f"[Session: {session_id}] Closing websocket in handle_messages finally block."
            )
            await websocket.close(
                code=WSCloseCode.NORMAL_CLOSURE, message=b"Session ending"
            )


# --- Main Client Connection Handler (Entry Point - Adapted for aiohttp) ---


async def handle_client(websocket: web.WebSocketResponse) -> None:
    """
    Handles a new client connection established via aiohttp.
    This function is called by the WebSocket route handler in combined-server.py.
    """
    # Generate a unique session ID (using object ID is simple but not persistent across restarts)
    # Consider using a more robust method if session persistence is needed.
    session_id = str(id(websocket))
    logger.info(f"WebSocket connection established. Assigning session ID: {session_id}")

    session = None  # Initialize session to None
    try:
        # 1. Get Agent Configuration
        agent_config = get_agent_config(session_id)  # Pass session_id for context
        app_name = agent_config.get("app_name", "default_app")
        root_agent = agent_config.get("root_agent")
        context = agent_config.get("context", {})  # Ensure context is a dict

        if not root_agent:
            logger.error(
                f"[Session: {session_id}] Agent configuration failed: No root agent found."
            )
            await send_error_message(
                websocket, {"message": "Server configuration error: Agent not found."}
            )
            await websocket.close(
                code=WSCloseCode.INTERNAL_ERROR, message=b"Agent configuration failed"
            )
            return

        # 2. Create Session State
        session = await create_session(
            session_id, root_agent, app_name, context=context
        )

        config_data = {
            "model": MODEL,
            "voice": VOICE,
            "model_language": MODEL_LANGUAGE,
            "prompt_language": PROMPT_LANGUAGE,
            "use_tts": USE_TTS,
        }

        await send_json_message(websocket, "config", config_data)

        # 3. Send "ready" message to client
        await send_json_message(websocket, "ready", True)
        logger.info(
            f">>>>>>>>>>>>>>> NEW SESSION: {session_id} ({app_name}) <<<<<<<<<<<<<<<"
        )

        # 4. Start bidirectional message handling
        await handle_messages(websocket, session)

    except ConnectionResetError:
        logger.warning(f"[Session: {session_id}] Connection reset by peer.")
    except asyncio.CancelledError:
        logger.info(f"[Session: {session_id}] handle_client task cancelled.")
    except Exception as e:
        logger.exception(
            f"[Session: {session_id}] Error during handle_client execution: {e}"
        )
        # Attempt to send error to client if possible
        await send_error_message(
            websocket,
            {
                "message": "An unexpected error occurred on the server.",
                "action": "Please try reconnecting.",
                "error_type": "general_server_error",
            },
        )
    finally:
        logger.info(f"Cleaning up resources for session {session_id}")
        # Ensure cleanup happens even if session creation failed partially
        await cleanup_session(session, session_id)
        # Ensure websocket is closed
        if not websocket.closed:
            logger.info(
                f"[Session: {session_id}] Closing websocket connection in handle_client finally block."
            )
            await websocket.close(
                code=WSCloseCode.GOING_AWAY, message=b"Server shutting down session"
            )
        logger.info(f"Session {session_id} fully terminated.")
=== ./server/core/session_utils.py ===
"""A set of utility methods that help manipulate Session context."""

from typing import Any, List, Dict
from google.genai import types

from google.adk.tools import BaseTool
from google.adk.tools.tool_context import ToolContext
from google.adk.agents.invocation_context import InvocationContext
from google.adk.agents.callback_context import CallbackContext
from google.adk.events import Event, EventActions
from google.adk.models.llm_request import LlmRequest
from google.adk.models.llm_response import LlmResponse

from .logger import logger

class SessionUtils:
    """A set of utility methods that help manipulate Session context."""

    @staticmethod
    def logic_check():
        logger.info("DETERMINISTIC LOGIC CHECK!")

    @staticmethod
    def log_after_agent():
        logger.info("AFTER AGENT")

    @staticmethod
    def log_before_agent():
        logger.info("BEFORE AGENT")

    @staticmethod
    def log_before_tool():
        logger.info("BEFORE TOOL")

    @staticmethod
    def log_after_tool():
        logger.info("AFTER TOOL")

    @staticmethod
    def log_before_model():
        logger.info("BEFORE MODEL")

    @staticmethod
    def log_after_model():
        logger.info("AFTER MODEL")

    @staticmethod
    def build_content(content) -> types.Content:
        """
        Builds a types.Content object. (Same as before)
        """
        if isinstance(content, str):
            return types.Content(role="model", parts=[types.Part(text=content)])
        else:
            raise ValueError(f"Unsupported content type: {type(content)}")
        
        # TODO: Add other content types
        
    @staticmethod
    def get_state(
        context: CallbackContext | ToolContext | InvocationContext
        ) -> Dict[str, Any]:
        """Get the current state based on provided context."""
        if isinstance(context, CallbackContext):
            return context._invocation_context.session.state

        elif isinstance(context, ToolContext):
            return context._invocation_context.session.state
        
        elif isinstance(context, InvocationContext):
            return context.session.state

        else:
            raise ValueError(f"Unknown context type: {type(context)}")

    @staticmethod
    def update_state(
        context: CallbackContext | ToolContext | InvocationContext,
        data: Dict[str, Any]) -> None:
        """Update all k/v pairs in data back into session state."""
        if isinstance(context, InvocationContext):
            for k, v in data.items():
                context.session.state[k] = v

        elif isinstance(context, CallbackContext):
            for k, v in data.items():
                context._invocation_context.session.state[k] = v

        elif isinstance(context, ToolContext):
            for k, v in data.items():
                context._invocation_context.session.state[k] = v

        else:
            raise ValueError(f"Unknown context type: {type(context)}")

    @staticmethod
    def dedupe_lists(existing_list: List[Any], new_list: List[Any]):
        """Dedupe items from list."""
        final_list = []
        if new_list is None:
            final_list = existing_list
        else:
            final_list = existing_list + [
                item for item in new_list if item not in existing_list
                ]
        
        return final_list

    @staticmethod
    def model_response(
            text: str = None, function_call_name: str = None,
            function_call_args: dict = None,
            function_response: types.FunctionResponse = None):
        """Method to simplify creating agent response object."""

        ROLE = "model"
        if text:
            return types.Content(role=ROLE, parts=[types.Part.from_text(text=text)])
        elif function_call_name and function_call_args:
            return types.Content(role=ROLE, parts=[types.Part.from_function_call(
                name=function_call_name,
                args=function_call_args
            )])
        elif function_response:
            return types.Content(role=ROLE, parts=[function_response])
        else:
            raise ValueError("Either text or function_call must be provided")

    def build_event(
            self,
            context: InvocationContext | CallbackContext | ToolContext,
            text: str = None,
            function_call: types.FunctionCall = None,
            event_options: Dict[str, Any] = None) -> Event:
        """Method to simplify Event response object."""

        event_options_obj = EventActions(**event_options) if event_options else None

        if isinstance(context, InvocationContext):
            invocation_id = context.invocation_id
            author = context.agent.name

        elif isinstance(context, CallbackContext):
            invocation_id = context._invocation_context.invocation_id
            author = context._invocation_context.agent.name

        elif isinstance(context, ToolContext):
            invocation_id = context._invocation_context.invocation_id
            author = context._invocation_context.agent.name

        if event_options_obj:
            return Event(
                invocation_id=invocation_id,
                author=author,
                content=self.model_response(
                    text=text, function_call=function_call),
                options=event_options_obj
            )
        else:
            return Event(
                invocation_id=invocation_id,
                author=author,
                content=self.model_response(
                    text=text, function_call=function_call)
                )

=== ./server/core/agents/teg/tools.py ===
# ./server/core/agents/teg/tools.py
import logging
import os
import json
import requests
import re # For parsing prices

# For Google Cloud authentication and ID token generation (retained for other tools)
import google.auth
import google.auth.transport.requests
from google.oauth2 import id_token as google_id_token
import google.auth.exceptions

from google.adk.tools.tool_context import ToolContext
from .context import TegContext # Imports LIVE_TEG_CATALOG_DATA

logger = logging.getLogger(__name__)

# --- Configuration for your Cloud Run Endpoints ---
CUSTOM_SEARCH_CLOUD_RUN_URL = os.environ.get("CUSTOM_SEARCH_CLOUD_RUN_URL")
WEB_SUMMARIZER_CLOUD_RUN_URL = os.environ.get("WEB_SUMMARIZER_CLOUD_RUN_URL")
# LIVE_CATALOG_CLOUD_RUN_URL is no longer used by search_live_teg_catalog

# --- Helper function to get an ID token for invoking Cloud Run (retained for other tools) ---
def get_id_token(target_audience_url: str) -> str:
    print(f"Attempting to get ID token for audience: {target_audience_url}")
    credentials = None 
    project_id = None
    auth_req = None
    try:
        print("Calling google.auth.default()...")
        if not os.environ.get("GOOGLE_APPLICATION_CREDENTIALS"):
            try:
                adc_path = "Unknown"
                if os.name == 'nt':
                    adc_path = os.path.join(os.getenv('APPDATA', ''), 'gcloud', 'application_default_credentials.json')
                else:
                    adc_path = os.path.join(os.path.expanduser('~'), '.config', 'gcloud', 'application_default_credentials.json')
                print(f"Expecting ADC file at: {adc_path}. Exists: {os.path.exists(adc_path)}")
            except Exception as path_e:
                logger.warning(f"Could not determine or check ADC path: {path_e}")

        credentials, project_id = google.auth.default(
            scopes=["openid", "email", "profile", "https://www.googleapis.com/auth/cloud-platform"]
        )

        if not credentials:
            logger.error("google.auth.default() returned no credentials.")
            raise google.auth.exceptions.DefaultCredentialsError("ADC: No credentials found.")
        
        print(f"ADC: Successfully obtained credentials. Type: {type(credentials)}. Project ID: {project_id or 'Not determined'}")

        auth_req = google.auth.transport.requests.Request()

        print("ADC: Attempting to refresh credentials if necessary...")
        try:
            credentials.refresh(auth_req)
            print("ADC: Credentials refresh attempt completed.")
        except google.auth.exceptions.RefreshError as re:
            logger.error(f"ADC: Failed to refresh credentials: {re}. ADC might be stale or revoked.")
            raise
        except AttributeError:
            logger.warning(f"ADC: Credentials of type {type(credentials)} do not have a refresh method. Proceeding.")

        print(f"ADC: Fetching ID token for audience: {target_audience_url} using obtained credentials.")
        token = google_id_token.fetch_id_token(auth_req, target_audience_url)
        
        if not token:
            logger.error("fetch_id_token returned None or empty token.")
            raise ValueError("Failed to fetch a valid ID token (token was None/empty).")
            
        print("Successfully fetched ID token.")
        return token

    except google.auth.exceptions.RefreshError as re:
        logger.error(f"ID Token Generation Failed due to RefreshError: {re}")
        raise
    except google.auth.exceptions.DefaultCredentialsError as dce:
        logger.error(f"ID Token Generation Failed due to DefaultCredentialsError: {dce}")
        logger.error("This error during fetch_id_token might indicate issues with the refresh token or network access to token servers.")
        raise
    except Exception as e:
        logger.exception(f"An unexpected error occurred during ID token generation for {target_audience_url}: {e}")
        if credentials:
            logger.error(f"Credentials state at time of error: valid={credentials.valid}, expired={credentials.expired}, token={credentials.token is not None}")
        raise

# --- Tool Implementations for Teg ---

def greeting() -> dict:
    logger.info("Tool: greeting called")
    return {"status": "success", 
            "greeting_message": f"Hello! I'm Evie, your Teg Android Assistant. How can I help you with your Android needs today?"}

def get_current_datetime_tool() -> dict:
    logger.info("Tool: get_current_datetime_tool called")
    from datetime import datetime
    now_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return {
        "status": "success", 
        "current_datetime_str": now_str}

def custom_web_search(search_query: str, tool_context: ToolContext, num_results: int = 3) -> dict:
    logger.info(f"Tool: custom_web_search (via authenticated Cloud Run) called with query: '{search_query}', num_results: {num_results}")

    if not CUSTOM_SEARCH_CLOUD_RUN_URL:
        logger.error("Custom Search Cloud Run URL is not configured.")
        return {"status": "error",
                "error_message": "Search service endpoint not configured.", 
                "search_results": [] }

    try:
        token = get_id_token(CUSTOM_SEARCH_CLOUD_RUN_URL)
    except Exception as auth_err:
        logger.error(f"Authentication failed for custom_web_search: {str(auth_err)}")
        return { "status": "error",
                 "error_message": f"Authentication failed for search service: {str(auth_err)}", 
                 "search_results": []}


    payload = {
        "search_terms": search_query,
        "num_results": num_results,
        "simplified_response": True 
    }
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}"
    }

    try:
        response = requests.post(CUSTOM_SEARCH_CLOUD_RUN_URL, json=payload, headers=headers, timeout=15)
        response.raise_for_status()
        
        data = response.json()
        if "error" in data: 
            logger.error(f"Custom Search Cloud Run service returned an error: {data['error']}")
            return {"status": "error",
                    "error_message": data["error"], 
                    "search_results": []}
        
        search_results = data.get("results", [])
        if not search_results:
             logger.info(f"No search results from Cloud Run for query: '{search_query}'")
        return { "status": "success", 
                 "search_results": search_results}

    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTP error calling Custom Search Cloud Run: {http_err} - Response: {http_err.response.text if http_err.response else 'No response body'}")
        return {"status": "error", "search_results": [], "error_message": f"Search service request failed (HTTP {http_err.response.status_code if http_err.response else 'Unknown'})."}
    except requests.exceptions.RequestException as req_err:
        logger.exception(f"Error calling Custom Search Cloud Run: {req_err}")
        return {"status": "error", "search_results": [], "error_message": f"Could not connect to search service: {str(req_err)}"}
    except json.JSONDecodeError:
        logger.error(f"Failed to decode JSON response from Custom Search Cloud Run. Response: {response.text if response else 'No response object'}")
        return {"status": "error", "search_results": [], "error_message": "Invalid response format from search service."}


def web_content_summarizer(url: str, tool_context: ToolContext) -> dict:
    logger.info(f"Tool: web_content_summarizer (via authenticated Cloud Run) called for URL: '{url}'")

    if not WEB_SUMMARIZER_CLOUD_RUN_URL:
        logger.error("Web Summarizer Cloud Run URL is not configured.")
        return {"status": "error", "summary": None, "error_message": "Summarizer service endpoint not configured."}

    try:
        token = get_id_token(WEB_SUMMARIZER_CLOUD_RUN_URL)
    except Exception as auth_err:
        logger.error(f"Authentication failed for web_content_summarizer: {str(auth_err)}")
        return {"status": "error", "summary": None, "error_message": f"Authentication failed for summarizer service: {str(auth_err)}"}

    payload = {"url": url}
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {token}"
    }

    try:
        response = requests.post(WEB_SUMMARIZER_CLOUD_RUN_URL, json=payload, headers=headers, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        if "error" in data: 
            logger.error(f"Web Summarizer Cloud Run service returned an error: {data['error']}")
            return {"status": "error", "summary": None, "error_message": data["error"]}
            
        summary = data.get("summary")
        if not summary: 
            logger.info(f"No summary returned or summary was empty from Cloud Run for URL: {url}")
            return {"status": "error", "summary": None, "error_message": "Content could not be summarized or the summary was empty."}
        return {"status": "success", "summary": summary}

    except requests.exceptions.HTTPError as http_err:
        logger.error(f"HTTP error calling Web Summarizer Cloud Run: {http_err} - Response: {http_err.response.text if http_err.response else 'No response body'}")
        return {"status": "error", "summary": None, "error_message": f"Summarizer service request failed (HTTP {http_err.response.status_code if http_err.response else 'Unknown'})."}
    except requests.exceptions.RequestException as req_err:
        logger.exception(f"Error calling Web Summarizer Cloud Run: {req_err}")
        return {"status": "error", "summary": None, "error_message": f"Could not connect to summarizer service: {str(req_err)}"}
    except json.JSONDecodeError:
        logger.error(f"Failed to decode JSON response from Web Summarizer Cloud Run. Response: {response.text if response else 'No response object'}")
        return {"status": "error", "summary": None, "error_message": "Invalid response format from summarizer service."}

def _get_price_string(product_data: dict) -> str:
    """Extracts a representative price string from product data."""
    price_outright = product_data.get("Price Outright", "")
    price_monthly = product_data.get("Price over 36 months", "")

    if isinstance(price_outright, str) and "$" in price_outright and "not available" not in price_outright.lower() and "not explicitly stated" not in price_outright.lower():
        return price_outright.split('/month')[0].strip() # Return outright if it looks like a price
    
    if isinstance(price_monthly, str) and "$" in price_monthly and "not available" not in price_monthly.lower() and "not explicitly stated" not in price_monthly.lower():
        return f"{price_monthly.split('/month')[0].strip()} /month" # Return monthly if outright is not good

    return "Price not available"

def _get_stock_status(product_data: dict) -> str:
    """Infers stock status from product data."""
    price_outright = product_data.get("Price Outright", "")
    price_monthly = product_data.get("Price over 36 months", "")
    url = product_data.get("URL", "").lower()

    if "out of stock" in url or \
       (isinstance(price_outright, str) and ("out of stock" in price_outright.lower() or "not available" == price_outright.lower())) or \
       (isinstance(price_monthly, str) and ("out of stock" in price_monthly.lower() or "not available" == price_monthly.lower())):
        return "Out of Stock"
    # Check for models known to be out of stock from product_v3.json examples
    if product_data.get("Model") == "Galaxy Z Flip6" and "Not available/Out of Stock" in price_outright :
        return "Out of Stock"
    if product_data.get("Model") == "Galaxy Z Fold6" and "Not available (Out of Stock)" in price_outright :
        return "Out of Stock"
    if product_data.get("Model") == "Galaxy S22" and "Not available - Out of Stock" in price_outright :
        return "Out of Stock"
        
    # If price is "N/A" it might also indicate out of stock for some entries in product_v3.json
    if price_outright == "N/A" or price_monthly == "N/A":
        # A more robust check might be needed if "N/A" doesn't always mean out of stock
        # For now, let's assume it might be unavailable.
        if "iphone 16" in product_data.get("Model","").lower() or "galaxy s25" in product_data.get("Model","").lower(): # Newer models might be pre-order
             return "Check availability (possibly pre-order)"


    # Default if no explicit out-of-stock indicators
    return "In Stock"


def search_live_teg_catalog(search_term: str, tool_context: ToolContext) -> dict:
    """
    Searches the Teg product catalog (from a local JSON data source) for events using a search term.
    The tool filters events based on the artist's name.
    It returns a JSON response with a list of matching events.
    The response is a dictionary with a single key "events", which contains a list of event objects.
    Example of a returned event object in the list:
    {
        "Artist": "Drake",
        "Time": "14 July 2025",
        "Country": "Australia",
        "City": "Hunter Valley",
        "Venue": "QIRKZ in The Hunter",
        "Price starting from": "$89.90",
        "Price Tiers": [
            {
                "Price": "$89.90",
                "SeatLocation": "Section C, Row 16",
                "View": "Average"
            },
            {
                "Price": "$169.90",
                "SeatLocation": "Section B, Row 15",
                "View": "Great"
            },
            {
                "Price": "$269.90",
                "SeatLocation": "Section A, Row 14",
                "View": "Excellent"
            }
        ]
    }
    """
    logger.info(f"Tool: search_live_teg_catalog (local JSON) called with search_term: '{search_term}'")

    catalog_data = TegContext.LIVE_TEG_CATALOG_DATA
    if not catalog_data:
        logger.warning("Teg product catalog data is not loaded or is empty.")
        return {"devices": [], "message": "Sorry, the product catalog is currently unavailable."}

    search_term_lower = search_term.lower()
    # Remove generic terms that don't help with filtering this specific JSON
    search_term_lower = search_term_lower.replace("teg", "").replace("android", "").replace("phone", "").replace("phones", "").replace("deals", "").replace("latest","").strip()
    
    results = []

    for product in catalog_data:
        # Ensure essential fields exist, skip product if not
        artist = product.get("Artist", "")
        if not artist: # Skip items that doesn't have artist. 
            continue

        match_score = 0
        artist_name_lower = f"{artist.lower()}"

        # Direct name match gives higher score
        if search_term_lower in artist_name_lower:
            match_score += 10
        
        # Partial matches for brand and model
        search_tokens = set(search_term_lower.split())
        artist_tokens = set(artist_name_lower.split())
        
        common_tokens = search_tokens.intersection(artist_tokens)
        match_score += len(common_tokens) * 2

        if match_score > 0:
            # Transform product to the desired output structure
            event_info = {
                "Artist": product.get("Artist", ""),
                "Time": product.get("Time", ""),
                "Country": product.get("Country", ""),
                "City": product.get("City", ""),
                "Venue": product.get("Venue"),
                "Price starting from": product.get("Price starting from", ""),
                "Price Tiers": product.get("Price Tiers", []),
                "_match_score": match_score # For sorting
            }
            results.append(event_info)

    # Sort results by match score, highest first
    sorted_results = sorted(results, key=lambda x: x["_match_score"], reverse=True)
    
    # Remove the temporary score key
    for res in sorted_results:
        del res["_match_score"]

    if not sorted_results:
        logger.info(f"No event found in local catalog for search_term: '{search_term}' (processed as '{search_term_lower}')")
        return {"events": [], "message": f"Sorry, I couldn't find any event  matching '{search_term}' in the Teg catalog right now."}
    
    logger.info(f"Found {len(sorted_results)} event(s) for search_term: '{search_term}'")
    # The prompt suggests Teg will pick 1-2 recommendations.
    # The tool should return all relevant found events (or a reasonable subset).
    # Let's return up to, say, 5 top matches to give the agent some choice.
    return {"events": sorted_results[:5]}


def request_visual_input(reason_for_request: str, tool_context: ToolContext) -> dict:
    logger.info(f"Tool: request_visual_input called. Reason: '{reason_for_request}'")
    return {
        "status": "visual_input_requested",
        "reason": reason_for_request,
        "message_to_user": f"Okay, to help with '{reason_for_request}', could you please show it to me using your camera or by uploading an image?"
    }

def affirmative() -> dict:
    logger.info("Tool: affirmative called. User gave affirmative response.")
    return {"status": "success", "user_affirmed": True}

def update_crm(customer_id: str, details: str, tool_context: ToolContext) -> dict:
    logger.info(f"Tool: update_crm called for customer '{customer_id}' with details: '{details}'")
    # In a real scenario, this would interact with a CRM system.
    return {"status": "success", "message": f"CRM record for '{customer_id}' updated."}

def book_ticket(artist: str) -> dict:
    logger.info(f"Tool: book_ticket called for the event of the artist: '{artist}'")
    # In a real scenario, this would interact with a booking system.
    return {"status": "success", "message": f"ticket booked for event of the artist '{artist}'."}

def adjust_seat_temp() -> dict:
    logger.info(f"Tool: adjust_seat_temp called for increasing the airflow of the localized ventilation by 20%")
    # In a real scenario, this would interact with a ventilation IoT system.
    return {"status": "success", "message": f"The airflow of the localized ventilation has been increased by 20%."}=== ./server/core/agents/teg/__init__.py ===
# This file can be empty, it just makes 'teg' a Python package.=== ./server/core/agents/teg/prompts.py ===
# ./server/core/agents/teg/prompts.py
from .examples import TegExamples
from .context import TegContext # To get default customer name, brand name, and potentially catalog access if needed by examples

# Get dynamic values from context for placeholders
assistant_name = TegContext.CUSTOMER_PROFILE.get("assistant_name", "Evie")
brand_name = TegContext.CUSTOMER_PROFILE.get("brand_name", "Teg")
customer_first_name = TegContext.CUSTOMER_PROFILE.get("customer_profile", {}).get("first_name", "Valued Customer")
allowed_search_domains_str = ", ".join(TegContext.CUSTOMER_PROFILE.get("allowed_search_domains", []))


# Compile examples with dynamic values
_greeting_example = TegExamples.GREETING_AND_GENERAL_QUERY.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_specific_query_example = TegExamples.SPECIFIC_QUERY_WITH_WEB_SEARCH.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
# Note: _upgrade_example uses search_teg_android_catalog and its old output format.
# This example is not being modified as per user request, but will be inconsistent with the new search_live_teg_catalog.
_upgrade_example = TegExamples.DEVICE_UPGRADE_ASSISTANCE.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_visual_troubleshooting_example = TegExamples.VISUAL_TROUBLESHOOTING.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_closing_example = TegExamples.CLOSING_CONVERSATION.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)


class TegPrompts:
    GLOBAL_PROMPT = f"""
You are an AI assistant named {assistant_name} for {brand_name}.
The current datetime is: {{current_datetime}}.
The profile of the current customer is: {{customer_profile}}.
Your current language for all interactions is: {{language}}.
Speak slowly and try not to overstep your own voices. 
DEBUG: Current Session ID is: {{session_id}}.

**Pronunciation Guide:**
*   When you encounter "gsmarena.com" in text or search results, you should pronounce it as "G.S.M. Arena dot com".
"""

    TEG_ASSIST_MAIN = f"""
You are {assistant_name}, a multimodal on-line friendly AI Assistant for {brand_name}. 
You have an expert knowledge of all the entertainment events, such as pop concerts, music festival, sports events, etc. You know the ones held and how to search for the upcoming ones. 
You are also an expert about the event venues, including the layout of the venues, seat arrangements, temperature controls, etc.
Your job is to help {brand_name} customers with their queries about the entertainment events, including the event date, venue, and all the relevant information.
You also help {brand_name} customers with their issues and questions while they are attending the events, such as helping find the lost wallet, showing the direction to the seat, translating ASL language to English, etc.
As some of {brand_name} customers have disabilities, so you understand American Sign Language (ASL) well and able to translate and help people in that regard. 
For any query the customer is asking, you need to consider the query in the context of entertainment events, in particular the ones managed by TEG, a global leader in live entertainment, ticketing, and technology, best known for its major ticketing brand, Ticketek, which operates across Australia, New Zealand, and other international markets.
When customer is unhappy or frustrated with your service, apologize first then politely and gracefully advises them that you are transferring them to a human agent. 

Be friendly, knowledgeable, and proactive in helping customers with their questions. 
Don't be too casual or disrespectful, and vary your syntax (for example, don't always say "great choice!".) Also, don't be too apologetic. Do not be robotic!
Incorporate the details provided by the user for personalized interactions.
Ensure responses stay relevant and coherent to the user's input, avoiding the generation of unrelated or tangential content.
When customer is unhappy or frustrated with your service, apologize first then politely and gracefully advises them that you are transferring them to a human agent. 

**Core Capabilities & Workflow:**

1.  **Greeting & Introduction:**
    *   Start by warmly greeting the user by their first name (e.g., "Hello {{customer_profile.first_name}}!").
    *   Introduce yourself: "I'm {assistant_name}, your {brand_name} Event Assistant."
    *   Ask how you can help with their questions about entertainment events: "How can I help you with your questions about entertainment events or improve your event experience today?"

2.  **Understand User Query:**
    *   Listen carefully to understand the user's query ($user_query).

3.  **Determine Query Type (Internal Logic - Do not state this classification to the user):**
    *   **General Query:** If the query is about general entertainment events, music (e.g., 'what's blues', 'where is opera house', 'what type of events can be held in olympic park'). This may or may not require a quick web search for broader, less time-sensitive information.
    *   **Musician & Event Query:** If the user's query requires up-to-date information on upcoming events for a specific musician or artist (e.g., 'what gigs are coming up for Drake', 'any Eminem concert coming up?', 'where is the venue for the next Taylor Swift concert?'). This will typically require searching TEG's internal event catalog.
    *   **Event Experience Assist Query:** If the user expresses assistant needed for attending an event (e.g., 'adjust the temperature around my seat', ' I just dropped my wallet during the event").

4.  **Handling Query Types:**

    *   **If General Query:**
        *   Provide a comprehensive, friendly, and easy-to-understand answer using your general knowledge.
        *   If your own knowledge is insufficient or the query might benefit from broader, less time-sensitive information, you can use the `custom_web_search` tool.
        *   If using search, inform the user: "Let me quickly check that for you."
        *   After search, synthesize information if found, or state if nothing specific was found.
        *   If search results were used, inform the user: "I found this information using a web search. I can show you the source articles or provide links if you'd like." Do NOT read out the URLs unless the user specifically asks for a URL to be read. If co-browsing is possible, offer to navigate to the page.

    *   **If Musician & Event Query:**
        *   Acknowledge their interest and advise the user that you are keen to help them find the relevant event. 
        *   If the user's query already has a specific musician or artist or band, proceed to the next step. Otherwise, ask clarifying questions to understand their needs: "What kind of musician or artist are you looking for? For example, Blues, R&B?", "which artist you are interested with?"
        *   Based on their response, formulate a `search_term` (e.g., "Drake", "James Blunt").
        *   Inform the user: "Let me check the current {brand_name} catalog for you. This may take a few seconds."
        *   Call the `search_live_teg_catalog` tool with the `search_term`. This tool queries the {brand_name} event catalog (from local data) and returns JSON data.
            *   The JSON response for each event will include fields like: `Artist`, `Time`, and `Country`, etc.
            *   **Note on tool usage:** Use this tool *primarily* when the user is interested in the upcoming events for a specific artist or musician. For general information about music, event venues, prefer 'General Query' handling.
        *   Examine the response:
            *   If the tool returns `None` or an empty list of events, or a `message` indicating no event were found: 
                *   Inform the user that you couldn't find any events of the artist in the {brand_name} catalog right now.
                *   Find an alternative artist from the list of {{customer_profile.preferred_artists}} who has similar characteristics:
                    *    For example, the alternative artist for Eminem would be Drake. The alternative band for "Foo Fighters" would be "The Rubens".
                *   Explain to the user that the alternative artist or band has similar music/art styles and also is what the user likes, and ask the user it's ok for you to search the upcoming events for the alternative artist or band instead:
                    *    If Yes, 
                          *    Formulate a `alternative_search_term` using the alternative artist name or the alternative band name. 
                          *    Call the `search_live_teg_catalog` tool with the `alternative_search_term`.
                          *    if the tool returns available event(s), advise the user about the event(s) and ask the user if they want to book a ticket. 
                               *    If yes, call the `book_ticket` tool with the artist name to book a ticket for the user.          
            *   If events are found (JSON response with a non-empty list):
                *   Select 1-2 top recommendations from the returned list.
                *   For each recommendation, present the information clearly.
                *   Mention the availability of more details: "You can find more details on the {brand_name} website."
                *   Ask the user if they want to book a ticket. 
                    *    if yes, then call the `book_ticket` tool with the artist name to book a ticket for user. 

    *   **Event Experience Assist Query:**
        *   Provide a comprehensive, friendly, and easy-to-understand answer using your general knowledge.
        *   If the user wants to share their camera, screen, or files with you, 
            *   Accept that request
            *   Answer the user's query based on the information shared. 
            *   Help the user to spot things in the video or image even if it's not in an event venue.
        *   If the topic is about bathroom, advise the user that the nearest accessible bathroom is located on Level 2, near Gate 14.
        *   If the user mentions the section of their seat is too hot and ask you to adjust the temperature around my seat:
            *    Ask  the user to confirm if they are happy for you to adjust the localized ventilation around the seat to a cooler setting by increasing the airflow by 20%. 
                 *    If yes, call the `adjust_seat_temp` tool.
        *   If your own knowledge is insufficient or the query might benefit from broader information, you can use the `custom_web_search` tool.
        *   If using search, inform the user: "Let me quickly check that for you."
        *   After search, synthesize information if found, or state if nothing specific was found.
        *   If search results were used, inform the user: "I found this information using a web search. I can show you the source articles or provide links if you'd like." Do NOT read out the URLs unless the user specifically asks for a URL to be read. If co-browsing is possible, offer to navigate to the page. 
                
5.  **Follow-Up:**
    *   After providing an answer or assistance, always ask: "Is there anything else I can help you with regard to your interested events, {{customer_profile.first_name}}?" or "Does that help answer your question?"

6.  **Loop or Conclude:**
    *   If the user has more questions (use `affirmative()` tool if they just say "yes" to needing more help), go back to step 2.
    *   If the user indicates they are satisfied or have no more questions (e.g., "no, that's all", "thank you"):
        *   Offer a polite closing: "You're welcome, {{customer_profile.first_name}}! I'm glad I could help. Feel free to reach out if you have more questions about any event in the future. Have a great day!"
        *   Call `update_crm` tool with `customer_id` (use `{{customer_profile.first_name}}` or a session identifier if available) and a brief `details` summary of the interaction.
        *   End the conversation.
    *   If the user is not satisfied with your answer:
        *   Apologize for that you couldn't provide the full answer first. 
        *   Gracefully and politely advise the user that you are transferring them to a human agent. 

**Tool Usage Guidelines:**
*   Use tools proactively.
*   Do not mention internal tool names. Refer to the action (e.g., "I'm checking the catalog," "I'll search for that," "Let me request a visual").
*   If a tool call is for an action the user should be aware of (like `request_visual_input`), inform them before or as part of the tool's output message.

**Interaction Style:**
*   Be friendly, empathetic, patient, and professional.
*   Keep responses concise but comprehensive.
*   If the user provides an image/video, analyze it and incorporate your findings into your response.

<Examples>
{_greeting_example}
{_specific_query_example}
{_closing_example}
</Examples>

Begin!
"""=== ./server/core/agents/teg/context.py ===
# ./server/core/agents/teg/context.py
import json
import logging
import os
from datetime import datetime
from config.config import PROMPT_LANGUAGE, FIRST_NAME, LAST_NAME

logger = logging.getLogger(__name__)

# Use configured names or provide Teg-specific defaults
TEG_CUSTOMER_FIRST_NAME = FIRST_NAME # Or "Alex"
TEG_CUSTOMER_LAST_NAME = LAST_NAME   # Or "Consumer"

DEFAULT_LANGUAGE = PROMPT_LANGUAGE or "en-AU"

# Path to the product catalog JSON file
# Assuming product_v3.json is in the same directory as this context.py file,
# or an appropriate path is provided.
PRODUCT_CATALOG_FILE = os.path.join(os.path.dirname(__file__), 'product_v4.json')

def load_catalog_data(file_path: str) -> list:
    """Loads product catalog data from a JSON file."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            if isinstance(data, list):
                return data
            else:
                logger.error(f"Product catalog JSON at {file_path} is not a list.")
                return []
    except FileNotFoundError:
        logger.error(f"Product catalog file not found: {file_path}")
        return []
    except json.JSONDecodeError:
        logger.error(f"Error decoding JSON from product catalog file: {file_path}")
        return []
    except Exception as e:
        logger.error(f"An unexpected error occurred while loading product catalog {file_path}: {e}")
        return []

class TegContext:
    # Load the live catalog data from the JSON file
    LIVE_TEG_CATALOG_DATA = load_catalog_data(PRODUCT_CATALOG_FILE)
    if not LIVE_TEG_CATALOG_DATA:
        logger.warning("LIVE_TEG_CATALOG_DATA is empty. Search functionality will be affected.")

    CUSTOMER_PROFILE = {
        "customer_profile": {
            "first_name": TEG_CUSTOMER_FIRST_NAME,
            "last_name": TEG_CUSTOMER_LAST_NAME,
            "is_teg_customer": False, # Can be updated based on interaction
            "current_device": None, # Can be identified during conversation
            "preferred_artists": ["Eminem", "Drake", "James Blunt", "The Rubens"], 
            "preferred_contact_method": "chat",
        },
        "brand_name": "Ticketek",
        "assistant_name": "Evie",
        "allowed_search_domains": [ # For agent's awareness if it were to generate search queries
            "support.google.com/android",
            "*.android.com",
            "*.gsmarena.com",
            "www.teg.com.au/mobile-phones",
            "www.teg.com.au"
        ],
        "current_datetime": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "session_id": None, # Will be populated at runtime
        "language": DEFAULT_LANGUAGE
    }

    # Note: The static TEG_ANDROID_CATALOG from R1 is no longer used by the primary catalog search tool.
    # If it was present in R2 context, it's superseded by LIVE_TEG_CATALOG_DATA for the search_live_teg_catalog tool.=== ./server/core/agents/teg/teg_assist.py ===
# ./server/core/agents/teg/teg_assist.py
import logging
from typing import Any, List, Dict # Added Dict for callback type hints if used

from google.adk import Agent
from google.adk.tools import BaseTool
# from google.adk.agents.callback_context import CallbackContext # If complex callbacks needed
# from google.adk.tools.tool_context import ToolContext # If complex callbacks needed

from config.config import MODEL
from .prompts import TegPrompts # Will import TegPrompts from prompts_R3.py
# Assuming session_utils is in parent directory, adjust if necessary
# from ...session_utils import SessionUtils # Example if session_utils is in a parent 'core' directory

# Import all the tools defined for Teg
from .tools import ( # Will import tools from tools_R3.py
    greeting,
    get_current_datetime_tool,
    custom_web_search,
    web_content_summarizer,
    search_live_teg_catalog, # Uses the local JSON search implementation
    request_visual_input,
    affirmative,
    update_crm,
    book_ticket,
    adjust_seat_temp
)

logger = logging.getLogger(__name__)

# --- Callbacks (Optional - Add logic if needed, ensure SessionUtils is correctly imported if used) ---
# def logic_check_teg(tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext):
#     # SessionUtils.log_before_tool() # Ensure SessionUtils is available
#     logger.debug(f"Teg Agent: Executing logic_check for tool: {tool.name} with args: {args}")
#     return None

# def after_tool_routing_teg(tool: BaseTool, args: Dict[str, Any], tool_context: ToolContext, tool_response: Any):
#     # SessionUtils.log_after_tool() # Ensure SessionUtils is available
#     logger.debug(f"Teg Agent: Executing after_tool_routing for tool: {tool.name}. Output: {tool_response}")
#     return None
# --- End Callbacks ---

def create_teg_agent(
        model_name: str = MODEL, # Use the global MODEL config
        name: str = "teg_android_assistant",
        global_instructions: str = TegPrompts.GLOBAL_PROMPT,
        instruction: str = TegPrompts.TEG_ASSIST_MAIN,
        tools_list: List[BaseTool] = None, # Allow overriding tools for testing
        sub_agents_list: List[Agent] = None
        ) -> Agent:
    """Factory method to create a configured Teg Agent instance."""

    default_tools = [
            greeting,
            get_current_datetime_tool,
            custom_web_search,
            web_content_summarizer,
            search_live_teg_catalog, # Now uses the local JSON-backed implementation
            request_visual_input,
            affirmative,
            update_crm,
            book_ticket,
            adjust_seat_temp
    ]
    
    default_sub_agents = [] # No default sub-agents for Teg in this design

    # Use provided lists or defaults
    final_tools = tools_list if tools_list is not None else default_tools
    final_sub_agents = sub_agents_list if sub_agents_list is not None else default_sub_agents

    # Deduplication logic if SessionUtils was intended for it (currently commented out in R2)
    # from ...session_utils import SessionUtils # Make sure this path is correct
    # final_tools = SessionUtils.dedupe_lists(default_tools, tools_list or [])
    # final_sub_agents = SessionUtils.dedupe_lists(default_sub_agents, sub_agents_list or [])


    logger.info(f"Creating Teg agent '{name}' with {len(final_tools)} tools using model '{model_name}'.")
    logger.info(f"Catalog search tool 'search_live_teg_catalog' is configured to use local JSON data.")

    agent = Agent(
        model=model_name, 
        name=name,
        global_instruction=global_instructions,
        instruction=instruction,
        tools=final_tools,
        sub_agents=final_sub_agents,
    )

    # Assign callbacks if defined and needed (ensure SessionUtils is correctly imported if used)
    # agent.before_tool_callback = logic_check_teg
    # agent.after_tool_callback = after_tool_routing_teg
    # agent.before_model_callback = SessionUtils.log_before_model # Ensure SessionUtils is available
    # agent.after_model_callback = SessionUtils.log_after_model  # Ensure SessionUtils is available

    return agent=== ./server/core/agents/teg/examples.py ===
# ./server/core/agents/teg/examples.py

class TegExamples:
    # Using __ASSISTANT_NAME__ and __BRAND_NAME__ as placeholders,
    # will be replaced by values from TegContext in prompts.py
    # __CUSTOMER_FIRST_NAME__ will also be replaced.

    GREETING_AND_GENERAL_QUERY = """
<Example>
[USER]:
Hi Evie!

[MODEL]:
Hello __CUSTOMER_FIRST_NAME__! I'm __ASSISTANT_NAME__, your __BRAND_NAME__ Android Assistant. How can I help you with your queries about all the exciting events today?

[USER]:
What's R&B?

[MODEL]:
That's a great question! R&B in music stands for Rhythm and Blues. It's a popular genre that originated in African American communities in the 1940s. It blends elements of blues, jazz, and gospel music, often characterized by strong rhythms, soulful vocals, and emotionally expressive lyrics. Over time, R&B has evolved significantly, influencing and incorporating elements from other genres like soul, funk, disco, hip hop, and pop.
</Example>
"""

    SPECIFIC_QUERY_WITH_WEB_SEARCH = """
<Example>
[USER]:
what gigs are coming up? I really like Drake.?

[MODEL]:
Okay, __CUSTOMER_FIRST_NAME__, I can Let me check the _BRAND_NAME_ catalog for you..
```tool_code
print(search_live_teg_catalog(search_term='Drake'))
```
```tool_outputs
{"search_results": [{}"Artist": "Drake", "Time": "14 July 2025", "Country": "Australia", "City": "Hunter Valley", "Venue": "QIRKZ in The Hunter", "Price starting from": "$89.90"}]}
```

I found an upcoming event of Drake. The concert will be held on 14 July 2025 in Hunter Valley Australia. 
"""

    DEVICE_UPGRADE_ASSISTANCE = """
<Example>
[USER]:
I'm thinking of upgrading my phone. What new Android phones does Teg have?


[MODEL]:
That's exciting, __CUSTOMER_FIRST_NAME__! I can definitely help you with that. What kind of features are you looking for in a new Android phone, or do you have a budget in mind? This will help me narrow down the options from the _BRAND_NAME_ catalog.

[USER]:
I want something with a great camera, maybe a Samsung.

[MODEL]:
Okay, a Samsung with a great camera! Let me check the _BRAND_NAME_ catalog for you.

```tool_code
print(search_teg_android_catalog(search_criteria='Samsung great camera'))
```
```tool_outputs
{"devices": [{"id": "opt001", "name": "Samsung Galaxy S24 Ultra", "price": 1899.00, "key_features": ["200MP Camera", "Snapdragon 8 Gen 3", "S Pen"], "product_url": "https://www.teg.com.au/mobile-phones/mobiles-on-a-plan/samsung/galaxy-s24-ultra", "image_url": "https://images.samsung.com/is/image/samsung/assets/au/smartphones/galaxy-s24-ultra/images/galaxy-s24-ultra-highlights-kv.jpg"}, {"id": "opt003", "name": "Samsung Galaxy A55", "price": 699.00, "key_features": ["Great Value", "120Hz AMOLED Display", "50MP Camera"], "product_url": "https://www.teg.com.au/mobile-phones/mobiles-on-a-plan/samsung/galaxy-a55", "image_url": "..."}]}
```

I found a couple of excellent Samsung options for you at _BRAND_NAME_!
For top-of-the-line camera performance, there's the Samsung Galaxy S24 Ultra. It features an incredible 200MP camera and the powerful Snapdragon 8 Gen 3 chip. It's priced at $1899.00.
If you're looking for great value with a very good camera, the Samsung Galaxy A55 has a 50MP camera and a smooth 120Hz AMOLED display, priced at $699.00.
Would you like to know more about either of these, or perhaps see other options? You can find more details on the S24 Ultra here: https://www.teg.com.au/mobile-phones/mobiles-on-a-plan/samsung/galaxy-s24-ultra

[USER]:
The S24 Ultra sounds interesting. Can you tell me more?

[MODEL]:
Absolutely! The Samsung Galaxy S24 Ultra is a real powerhouse. Besides the 200MP main camera, it also includes advanced zoom capabilities, the latest Snapdragon 8 Gen 3 processor for super-fast performance, a beautiful large display, and it even comes with an S Pen for productivity. It's designed for users who want the absolute best in mobile technology. It's available at _BRAND_NAME_ for $1899.00. Would you like to explore contract options or compare it with another device?
</Example>
"""

    VISUAL_TROUBLESHOOTING = """
<Example>
[USER]:
My phone screen looks weird, it has lines on it.


[MODEL]:
Oh, I'm sorry to hear that, __CUSTOMER_FIRST_NAME__. Lines on the screen can be concerning. To help me understand what's going on, would you be able to show me?

```tool_code
print(request_visual_input(reason_for_request='to check your phone screen'))
```
```tool_outputs
{"status": "visual_input_requested", "reason": "to check your phone screen", "message_to_user": "Okay, to help with 'to check your phone scree', could you please show it to me using your camera or by uploading an image?"}
```

Okay, to help me check your phone screen, could you please show it to me using your camera or by uploading an image?

[USER]:
(User shows the mobile phone screen to the camera.)
Hey, I'm showing my phone screen to you. 

[MODEL]:
Thank you for showing your phone screen to me via the camera, __CUSTOMER_FIRST_NAME__. I can see the horizontal lines on your screen. That does look unusual. This could sometimes be related to a loose display cable, a software glitch, or unfortunately, a hardware issue with the screen itself.
Have you tried restarting your phone yet? Sometimes a simple restart can resolve temporary display glitches.

[USER]:
No, I haven't. Should I try that?

[MODEL]:
Yes, please do. A restart is a good first troubleshooting step. Let me know if that makes any difference to the lines on the screen.
</Example>
"""
    CLOSING_CONVERSATION = """
<Example>
[USER]:
That's all the help I needed, thank you Evie!

[MODEL]:
You're very welcome, CUSTOMER_FIRST_NAME! I'm glad I could assist you today. Feel free to reach out if you have more event questions. Have a great day!

```tool_code
print(update_crm(customer_id='__CUSTOMER_FIRST_NAME__', details='Assisted with customer's queries about music events. Customer satisfied.'))
```
```tool_outputs
{'status': 'success', 'message': 'CRM record updated.'}
```
</Example>
"""
=== ./server/core/agents/teg/prompts_orig.py ===
# ./server/core/agents/teg/prompts.py
from .examples import TegExamples
from .context import TegContext # To get default customer name, brand name, and potentially catalog access if needed by examples

# Get dynamic values from context for placeholders
assistant_name = TegContext.CUSTOMER_PROFILE.get("assistant_name", "Teg")
brand_name = TegContext.CUSTOMER_PROFILE.get("brand_name", "Teg")
customer_first_name = TegContext.CUSTOMER_PROFILE.get("customer_profile", {}).get("first_name", "Valued Customer")
allowed_search_domains_str = ", ".join(TegContext.CUSTOMER_PROFILE.get("allowed_search_domains", []))


# Compile examples with dynamic values
_greeting_example = TegExamples.GREETING_AND_GENERAL_QUERY.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_specific_query_example = TegExamples.SPECIFIC_QUERY_WITH_WEB_SEARCH.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
# Note: _upgrade_example uses search_teg_android_catalog and its old output format.
# This example is not being modified as per user request, but will be inconsistent with the new search_live_teg_catalog.
_upgrade_example = TegExamples.DEVICE_UPGRADE_ASSISTANCE.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_visual_troubleshooting_example = TegExamples.VISUAL_TROUBLESHOOTING.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)
_closing_example = TegExamples.CLOSING_CONVERSATION.replace("__ASSISTANT_NAME__", assistant_name).replace("__BRAND_NAME__", brand_name).replace("__CUSTOMER_FIRST_NAME__", customer_first_name)


class TegPrompts:
    GLOBAL_PROMPT = f"""
You are an AI assistant named {assistant_name} for {brand_name}.
The current datetime is: {{current_datetime}}.
The profile of the current customer is: {{customer_profile}}.
Your current language for all interactions is: {{language}}
DEBUG: Current Session ID is: {{session_id}}.
You are acting as an in-store live expert at a local {brand_name} store.
Be friendly, knowledgeable, and proactive in helping customers with their Android smartphones.

**Pronunciation Guide:**
*   When you encounter "gsmarena.com" in text or search results, you should pronounce it as "G.S.M. Arena dot com".
"""

    TEG_ASSIST_MAIN = f"""
You are {assistant_name}, a multimodal Android Assistant for {brand_name}. Your goal is to provide an experience similar to an in-store live expert.
You assist customers with Android smartphone usage, troubleshooting, and finding new Android devices available through {brand_name}.

**Core Capabilities & Workflow:**

1.  **Greeting & Introduction:**
    *   Start by warmly greeting the user by their first name (e.g., "Hello {{customer_profile.first_name}}!").
    *   Introduce yourself: "I'm {assistant_name}, your {brand_name} Android Assistant."
    *   Ask how you can help with their Android needs: "How can I help you with your Android needs today?"

2.  **Understand User Query:**
    *   Listen carefully to the user's query ($user_query).

3.  **Determine Query Type (Internal Logic - Do not state this classification to the user):**
    *   **General Query:** If the query is about general Android features, usage tips, common troubleshooting steps (e.g., 'how to take a screenshot', 'explain battery saving mode', 'my phone is slow'). This may or may not require a quick web search for broader, less time-sensitive information.
    *   **Specific Query:** If the query requires in-depth, up-to-date information on a specific phone model, its features, comparisons, or news, especially with a time component (e.g., 'latest reviews for Pixel X camera', 'compare Samsung Galaxy S2Y vs Pixel Z focusing on battery life', 'when is Android version ABC releasing for phone X'). This will typically require web search followed by summarization of a specific page.
    *   **Teg Catalog Query:** If the user expresses clear interest in purchasing or upgrading to a new phone *specifically through {brand_name}*, or asks about phone availability, pricing, or deals *at {brand_name}* (e.g., 'I want to upgrade my phone with {brand_name}', 'what {brand_name} have on Samsung phones?', 'check availability of Pixel 8 Pro at {brand_name}').
    *   **Visual Troubleshooting Query:** If the user describes a visual problem or you need to see something on their device/environment.

4.  **Handling Query Types:**

    *   **If General Query:**
        *   Provide a comprehensive, friendly, and easy-to-understand answer using your general knowledge about Android.
        *   If your own knowledge is insufficient or the query might benefit from broader, less time-sensitive information (e.g., common solutions to 'phone is slow'), you can use the `custom_web_search` tool.
        *   If using search, inform the user: "Let me quickly check that for you."
        *   After search, synthesize information if found, or state if nothing specific was found.
        *   If search results were used, inform the user: "I found this information using a web search. I can show you the source articles or provide links if you'd like." Do NOT read out the URLs unless the user specifically asks for a URL to be read. If co-browsing is possible, offer to navigate to the page.

    *   **If Specific Query (Requires Web Search and Summarization):**
        *   Inform the user: "Okay, I'll need to look up some detailed information on that for you. One moment."
        *   Call the `custom_web_search` tool with the $user_query.
            *   The search should ideally prioritize information from: {allowed_search_domains_str}.
        *   Examine the `search_results` from the tool:
            *   If `search_results` is empty or contains no relevant snippets, inform the user: "I couldn't find specific information for your query right now."
            *   If snippets provide a clear answer: Synthesize the information from the relevant snippets. Present this summarized answer.
                *   Then, inform the user: "I found this information using a web search. I can show you the source articles or provide links if you'd like." Do NOT read out the URLs unless the user specifically asks for a URL to be read. If co-browsing is possible, offer to navigate to the page.
            *   If snippets are insufficient but a promising `link` exists: Inform the user: "I found a relevant page. Processing its content might take a few moments, so I appreciate your patience." Then, call `web_content_summarizer` with the `top_url`.
                *   If `summary` is returned: Present the `summary`.
                    *   Then state: "This summary is from a webpage. I can show you the page or provide the link if you're interested." Do NOT read out the URL unless specifically asked. If co-browsing is possible, offer to navigate to the page.
                *   If summarizer fails or returns empty: Say, "I found a potentially relevant page but couldn't summarize it effectively. I can show you the page or provide the link if you'd like to check it yourself." (Offer co-browsing if available).

    *   **If Teg Catalog Query:**
        *   Acknowledge their interest: "That's exciting! I can help you with finding a new Android phone through {brand_name}."
        *   If the user's query already has a specific Android phone model they are interested in with {brand_name}, proceed to the next step. Otherwise, ask clarifying questions to understand their needs: "What kind of things are you looking for in a new phone? For example, do you have a preferred brand, a specific model, particular colors, or storage size in mind?"
        *   Based on their response, formulate a `search_term` (e.g., "Samsung phones", "Pixel 8 Pro 256GB", "blue Samsung phones", "Samsung 512GB").
        *   Inform the user: "Let me check the current {brand_name} catalog for you. This may take a few seconds."
        *   Call the `search_live_teg_catalog` tool with the `search_term`. This tool queries the {brand_name} phone catalog (from local data) and returns JSON data.
        *   The JSON response for each device will include fields like: `deviceName`, `price` (usually outright price if available, or monthly), `productURL`, `stockStatus`, and `keyFeatures` (which will typically list available colors and storage options). `imageURL` will not be provided by this tool.
        *   **Note on tool usage:** Use this tool *primarily* when the user is interested in {brand_name} availability, pricing, or purchasing/upgrading through {brand_name}. For general information about phone models not tied to an {brand_name} transaction, prefer 'Specific Query' handling.
        *   Examine the response:
            *   If the tool returns `None` or an empty list of devices in the `devices` field, or a `message` indicating no devices were found: Inform the user, "I couldn't find any devices matching that exact description in the {brand_name} catalog right now. Would you like to try a broader search, or perhaps describe what you're looking for in a different way?"
            *   If devices are found (JSON response with a list in the `devices` field):
                *   Select 1-2 top recommendations from the returned list.
                *   For each recommendation, present the information clearly. Use the `keyFeatures` (which list colors and storage) in your description. Example: "Based on what you're looking for, the [Device Name] at [Price] could be a great fit. It's available in colors like [mention some colors from keyFeatures] and with storage options such as [mention storage from keyFeatures]. Currently, its status is [Stock Status]."
                *   Mention the availability of more details: "You can find more specifications and details on the {brand_name} website."
                *   If a `productURL` is available in the JSON, state: "I can help you view this device on the {brand_name} website if you'd like." (This enables co-browsing. Do NOT read the URL unless asked).
                *   Since `imageURL` is not provided by the tool, you can say: "Images of the device are available on the product page on the {brand_name} website."
                *   Offer to discuss other options from the search, provide more details on a specific phone from the JSON, or refine the search. Example: "Would you like to know more about this phone, see other options from {brand_name}, or refine your search?"

    *   **If Visual Troubleshooting Query (or you need to see something):**
        *   Explain why you need to see it: "To better understand the [issue/item], it would be helpful if I could see it."
        *   Call the `request_visual_input` tool, providing a clear `reason_for_request`.
        *   The tool will output a message like: "Okay, to help with '[reason_for_request]', could you please show it to me using your camera or by uploading an image?" You should say this message to the user.
        *   **STOP your turn and wait for the user to provide the image/video.**
        *   When image/video data is received (it will appear as user input, likely a blob):
            *   Acknowledge receipt: "Thanks for sending that over! Let me take a look."
            *   Analyze the visual information in the context of the user's problem and continue troubleshooting or providing advice. (e.g., "I see the error message now. It looks like...")

5.  **Follow-Up:**
    *   After providing an answer or assistance, always ask: "Is there anything else I can help you with regarding your Android smartphone or {brand_name} services today, {{customer_profile.first_name}}?" or "Does that help answer your question?"

6.  **Loop or Conclude:**
    *   If the user has more questions (use `affirmative()` tool if they just say "yes" to needing more help), go back to step 2.
    *   If the user indicates they are satisfied or have no more questions (e.g., "no, that's all", "thank you"):
        *   Offer a polite closing: "You're welcome, {{customer_profile.first_name}}! I'm glad I could help. Feel free to reach out if you have more Android questions in the future. Have a great day!"
        *   Call `update_crm` tool with `customer_id` (use `{{customer_profile.first_name}}` or a session identifier if available) and a brief `details` summary of the interaction.
        *   End the conversation.

**Tool Usage Guidelines:**
*   Use tools proactively.
*   Do not mention internal tool names. Refer to the action (e.g., "I'm checking the catalog," "I'll search for that," "Let me request a visual").
*   If a tool call is for an action the user should be aware of (like `request_visual_input`), inform them before or as part of the tool's output message.

**Interaction Style:**
*   Be friendly, empathetic, patient, and professional.
*   Keep responses concise but comprehensive.
*   If the user provides an image/video, analyze it and incorporate your findings into your response.

<Examples>
{_greeting_example}
{_specific_query_example}
{_upgrade_example}
{_visual_troubleshooting_example}
{_closing_example}
</Examples>

Begin!
"""=== ./server/core/logger.py ===
import os
import logging

from dotenv import load_dotenv
load_dotenv()

LOG_LEVEL=os.getenv('LOG_LEVEL', 'INFO').upper()
LOG_TO_FILE= True if (os.getenv('LOG_TO_FILE', False) == "true") else False
LOG_FILE_NAME=os.getenv('LOG_FILE_NAME', "debug_messages.log")

print(f"LOG_LEVEL: {os.getenv('LOG_LEVEL')}")

if LOG_TO_FILE:
    logging.basicConfig(
        filename=LOG_FILE_NAME,
        level=getattr(logging, LOG_LEVEL),
        format="%(asctime)s - [%(filename)s:%(lineno)d] - %(levelname)s - %(message)s",
        force=True
    )
else:
    logging.basicConfig(
        level=getattr(logging, LOG_LEVEL),
        format="%(asctime)s - [%(filename)s:%(lineno)d] - %(levelname)s - %(message)s",
        force=True
    )

logger = logging.getLogger(__name__)
=== ./server/config/config.py ===
"""
Configuration for Vertex AI Gemini Multimodal Live Proxy Server
"""

import os
import warnings
from typing import Optional

from dotenv import load_dotenv
from google.adk.agents import RunConfig
from google.api_core.client_options import ClientOptions
from google.cloud import secretmanager
from google.cloud import texttospeech_v1beta1 as tts
from google.genai import types

warnings.filterwarnings("ignore", category=UserWarning)

from core.logger import logger

# Load environment variables
load_dotenv()

PROJECT_ID = os.environ.get("PROJECT_ID", "next-2025-ces")
LOCATION = os.environ.get("VERTEX_LOCATION", "us-central1")
DEMO_TYPE = os.environ.get("DEMO_TYPE", "retail")
FIRST_NAME = os.environ.get("FIRST_NAME", "Patrick")
LAST_NAME = os.environ.get("LAST_NAME", "Marlow")
MODEL_NAME = os.environ.get("MODEL", "gemini-2.0-flash-live-001")

logger.info(f"FIRST_NAME: {FIRST_NAME}")
logger.info(f"LAST_NAME: {LAST_NAME}")
logger.info(f"DEMO_TYPE: {DEMO_TYPE}")
logger.info(f"PROJECT_ID: {PROJECT_ID}")
logger.info(f"LOCATION: {LOCATION}")
logger.info(f"MODEL_NAME: {MODEL_NAME}")

# Model and Voice Globals
MODEL = os.getenv("MODEL", "gemini-2.0-flash-001")
VOICE = os.getenv("VOICE", "Aoede")
MODEL_LANGUAGE = os.getenv("MODEL_LANGUAGE", "en-US")
PROMPT_LANGUAGE = os.getenv("PROMPT_LANGUAGE", None)
ACCENT_LANGUAGE = os.getenv("ACCENT_LANGUAGE", None)

USE_TTS = True if os.environ.get("USE_TTS", False) == "true" else False
TTS_LOCATION = os.environ.get("TTS_LOCATION", "global")
TTS_ENDPOINT = (
    f"{TTS_LOCATION}-texttospeech.googleapis.com"
    if TTS_LOCATION != "global"
    else "texttospeech.googleapis.com"
)
logger.info(f"USE_TTS: {USE_TTS}")


class ConfigurationError(Exception):
    """Custom exception for configuration errors."""

    pass


def get_secret(secret_id: str) -> str:
    """Get secret from Secret Manager."""
    client = secretmanager.SecretManagerServiceClient()
    project_id = PROJECT_ID

    if not project_id:
        raise ConfigurationError("PROJECT_ID environment variable is not set")

    name = f"projects/{project_id}/secrets/{secret_id}/versions/latest"

    try:
        response = client.access_secret_version(request={"name": name})
        return response.payload.data.decode("UTF-8")
    except Exception:
        raise


class ApiConfig:
    """API configuration handler."""

    def __init__(self):
        use_vertex_env = os.getenv("GOOGLE_GENAI_USE_VERTEXAI", "1")
        if use_vertex_env.lower() == "true":
            self.use_vertex = 1
        elif use_vertex_env.lower() == "false":
            self.use_vertex = 0
        else:
            self.use_vertex = int(use_vertex_env)

        self.api_key: Optional[str] = None
        self.tts_client: tts.TextToSpeechClient = self.init_tts_client()

        logger.info(f"Initialized API configuration with Vertex AI: {self.use_vertex}")

    async def initialize(self):
        """Initialize API credentials."""
        if not self.use_vertex:
            try:
                self.api_key = get_secret("GOOGLE_API_KEY")
            except Exception as e:
                logger.warning(f"Failed to get API key from Secret Manager: {e}")
                self.api_key = os.getenv("GOOGLE_API_KEY")
                if not self.api_key:
                    raise ConfigurationError(
                        "No API key available from Secret Manager or environment"
                    )

    def init_tts_client(self):
        """Initialize TTS client."""
        try:
            tts_client = tts.TextToSpeechClient(
                client_options=ClientOptions(api_endpoint=TTS_ENDPOINT)
            )
            logger.info(f"TTS Client initialized for endpoint: {TTS_ENDPOINT}")
        except Exception as e:
            logger.exception(f"Failed to initialize TTS client: {e}")
            tts_client = None  # Handle cases where TTS might not be available

        return tts_client

    def get_tts_streaming_config(self):
        """Return the TTS streaming config."""
        if not self.tts_client:
            logger.warning("TTS client not available, cannot get streaming config.")
            return None

        TTS_VOICE = f"{MODEL_LANGUAGE}-Chirp3-HD-{VOICE}"

        try:
            streaming_config = tts.StreamingSynthesizeConfig(
                voice=tts.VoiceSelectionParams(
                    name=TTS_VOICE, language_code=MODEL_LANGUAGE
                )
            )
        except Exception as e:
            logger.exception(f"Failed to initialize TTS Config: {e}")

        return streaming_config


# Initialize API configuration
api_config = ApiConfig()

if USE_TTS:
    # Temp: 2 newest voices are not supported across all langauges yet
    # As of 4/23/25 the 2 newest voices are only supported in en-US
    if VOICE in ["Achernar", "Sulafat"] and MODEL_LANGUAGE != "en-US":
        raise ConfigurationError(
            f"Voice `{VOICE}` only supported in `en-US` for TTS at this time."
        )

    RUN_CONFIG = RunConfig(
        response_modalities=["TEXT"],
    )

    logger.info(f"TTS VERSION: {tts.__version__}")
    logger.info(
        f"Using Cloud TTS for Audio Out and voice `{VOICE}`. language_code=`{MODEL_LANGUAGE}`"
    )

else:
    # Temp: Raise if voice selection is in non-supported Live API Audio Out
    # As of 4/23/25 there are still 2 voices that are not supported
    if VOICE in ["Achernar", "Sulafat"]:
        raise ConfigurationError(
            f"Voice `{VOICE}` is currently not supported in Live API. Set USE_TTS=true if you want to use this voice."
        )

    RUN_CONFIG = RunConfig(
        response_modalities=["AUDIO"],
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfigDict(
                {"prebuilt_voice_config": {"voice_name": VOICE}}
            ),
            language_code=MODEL_LANGUAGE,
        ),
        #enable_affective_dialog=True,
        #proactivity=types.ProactivityConfig(proactive_audio=True),
    )

    logger.info(
        f"Using Live API for Audio Out and voice `{VOICE}`. language_code=`{MODEL_LANGUAGE}`"
    )

TTS_CLIENT = api_config.tts_client
TTS_CONFIG = api_config.get_tts_streaming_config()
=== ./server/combined_server.py ===
# ./server/server.py

"""
Combined HTTP/WebSocket Server Entry Point for Cloud Run using aiohttp.
Handles HTTP callbacks and delegates WebSocket connections to websocket_handler.handle_client.
"""

import asyncio
import json
import os

# Use aiohttp for both HTTP and WebSockets
from aiohttp import WSCloseCode, web
from core.logger import logger

# Type hinting and utils needed for the callback handler
from core.session_state import SessionState
from core.session_utils import SessionUtils

# Import necessary components from core modules
from core.websocket_handler import (
    ACTIVE_SESSIONS,  # Needed for callback handler
    handle_client,  # The original entry point for WS logic, now adapted for aiohttp
)


# --- HTTP Callback Handler (Unchanged from your original working version) ---
async def handle_callback(request: web.Request):
    """Handles HTTP POST requests to the /callback endpoint."""
    logger.info(f"Received callback request at {request.path}")
    raw_data_decoded = "<Could not read body>"
    try:
        raw_data = await request.read()
        raw_data_decoded = raw_data.decode("utf-8", errors="ignore")
        logger.info(f"Raw request body: {raw_data_decoded}")
    except Exception as e:
        logger.exception(f"Error reading request body: {e}")

    try:
        data = await request.json()
        logger.info(f"Callback Request data: {data}")
        session_id = data.get("requestId")

        if not session_id:
            logger.error("Callback missing session_id (requestId)")
            return web.json_response(
                {"error": "Missing session_id (requestId)"}, status=400
            )

        session: SessionState = ACTIVE_SESSIONS.get(session_id)
        if not session:
            logger.error(f"Callback received for invalid session_id: {session_id}")
            return web.json_response({"error": "Invalid session_id"}, status=404)

        # Inject the callback data into the session's request queue.
        logger.info(f"Injecting callback data into session {session_id}")
        content = data.get("agentMessage", "Callback received, processing.")
        manager_approved = data.get("manager_approved", True)

        # Update session state
        session.session.state["manager_approved"] = manager_approved
        session.live_request_queue.send_content(
            SessionUtils.model_response(text=content)
        )

        return web.json_response({"status": "success"})

    except json.JSONDecodeError:
        logger.error(f"Invalid JSON received in callback: {raw_data_decoded}")
        return web.json_response({"error": "Invalid JSON"}, status=400)
    except Exception as e:
        logger.exception(f"Error handling callback: {e}")
        return web.json_response({"error": "Internal server error"}, status=500)


# --- WebSocket Connection Handler (Delegates to handle_client) ---
async def handle_websocket_entrypoint(request: web.Request):
    """
    Accepts incoming WebSocket connections and delegates handling to
    core.websocket_handler.handle_client (adapted for aiohttp).
    """
    heartbeat_interval = 25.0
    ws = web.WebSocketResponse(heartbeat=heartbeat_interval)
    connection_id = str(id(ws))  # Unique ID for logging this specific socket attempt
    try:
        # Prepare the WebSocket handshake (upgrades connection)
        await ws.prepare(request)
        logger.info(
            f"WebSocket connection prepared (handshake successful) for connection_id: {connection_id}, heartbeat={heartbeat_interval}s"
        )

        # --- Delegate to the adapted handle_client ---
        # Pass the established aiohttp WebSocketResponse object
        await handle_client(ws)

        # Log when the handler function returns control (implies connection ended)
        logger.info(f"handle_client finished for connection_id: {connection_id}")

    except asyncio.CancelledError:
        logger.info(
            f"WebSocket connection handler cancelled for connection_id: {connection_id}."
        )
        if not ws.closed:
            await ws.close(
                code=WSCloseCode.GOING_AWAY, message=b"Server cancelling connection"
            )
    except Exception as e:
        # Catch errors during ws.prepare() or if handle_client raises unexpectedly
        logger.exception(
            f"Unhandled error in WebSocket entrypoint for connection_id {connection_id}: {e}"
        )
        if not ws.closed:
            await ws.close(
                code=WSCloseCode.INTERNAL_ERROR,
                message=b"Internal server error during connection handling",
            )

    logger.info(
        f"WebSocket connection processing fully completed for connection_id: {connection_id}"
    )
    return ws  # Return the WebSocketResponse


# --- Main Application Setup ---
async def main() -> None:
    """Starts the combined aiohttp server for HTTP and WebSocket."""
    # Get port from environment variable for Cloud Run, default to 8080 locally
    port = int(os.environ.get("PORT", 8080))

    app = web.Application()

    # Add routes
    app.router.add_post("/callback", handle_callback)
    app.router.add_get("/ws", handle_websocket_entrypoint)  # WebSocket endpoint

    runner = web.AppRunner(app)
    await runner.setup()

    # Listen on 0.0.0.0 to be accessible from Cloud Run's proxy
    site = web.TCPSite(runner, "0.0.0.0", port)
    await site.start()

    logger.info(f"Running combined HTTP/WebSocket server on 0.0.0.0:{port}...")
    logger.info("WebSocket endpoint available at /ws")
    logger.info("HTTP callback endpoint available at /callback")

    # Keep the server running indefinitely
    await asyncio.Future()


if __name__ == "__main__":
    # Ensure logger is configured before running
    logger.info("Starting server...")
    asyncio.run(main())
=== ./server/secret_manager.py ===
import json
import logging
import os

from google.auth.transport.requests import Request  # type: ignore
from google.cloud import secretmanager
from google.oauth2.credentials import Credentials  # type: ignore
from google_auth_oauthlib.flow import InstalledAppFlow  # type: ignore
from googleapiclient.discovery import build  # type: ignore

logger = logging.getLogger(__name__)

PROJECT_ID = "argolis-jasper-3"
LOCATION = "us-central1"

def get_secret(secret_id, project_id):
    client = secretmanager.SecretManagerServiceClient()
    name = f"projects/{project_id}/secrets/{secret_id}/versions/latest"
    response = client.access_secret_version(name=name)
    return response.payload.data.decode("UTF-8")

class GmailClient:
    # If modifying these scopes, delete the file token.json.
    SCOPES = [
        "https://www.googleapis.com/auth/gmail.readonly",  # Read-only access
        "https://www.googleapis.com/auth/gmail.modify",  # Read and modify but not delete
        "https://www.googleapis.com/auth/gmail.compose",  # Create/send emails
        "https://www.googleapis.com/auth/gmail.labels",  # Manage labels
    ]

    def __init__(
        self, credentials_path="credentials.json", token_path="gmail_token.json"
    ):
        self.credentials_path = credentials_path
        self.token_path = token_path
        self.service = self._authenticate()

    def _authenticate(self):
        """Authenticate with Gmail API using OAuth 2.0"""
        creds = None

        # Fetch credentials from Secret Manager if specified
        if self.credentials_path.startswith("secret:"):
            # Format: secret:SECRET_ID:PROJECT_ID
            _, secret_id, project_id = self.credentials_path.split(":")
            credentials_json = get_secret(secret_id, project_id)
            credentials_info = json.loads(credentials_json)
            flow = InstalledAppFlow.from_client_config(credentials_info, self.SCOPES)
            creds = flow.run_local_server(port=0)
        else:
            # If token_path is a secret, fetch and write to file
            if self.token_path.startswith("secret:"):
                _, token_secret_id, token_project_id = self.token_path.split(":")
                token_json = get_secret(token_secret_id, token_project_id)
                # Write the token to a file for use by Credentials
                with open("gmail_token.json", "w") as token_file:
                    token_file.write(token_json)
                token_path_to_use = "gmail_token.json"
            else:
                token_path_to_use = self.token_path

            # Load existing credentials if available
            if os.path.exists(token_path_to_use):
                creds = Credentials.from_authorized_user_file(token_path_to_use, self.SCOPES)

            # If no valid credentials, authenticate user
            if not creds or not creds.valid:
                if creds and creds.expired and creds.refresh_token:
                    creds.refresh(Request())
                else:
                    flow = InstalledAppFlow.from_client_secrets_file(
                        self.credentials_path, self.SCOPES
                    )
                    # Set token expiry to 1 year
                    flow.oauth2session.expires_in = (
                        24 * 60 * 60 * 365
                    )  # 365 days in seconds
                    creds = flow.run_local_server(port=0)

                # Save credentials for future use
                with open(token_path_to_use, "w") as token:
                    token.write(creds.to_json())

        logger.info(f"Credentials: {creds}")
        return build("gmail", "v1", credentials=creds)
    
if __name__ == "__main__":

    # data = get_secret("gmail-token", PROJECT_ID)
    # print(data)

    gmail = GmailClient(credentials_path="credentials.json")
=== ./client/optus-home.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link rel="stylesheet" href="styles/style-teg-home.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="header">
        <div class="header-left">
            <img src="assets/optus_logo.svg" alt="Optus Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search phones, plans, NBN broadband, 5G...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <nav class="navbar">
        <ul class="nav-list">
            <li><a href="#">Featured</a></li>
            <li><a href="#">Sports</a></li>
            <li><a href="#">Concerts</a></li>
            <li><a href="#">Theatre & Arts</a></li>
            <li><a href="#">Family</a></li>
            <li><a href="#">Comedy</a></li>
            <li><a href="#">Premium Tickets</a></li>
            <li class="dropdown">
                <a href="#">Last Minute <span class="arrow-down">&#9662;</span></a>
                <div class="dropdown-content">
                    <a href="#">Today</a>
                    <a href="#">Tomorrow</a>
                    <a href="#">This Weekend</a>
                </div>
            </li>
            <li><a href="#">Where's My Ticket?</a></li>
        </ul>
    </nav>

    <main class="main-content">
        <div class="poster-grid">
            <a href="#" class="poster-item">
                <img src="assets/samsung-z-fold-6.png" alt="Samsung Galaxy Z Fold6">
                <div class="poster-title">Samsung Galaxy Z Fold6</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro-Fold.png" alt="Google Pixel 9 Pro Fold">
                <div class="poster-title">Google Pixel 9 Pro Fold</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro-XL.png" alt="Google Pixel 9 Pro XL">
                <div class="poster-title">Google Pixel 9 Pro XL</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9a.png" alt="Google Pixel 9a">
                <div class="poster-title">Google Pixel 9a</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro.png" alt="Google Pixel 9 Pro">
                <div class="poster-title">Google Pixel 9 Pro</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-8a.png" alt="Google Pixel 8a">
                <div class="poster-title">Google Pixel 8a</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9.png" alt="Google Pixel 9">
                <div class="poster-title">Google Pixel 9</div>
            </a>
        </div>
    </main>
</body>
</html>=== ./client/index.html ===

<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">

  <!-- Load Optus's specific stylesheet for proper rendering -->
  <link rel="stylesheet" href="styles/style-teg-home.css"> 
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Optus Homepage (70%) -->
    <div id="optus-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Optus content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    //const api = new GeminiAPI('wss://live141-teg-agent-backend-combined-927033137380.us-central1.run.app/ws'); // Cloud Run single server, multi port setup
    const api = new GeminiAPI('ws://127.0.0.1:8080/ws');

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      // You can add more function call handling here if needed
      // For example, if you had a function to load different content into the right frame:
      // if (data.name === 'load_page') {
      //   fetch(data.args.url)
      //     .then(response => response.text())
      //     .then(html => {
      //       const parser = new DOMParser();
      //       const doc = parser.parseFromString(html, 'text/html');
      //       const pageBody = doc.body.innerHTML;
      //       document.getElementById('optus-home').innerHTML = pageBody; // Changed from dyson-home to optus-home
      //     })
      //     .catch(err => {
      //       document.getElementById('optus-home').innerHTML = '<p style="color:red;">Failed to load content.</p>';
      //       console.error('Error loading content:', err);
      //     });
      // }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Handle API responses if necessary, for example, displaying updated information
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('optus-home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        // Extract only the content within the <body> tag of optus-home.html
        const optusBodyContent = doc.body.innerHTML;
        document.getElementById('optus-home').innerHTML = optusBodyContent;
      })
      .catch(err => {
        document.getElementById('optus-home').innerHTML = '<p style="color:red;">Failed to load optus content.</p>';
        console.error('Error loading optus content:', err);
      });
  </script>
</body>
</html>=== ./client/video.html ===
<div style="width: 100%; height: 100%; display: flex; justify-content: center; align-items: center; background-color: #000;">
  <iframe id="youtube-video" 
          style="width: 100%; max-width: 1280px; aspect-ratio: 16 / 9;"
          src="" 
          title="YouTube video player" 
          frameborder="0" 
          allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
          allowfullscreen>
  </iframe>
</div> === ./client/index-dyson-original.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Dyson Homepage (70%) -->
    <div id="dyson-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Dyson content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    //const api = new GeminiAPI('wss://live141-agent-backend-combined-671247654914.us-central1.run.app/ws'); // Cloud Run single server, multi port setup
    const api = new GeminiAPI('ws://127.0.0.1:8080/ws');

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      if (data.name === 'show_hair_dryer_models') {
        fetch('dyson_supersonic.html')
          .then(response => response.text())
          .then(html => {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, 'text/html');
            const dysonBody = doc.body.innerHTML;
            document.getElementById('dyson-home').innerHTML = dysonBody;
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson Supersonic content.</p>';
            console.error('Error loading Dyson Supersonic content:', err);
          });
      }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Check for appointment_id and show appointment.html if present
      if (data && data.appointment_id) {
        fetch('dyson_appointment.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            // Wait for DOM to update, then set the values
            setTimeout(() => {
              if (document.getElementById('appointmentId')) {
                document.getElementById('appointmentId').textContent = data.appointment_id;
              }
              if (document.getElementById('appointmentSlot')) {
                document.getElementById('appointmentSlot').textContent = data.scheduled_slot;
              }
            }, 0);
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Appointment content.</p>';
            console.error('Error loading Appointment content:', err);
          });
      }
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('dyson_home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        const dysonBody = doc.body.innerHTML;
        document.getElementById('dyson-home').innerHTML = dysonBody;
      })
      .catch(err => {
        document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson content.</p>';
        console.error('Error loading Dyson content:', err);
      });
  </script>
</body>
</html>=== ./client/index_xtelcom.html ===

<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">

  <!-- Load Xtelcom's specific stylesheet for proper rendering -->
  <link rel="stylesheet" href="styles/style-teg-home.css"> 
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Xtelcom Homepage (70%) -->
    <div id="xtelcom-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Xtelcom content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    //const api = new GeminiAPI('wss://live141-teg-agent-backend-combined-927033137380.us-central1.run.app/ws'); // Cloud Run single server, multi port setup
    const api = new GeminiAPI('ws://127.0.0.1:8080/ws');

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      // You can add more function call handling here if needed
      // For example, if you had a function to load different content into the right frame:
      // if (data.name === 'load_page') {
      //   fetch(data.args.url)
      //     .then(response => response.text())
      //     .then(html => {
      //       const parser = new DOMParser();
      //       const doc = parser.parseFromString(html, 'text/html');
      //       const pageBody = doc.body.innerHTML;
      //       document.getElementById('xtelcom-home').innerHTML = pageBody; // Changed from dyson-home to xtelcom-home
      //     })
      //     .catch(err => {
      //       document.getElementById('xtelcom-home').innerHTML = '<p style="color:red;">Failed to load content.</p>';
      //       console.error('Error loading content:', err);
      //     });
      // }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Handle API responses if necessary, for example, displaying updated information
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('xtelcom-home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        // Extract only the content within the <body> tag of xtelcom-home.html
        const xtelcomBodyContent = doc.body.innerHTML;
        document.getElementById('xtelcom-home').innerHTML = xtelcomBodyContent;
      })
      .catch(err => {
        document.getElementById('xtelcom-home').innerHTML = '<p style="color:red;">Failed to load xtelcom content.</p>';
        console.error('Error loading xtelcom content:', err);
      });
  </script>
</body>
</html>=== ./client/index_basic.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Live Agent Demo - ADK version</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body>
  <div class="header-section">
    <h1>Live Agent Demo - ADK version</h1>
    <p>Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
  </div>

  <div class="input-container">
    <button id="micButton" disabled class="action-button">
      <span class="material-symbols-outlined">mic</span>
    </button>
    <button id="webcamButton" class="action-button">
      <span class="material-symbols-outlined">videocam</span>
    </button>
    <button id="screenButton" class="action-button">
      <span class="material-symbols-outlined">present_to_all</span>
    </button>
    <button id="imageButton" class="action-button">
      <span class="material-symbols-outlined">image</span>
    </button>
    <input type="file" id="imageInput" accept="image/*" style="display: none;">
    <div class="text-input-container">
      <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
      <button id="sendButton" class="action-button">
        <span class="material-symbols-outlined">send</span>
      </button>
      <button id="interruptButton" class="action-button" style="display: none;">
        <span class="material-symbols-outlined">cancel</span>
      </button>
    </div>
  </div>

  <div class="video-container">
    <video id="videoPreview" autoplay playsinline class="hidden"></video>
  </div>

  <div id="imagePreviewContainer" style="display: none;">
    <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
  </div>

  <div id="output"></div>

  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    // const api = new GeminiAPI(); // without specifing an endpoint it will try to call the 'ws://localhost:8081'
    const api = new GeminiAPI('wss://live141-agent-backend-combined-671247654914.us-central1.run.app/ws'); // remote endpoint example

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
    };

    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording() {
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML = 
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      
      // Stop video streams
      mediaHandler.stopAll();
      document.getElementById('webcamButton').innerHTML = 
        '<span class="material-symbols-outlined">videocam</span>';
      document.getElementById('screenButton').innerHTML = 
        '<span class="material-symbols-outlined">present_to_all</span>';
      
      api.sendEndMessage();
      api.isSpeaking = false;
    }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
</body>
</html>=== ./client/ticketek-home.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link rel="stylesheet" href="styles/style-teg-home.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="header">
        <div class="header-left">
            <img src="assets/Ticketek-Logo-White.svg" alt="Ticketek Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search artist, event, venue, location...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <nav class="navbar">
        <ul class="nav-list">
            <li><a href="#">Featured</a></li>
            <li><a href="#">Sports</a></li>
            <li><a href="#">Concerts</a></li>
            <li><a href="#">Theatre & Arts</a></li>
            <li><a href="#">Family</a></li>
            <li><a href="#">Comedy</a></li>
            <li><a href="#">Premium Tickets</a></li>
            <li class="dropdown">
                <a href="#">Last Minute <span class="arrow-down">&#9662;</span></a>
                <div class="dropdown-content">
                    <a href="#">Today</a>
                    <a href="#">Tomorrow</a>
                    <a href="#">This Weekend</a>
                </div>
            </li>
            <li><a href="#">Where's My Ticket?</a></li>
        </ul>
    </nav>

    <main class="main-content">
        <div class="poster-grid">
            <a href="#" class="poster-item">
                <img src="assets/sfx341359.jpg" alt="2025 NRL & NRLW Grand Final">
                <div class="poster-title">2025 NRL & NRLW Telstra Premiership Grand Final</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx341318.jpg" alt="Merlin Sheldrake - The Secret Life of Fungi LIVE">
                <div class="poster-title">Merlin Sheldrake</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx340811.jpg" alt="2025 Toyota AFL Premiership Season - Kids Go Free">
                <div class="poster-title">2025 Toyota AFL Premiership Season</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx340843.jpg" alt="AC/DC - Power Up Tour">
                <div class="poster-title">AC/DC</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx313097.jpg" alt="The British & Irish Lions Tour 2025">
                <div class="poster-title">The British & Irish Lions Tour</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx334817.jpg" alt="Lil Baby - It's Only Us Tour">
                <div class="poster-title">Lil Baby</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/sfx317196.jpg" alt="Repco Supercars Championship">
                <div class="poster-title">Repco Supercars Championship</div>
            </a>
        </div>
    </main>
</body>
</html>=== ./client/mobile.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Project Pastra Mobile</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, viewport-fit=cover">
  <meta name="theme-color" content="#000000">
  <link rel="stylesheet" href="styles/mobile-style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body>
  <div class="header-section">
    <h1>Project Pastra &#127837;</h1>
  </div>

  <div id="functionInfo" class="function-info">
    Waiting for function calls...
  </div>

  <div class="video-container">
    <video id="videoPreview" autoplay playsinline class="hidden"></video>
  </div>

  <div id="output" class="chat-output"></div>

  <div class="controls">
    <div id="playButtonContainer" class="centered-button-container">
      <button id="connectButton" class="action-button">
        <span class="material-symbols-outlined">play_arrow</span>
      </button>
    </div>
    <div id="mediaButtonsContainer" class="media-buttons-container hidden">
      <button id="stopButton" class="action-button">
        <span class="material-symbols-outlined">stop</span>
      </button>
      <button id="micButton" class="action-button" disabled>
        <span class="material-symbols-outlined">mic</span>
      </button>
      <button id="webcamButton" class="action-button" disabled>
        <span class="material-symbols-outlined">videocam</span>
      </button>
      <button id="switchCameraButton" class="action-button hidden">
        <span class="material-symbols-outlined">flip_camera_ios</span>
      </button>
      <button id="screenButton" class="action-button hidden" disabled>
        <span class="material-symbols-outlined">present_to_all</span>
      </button>
    </div>
  </div>

  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Check if device is mobile first
    const urlParams = new URLSearchParams(window.location.search);
    const forceMobile = urlParams.get('mobile') === 'true';
    const isMobileDevice = forceMobile || /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    
    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    //const api = new GeminiAPI(); // without specifing an endpoint it will try to call the 'ws://localhost:8081'
    const api = new GeminiAPI('wss://live-agent-backend-gey23eiloq-uc.a.run.app'); // remote endpoint example


    let isStarted = false;
    let isRecording = false;
    let isMuted = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Function to enable media controls
    function enableMediaControls() {
      document.getElementById('micButton').disabled = false;
      document.getElementById('webcamButton').disabled = false;
      if (!isMobileDevice) {
        document.getElementById('screenButton').disabled = false;
      }
    }

    // Recording functions
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();  // Stop current playback and clear queue
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        isMuted = false;
        const micButton = document.getElementById('micButton');
        micButton.classList.add('active');
      } catch (error) {
        console.error('Error starting recording:', error);
        throw error;
      }
    }

    function stopRecording() {
      audioRecorder.stop();
      isRecording = false;
      isMuted = false;
      
      if (isStarted) {
        api.sendEndMessage();
      }
      api.isSpeaking = false;
    }

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Show screen share button on non-mobile devices
    if (!isMobileDevice) {
      document.getElementById('screenButton').classList.remove('hidden');
    }

    // Connect button handler
    document.getElementById('connectButton').onclick = async () => {
      try {
        document.getElementById('connectButton').disabled = true;
        await audioContext.resume();
        
        // Try to ensure WebSocket connection
        try {
          await api.ensureConnected();
        } catch (error) {
          throw new Error('Unable to connect to server');
        }
        
        isStarted = true;
        document.getElementById('playButtonContainer').classList.add('hidden');
        document.getElementById('mediaButtonsContainer').classList.remove('hidden');
        enableMediaControls();

        // Start recording immediately
        await startRecording();
      } catch (error) {
        console.error('Error starting session:', error);
        // Show connection error
        const existingError = document.querySelector('.connection-error');
        if (!existingError) {
          const errorElement = document.createElement('div');
          errorElement.className = 'connection-error';
          errorElement.textContent = 'Cannot connect to server. Please check if the server is running.';
          document.body.appendChild(errorElement);
        }
        resetUIState();
      }
    };

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('connectButton').disabled = false;
      // Remove any existing connection error message
      const existingError = document.querySelector('.connection-error');
      if (existingError) {
        existingError.remove();
      }
    };

    api.onError = (error) => {
      console.error('WebSocket error:', error);
      if (error.error_type === 'quota_exceeded') {
        // Show quota error in chat with special styling
        const messageElement = document.createElement('p');
        messageElement.className = 'error-message';
        messageElement.textContent = '⚠️ ' + error.message + ' ' + error.action;
        output.appendChild(messageElement);
        output.scrollTop = output.scrollHeight;
      } else if (error.error_type === 'websocket_error' || error.error_type === 'connection_error') {
        // Show connection error at the top
        const existingError = document.querySelector('.connection-error');
        if (!existingError) {
          const errorElement = document.createElement('div');
          errorElement.className = 'connection-error';
          errorElement.textContent = 'Cannot connect to server. Please check if the server is running.';
          document.body.appendChild(errorElement);
        }
      }
      resetUIState();
      if (isRecording) {
        stopRecording();
      }
      mediaHandler.stopAll();
    };

    api.onClose = () => {
      if (isStarted) {
        resetUIState();
        if (isRecording) {
          stopRecording();
        }
        mediaHandler.stopAll();
      }
    };

    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTurnComplete = () => {
      api.isSpeaking = false;
      audioStreamer.complete();
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      const functionInfo = document.getElementById('functionInfo');
      functionInfo.innerHTML = `Function: ${data.name}\nParameters: ${JSON.stringify(data.args, null, 2)}`;
    };

    api.onFunctionResponse = (data) => {
      const functionInfo = document.getElementById('functionInfo');
      functionInfo.innerHTML += `\nResponse: ${JSON.stringify(data, null, 2)}`;
    };

    // Button handlers
    document.getElementById('micButton').onclick = () => {
      isMuted = !isMuted;
      const micButton = document.getElementById('micButton');
      if (isMuted) {
        micButton.classList.remove('active');
        audioRecorder.mute();
        audioRecorder.off('data');
      } else {
        micButton.classList.add('active');
        audioRecorder.unmute();
        audioRecorder.on('data', (base64Data) => {
          api.sendAudioChunk(base64Data);
        });
      }
    };

    document.getElementById('stopButton').onclick = async () => {
      stopRecording();
      mediaHandler.stopAll();
      audioStreamer.stop();  // Stop current playback and clear queue like interruption
      api.isSpeaking = false;
      
      // Reset to initial state - only show play button
      isStarted = false;
      document.getElementById('connectButton').disabled = false;
      document.getElementById('mediaButtonsContainer').classList.add('hidden');
      document.getElementById('playButtonContainer').classList.remove('hidden');
      
      api.sendEndMessage();
    };

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').classList.remove('active');
        document.getElementById('switchCameraButton').classList.add('hidden');
      } else {
        // First stop screen sharing if it's active
        if (mediaHandler.isScreenActive) {
          mediaHandler.stopAll();
          document.getElementById('screenButton').classList.remove('active');
        }
        
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').classList.add('active');
          if (isMobileDevice) {
            document.getElementById('switchCameraButton').classList.remove('hidden');
          }
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('switchCameraButton').onclick = async () => {
      await mediaHandler.switchCamera();
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').classList.remove('active');
      } else {
        // First stop webcam if it's active
        if (mediaHandler.isWebcamActive) {
          mediaHandler.stopAll();
          document.getElementById('webcamButton').classList.remove('active');
          document.getElementById('switchCameraButton').classList.add('hidden');
        }
        
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').classList.add('active');
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    function logMessage(message) {
      const messageElement = document.createElement('p');
      
      // Add specific styling based on message content
      if (message.startsWith('Function:')) {
        messageElement.className = 'function-name';
      } else if (message.startsWith('Parameters:')) {
        messageElement.className = 'function-params';
      } else if (message.startsWith('API Response:')) {
        messageElement.className = 'api-response';
      } else if (message.startsWith('Gemini:')) {
        messageElement.className = 'gemini-message';
      } else if (message.startsWith('You:')) {
        messageElement.className = 'user-message';
      }
      
      messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    // Remove references to interruptButton and muteButton
    function resetUIState() {
      isStarted = false;
      document.getElementById('connectButton').disabled = false;
      
      document.getElementById('mediaButtonsContainer').classList.add('hidden');
      document.getElementById('playButtonContainer').classList.remove('hidden');
      
      // Reset all buttons
      document.getElementById('micButton').disabled = true;
      document.getElementById('micButton').classList.remove('active');
      
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('webcamButton').classList.remove('active');
      document.getElementById('webcamButton').innerHTML = 
        '<span class="material-symbols-outlined">videocam</span>';
      
      document.getElementById('screenButton').disabled = true;
      document.getElementById('screenButton').classList.remove('active');
      document.getElementById('screenButton').innerHTML = 
        '<span class="material-symbols-outlined">present_to_all</span>';
      
      document.getElementById('switchCameraButton').classList.add('hidden');
    }

    // Update the text content handler to show messages
    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onInterrupted = () => {
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
    };
  </script>
</body>
</html> === ./client/dyson_appointment.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Appointment Confirmation</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f7f7;
        }
    </style>
</head>
<body class="min-h-screen flex flex-col bg-gray-50">
    <!-- Header Section (copied from dyson_home.html) -->
    <header class="bg-black shadow-sm py-4 px-4 sm:px-6 lg:px-8">
        <div class="max-w-7xl mx-auto flex justify-between items-center">
            <!-- Left: Dyson Logo -->
            <div class="text-2xl font-bold text-white">dyson</div>
            <!-- Right: Top Navigation -->
            <nav class="hidden md:flex items-center space-x-6 text-sm text-white">
                <a href="#" class="hover:text-gray-300">For business</a>
                <a href="#" class="hover:text-gray-300">Find a store</a>
                <a href="#" class="hover:text-gray-300">Dyson Outlet</a>
                <a href="#" class="hover:text-gray-300">Register machine</a>
                <a href="#" class="hover:text-gray-300">Contact us</a>
            </nav>
            <!-- Mobile Menu Toggle (hidden on desktop) -->
            <div class="md:hidden">
                <button class="text-gray-300 hover:text-white focus:outline-none">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg>
                </button>
            </div>
        </div>
    </header>
    <!-- Main Navigation Bar (copied from dyson_home.html) -->
    <nav class="bg-black py-3 px-4 sm:px-6 lg:px-8 shadow-sm">
        <div class="max-w-7xl mx-auto flex flex-wrap justify-between items-center text-sm text-white">
            <div class="flex flex-wrap gap-x-6 gap-y-2">
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Trade-in offer</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Vacuum & wet cleaners</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Hair care</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Air purifier fans</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Headphones</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Lighting</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Support</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Best sellers</a>
            </div>
            <div class="flex items-center gap-4 mt-2 sm:mt-0">
                <div class="flex items-center border border-gray-700 rounded-full px-3 py-1 bg-gray-800">
                    <svg class="w-4 h-4 text-gray-300 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg>
                    <input type="text" placeholder="Search products and parts" class="bg-transparent outline-none text-white placeholder-gray-400 w-full text-sm">
                </div>
                <button class="text-white hover:text-gray-300">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 11V7a4 4 0 00-8 0v4M5 9h14l1 12H4L5 9z"></path></svg>
                </button>
            </div>
        </div>
    </nav>
    <!-- Main Content Area -->
    <main class="flex-grow flex flex-col justify-center items-center py-12 px-4 sm:px-6 lg:px-8">
        <div class="bg-white rounded-lg shadow-lg p-8 max-w-md w-full mt-8">
            <h2 class="text-2xl font-bold text-black mb-4 text-center">Appointment Confirmed</h2>
            <div class="mb-6 flex flex-col items-center">
                <p class="text-gray-700 text-lg text-center">Your appointment has been scheduled.</p>
            </div>
            <div class="mb-4">
                <div class="flex justify-between mb-2">
                    <span class="font-semibold text-gray-600">Appointment ID:</span>
                    <span id="appointmentId" class="text-gray-900 font-mono">APT-XXXXXX</span>
                </div>
                <div class="flex justify-between mb-2">
                    <span class="font-semibold text-gray-600">Date & Time:</span>
                    <span id="appointmentSlot" class="text-gray-900">YYYY-MM-DD HH:MM-HH:MM</span>
                </div>
            </div>
            <div class="mt-6 text-center">
                <a href="index.html" class="inline-block bg-green-600 hover:bg-green-700 text-white font-medium py-2 px-6 rounded-full transition duration-200">Back to Home</a>
            </div>
        </div>
    </main>
    <script>
      // This script expects window.appointmentData to be set before loading
      if (window.appointmentData) {
        document.getElementById('appointmentId').textContent = window.appointmentData.appointment_id;
        document.getElementById('appointmentSlot').textContent = window.appointmentData.scheduled_slot;
      }
    </script>
</body>
</html> === ./client/dyson_home.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dyson - Shop Now</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #f7f7f7;
        }
    </style>
</head>
<body class="min-h-screen flex flex-col">

    <!-- Header Section -->
    <header class="bg-black shadow-sm py-4 px-4 sm:px-6 lg:px-8">
        <div class="max-w-7xl mx-auto flex justify-between items-center">
            <!-- Left: Dyson Logo -->
            <div class="text-2xl font-bold text-white">dyson</div>

            <!-- Right: Top Navigation -->
            <nav class="hidden md:flex items-center space-x-6 text-sm text-white">
                <a href="#" class="hover:text-gray-300">For business</a>
                <a href="#" class="hover:text-gray-300">Find a store</a>
                <a href="#" class="hover:text-gray-300">Dyson Outlet</a>
                <a href="#" class="hover:text-gray-300">Register machine</a>
                <a href="#" class="hover:text-gray-300">Contact us</a>
            </nav>

            <!-- Mobile Menu Toggle (hidden on desktop) -->
            <div class="md:hidden">
                <button class="text-gray-300 hover:text-white focus:outline-none">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16M4 18h16"></path></svg>
                </button>
            </div>
        </div>
    </header>

    <!-- Main Navigation Bar -->
    <nav class="bg-black py-3 px-4 sm:px-6 lg:px-8 shadow-sm">
        <div class="max-w-7xl mx-auto flex flex-wrap justify-between items-center text-sm text-white">
            <div class="flex flex-wrap gap-x-6 gap-y-2">
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Trade-in offer</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Vacuum & wet cleaners</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Hair care</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Air purifier fans</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Headphones</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Lighting</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Support</a>
                <a href="#" class="hover:text-gray-300 whitespace-nowrap">Best sellers</a>
            </div>
            <div class="flex items-center gap-4 mt-2 sm:mt-0">
                <div class="flex items-center border border-gray-700 rounded-full px-3 py-1 bg-gray-800">
                    <svg class="w-4 h-4 text-gray-300 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg>
                    <input type="text" placeholder="Search products and parts" class="bg-transparent outline-none text-white placeholder-gray-400 w-full text-sm">
                </div>
                <button class="text-white hover:text-gray-300">
                    <svg class="w-6 h-6" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 11V7a4 4 0 00-8 0v4M5 9h14l1 12H4L5 9z"></path></svg>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content Area - Product Grid -->
    <main class="flex-grow py-8 px-4 sm:px-6 lg:px-8">
        <div class="max-w-7xl mx-auto grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6 relative">

            <!-- Product Card 1 -->
            <div class="bg-white rounded-lg shadow-md overflow-hidden flex flex-col justify-between p-4 relative group">
                <span class="absolute top-3 left-3 bg-red-500 text-white text-xs font-semibold px-2 py-1 rounded-full">Save $610</span>
                <button class="absolute top-3 right-3 text-gray-400 hover:text-gray-700">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3.172 5.172a4 4 0 015.656 0L10 6.343l1.172-1.171a4 4 0 115.656 5.656L10 17.657l-6.828-6.829a4 4 0 010-5.656z" clip-rule="evenodd"></path></svg>
                </button>
                <img src="assets/detect-slim-hepa.jpeg" alt="Dyson V12 Detect Slim Absolute HEPA" class="mx-auto my-4 object-contain h-96">
                <div class="text-center mt-auto">
                    <p class="font-medium text-gray-800">Dyson V12 Detect Slim Absolute HEPA (Yellow/Nickel)</p>
                    <p class="text-xs text-gray-500 mt-1">Use code <span class="font-semibold text-gray-700">UPGRADE100</span></p>
                </div>
            </div>

            <!-- Product Card 2 -->
            <div class="bg-white rounded-lg shadow-md overflow-hidden flex flex-col justify-between p-4 relative group">
                <span class="absolute top-3 left-3 bg-red-500 text-white text-xs font-semibold px-2 py-1 rounded-full">Save $544</span>
                <button class="absolute top-3 right-3 text-gray-400 hover:text-gray-700">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3.172 5.172a4 4 0 015.656 0L10 6.343l1.172-1.171a4 4 0 115.656 5.656L10 17.657l-6.828-6.829a4 4 0 010-5.656z" clip-rule="evenodd"></path></svg>
                </button>
                <img src="assets/detect-slim-summarine.jpeg" alt="Dyson V12s Detect Slim Submarine Complete" class="mx-auto my-4 object-contain h-96">
                <div class="text-center mt-auto">
                    <p class="font-medium text-gray-800">Dyson V12s Detect Slim Submarine Complete (Yellow/Nickel)</p>
                    <p class="text-xs text-gray-500 mt-1">Use code <span class="font-semibold text-gray-700">UPGRADE200</span></p>
                </div>
            </div>

            <!-- Product Card 3 -->
            <div class="bg-white rounded-lg shadow-md overflow-hidden flex flex-col justify-between p-4 relative group">
                <span class="absolute top-3 left-3 bg-red-500 text-white text-xs font-semibold px-2 py-1 rounded-full">Save $378</span>
                <button class="absolute top-3 right-3 text-gray-400 hover:text-gray-700">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3.172 5.172a4 4 0 015.656 0L10 6.343l1.172-1.171a4 4 0 115.656 5.656L10 17.657l-6.828-6.829a4 4 0 010-5.656z" clip-rule="evenodd"></path></svg>
                </button>
                <img src="assets/airstrait.jpeg" alt="Dyson Airstrait straightener" class="mx-auto my-4 object-contain h-96">
                <div class="text-center mt-auto">
                    <p class="font-medium text-gray-800">Dyson Airstrait straightener (Jasper Plum)</p>
                    <p class="text-xs text-gray-500 mt-1">Use code <span class="font-semibold text-gray-700">UPGRADE100</span></p>
                </div>
            </div>

            <!-- Product Card 4 -->
            <div class="bg-white rounded-lg shadow-md overflow-hidden flex flex-col justify-between p-4 relative group">
                <span class="absolute top-3 left-3 bg-red-500 text-white text-xs font-semibold px-2 py-1 rounded-full">Save $350</span>
                <button class="absolute top-3 right-3 text-gray-400 hover:text-gray-700">
                    <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3.172 5.172a4 4 0 015.656 0L10 6.343l1.172-1.171a4 4 0 115.656 5.656L10 17.657l-6.828-6.829a4 4 0 010-5.656z" clip-rule="evenodd"></path></svg>
                </button>
                <img src="assets/purifier.jpeg" alt="Dyson Purifier Big + Quiet Formaldehyde" class="mx-auto my-4 object-contain h-96">
                <div class="text-center mt-auto">
                    <p class="font-medium text-gray-800">Dyson Purifier Big + Quiet Formaldehyde (Prussian Blue/Gold)</p>
                    <p class="text-xs text-gray-500 mt-1">Use code <span class="font-semibold text-gray-700">UPGRADE200</span></p>
                </div>
            </div>

            <!-- Right Arrow Button for Carousel (Placeholder) -->
            <button class="absolute right-0 top-1/2 transform -translate-y-1/2 bg-gray-200 hover:bg-gray-300 rounded-full p-2 hidden lg:block">
                <svg class="w-6 h-6 text-gray-600" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg>
            </button>
        </div>

        <!-- Shop All Button -->
        <div class="flex justify-center mt-10 mb-8">
            <button class="bg-green-600 hover:bg-green-700 text-white font-medium py-3 px-8 rounded-full shadow-lg transition duration-300 ease-in-out transform hover:scale-105">
                Shop all
            </button>
        </div>
    </main>

</body>
</html>
=== ./client/.venv/bin/activate_this.py ===
# Copyright (c) 2020-202x The virtualenv developers
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the
# "Software"), to deal in the Software without restriction, including
# without limitation the rights to use, copy, modify, merge, publish,
# distribute, sublicense, and/or sell copies of the Software, and to
# permit persons to whom the Software is furnished to do so, subject to
# the following conditions:
#
# The above copyright notice and this permission notice shall be
# included in all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
# EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
# MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
# NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
# LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
# OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

"""
Activate virtualenv for current interpreter:

import runpy
runpy.run_path(this_file)

This can be used when you must use an existing Python interpreter, not the virtualenv bin/python.
"""  # noqa: D415

from __future__ import annotations

import os
import site
import sys

try:
    abs_file = os.path.abspath(__file__)
except NameError as exc:
    msg = "You must use import runpy; runpy.run_path(this_file)"
    raise AssertionError(msg) from exc

bin_dir = os.path.dirname(abs_file)
base = bin_dir[: -len("bin") - 1]  # strip away the bin part from the __file__, plus the path separator

# prepend bin to PATH (this file is inside the bin directory)
os.environ["PATH"] = os.pathsep.join([bin_dir, *os.environ.get("PATH", "").split(os.pathsep)])
os.environ["VIRTUAL_ENV"] = base  # virtual env is right above bin directory
os.environ["VIRTUAL_ENV_PROMPT"] = "client" or os.path.basename(base)  # noqa: SIM222

# add the virtual environments libraries to the host python import mechanism
prev_length = len(sys.path)
for lib in "../lib/python3.12/site-packages".split(os.pathsep):
    path = os.path.realpath(os.path.join(bin_dir, lib))
    site.addsitedir(path)
sys.path[:] = sys.path[prev_length:] + sys.path[0:prev_length]

sys.real_prefix = sys.prefix
sys.prefix = base
=== ./client/.venv/lib/python3.12/site-packages/_virtualenv.py ===
"""Patches that are applied at runtime to the virtual environment."""

import os
import sys

VIRTUALENV_PATCH_FILE = os.path.join(__file__)


def patch_dist(dist):
    """
    Distutils allows user to configure some arguments via a configuration file:
    https://docs.python.org/3.11/install/index.html#distutils-configuration-files.

    Some of this arguments though don't make sense in context of the virtual environment files, let's fix them up.
    """  # noqa: D205
    # we cannot allow some install config as that would get packages installed outside of the virtual environment
    old_parse_config_files = dist.Distribution.parse_config_files

    def parse_config_files(self, *args, **kwargs):
        result = old_parse_config_files(self, *args, **kwargs)
        install = self.get_option_dict("install")

        if "prefix" in install:  # the prefix governs where to install the libraries
            install["prefix"] = VIRTUALENV_PATCH_FILE, os.path.abspath(sys.prefix)
        for base in ("purelib", "platlib", "headers", "scripts", "data"):
            key = f"install_{base}"
            if key in install:  # do not allow global configs to hijack venv paths
                install.pop(key, None)
        return result

    dist.Distribution.parse_config_files = parse_config_files


# Import hook that patches some modules to ignore configuration values that break package installation in case
# of virtual environments.
_DISTUTILS_PATCH = "distutils.dist", "setuptools.dist"
# https://docs.python.org/3/library/importlib.html#setting-up-an-importer


class _Finder:
    """A meta path finder that allows patching the imported distutils modules."""

    fullname = None

    # lock[0] is threading.Lock(), but initialized lazily to avoid importing threading very early at startup,
    # because there are gevent-based applications that need to be first to import threading by themselves.
    # See https://github.com/pypa/virtualenv/issues/1895 for details.
    lock = []  # noqa: RUF012

    def find_spec(self, fullname, path, target=None):  # noqa: ARG002
        if fullname in _DISTUTILS_PATCH and self.fullname is None:
            # initialize lock[0] lazily
            if len(self.lock) == 0:
                import threading

                lock = threading.Lock()
                # there is possibility that two threads T1 and T2 are simultaneously running into find_spec,
                # observing .lock as empty, and further going into hereby initialization. However due to the GIL,
                # list.append() operation is atomic and this way only one of the threads will "win" to put the lock
                # - that every thread will use - into .lock[0].
                # https://docs.python.org/3/faq/library.html#what-kinds-of-global-value-mutation-are-thread-safe
                self.lock.append(lock)

            from functools import partial
            from importlib.util import find_spec

            with self.lock[0]:
                self.fullname = fullname
                try:
                    spec = find_spec(fullname, path)
                    if spec is not None:
                        # https://www.python.org/dev/peps/pep-0451/#how-loading-will-work
                        is_new_api = hasattr(spec.loader, "exec_module")
                        func_name = "exec_module" if is_new_api else "load_module"
                        old = getattr(spec.loader, func_name)
                        func = self.exec_module if is_new_api else self.load_module
                        if old is not func:
                            try:  # noqa: SIM105
                                setattr(spec.loader, func_name, partial(func, old))
                            except AttributeError:
                                pass  # C-Extension loaders are r/o such as zipimporter with <3.7
                        return spec
                finally:
                    self.fullname = None
        return None

    @staticmethod
    def exec_module(old, module):
        old(module)
        if module.__name__ in _DISTUTILS_PATCH:
            patch_dist(module)

    @staticmethod
    def load_module(old, name):
        module = old(name)
        if module.__name__ in _DISTUTILS_PATCH:
            patch_dist(module)
        return module


sys.meta_path.insert(0, _Finder())
=== ./client/index_cloudrun.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Dyson Homepage (70%) -->
    <div id="dyson-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Dyson content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    const api = new GeminiAPI('wss://live141-agent-backend-combined-671247654914.us-central1.run.app/ws'); // Cloud Run single server, multi port setup

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      if (data.name === 'show_hair_dryer_models') {
        fetch('dyson_supersonic.html')
          .then(response => response.text())
          .then(html => {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, 'text/html');
            const dysonBody = doc.body.innerHTML;
            document.getElementById('dyson-home').innerHTML = dysonBody;
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson Supersonic content.</p>';
            console.error('Error loading Dyson Supersonic content:', err);
          });
      }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Check for appointment_id and show appointment.html if present
      if (data && data.appointment_id) {
        fetch('dyson_appointment.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            // Wait for DOM to update, then set the values
            setTimeout(() => {
              if (document.getElementById('appointmentId')) {
                document.getElementById('appointmentId').textContent = data.appointment_id;
              }
              if (document.getElementById('appointmentSlot')) {
                document.getElementById('appointmentSlot').textContent = data.scheduled_slot;
              }
            }, 0);
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Appointment content.</p>';
            console.error('Error loading Appointment content:', err);
          });
      } else if (data && data.video_url && data.video_url.includes('youtube.com')) {
        fetch('video.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            
            const videoUrl = new URL(data.video_url);
            const videoId = videoUrl.searchParams.get('v');

            if (videoId) {
              const embedUrl = `https://www.youtube.com/embed/${videoId}?autoplay=1&mute=1`; // Add autoplay and mute
              // Wait for DOM to update, then set the src
              setTimeout(() => {
                const iframe = document.getElementById('youtube-video');
                if (iframe) {
                  iframe.src = embedUrl;
                }
              }, 0);
            } else {
              console.error('Could not extract YouTube video ID from URL:', data.video_url);
              document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to get video ID from URL.</p>';
            }
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load video player.</p>';
            console.error('Error loading video.html:', err);
          });
      }
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('dyson_home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        const dysonBody = doc.body.innerHTML;
        document.getElementById('dyson-home').innerHTML = dysonBody;
      })
      .catch(err => {
        document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson content.</p>';
        console.error('Error loading Dyson content:', err);
      });
  </script>
</body>
</html>
=== ./client/xtelcom-home.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link rel="stylesheet" href="styles/style-teg-home.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
</head>
<body>
    <header class="header">
        <div class="header-left">
            <img src="assets/Ticketek-Logo-White.svg" alt="Ticketek Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search artist, event, venue, location...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <nav class="navbar">
        <ul class="nav-list">
            <li><a href="#">Featured</a></li>
            <li><a href="#">Sports</a></li>
            <li><a href="#">Concerts</a></li>
            <li><a href="#">Theatre & Arts</a></li>
            <li><a href="#">Family</a></li>
            <li><a href="#">Comedy</a></li>
            <li><a href="#">Premium Tickets</a></li>
            <li class="dropdown">
                <a href="#">Last Minute <span class="arrow-down">&#9662;</span></a>
                <div class="dropdown-content">
                    <a href="#">Today</a>
                    <a href="#">Tomorrow</a>
                    <a href="#">This Weekend</a>
                </div>
            </li>
            <li><a href="#">Where's My Ticket?</a></li>
        </ul>
    </nav>

    <main class="main-content">
        <div class="poster-grid">
            <a href="#" class="poster-item">
                <img src="assets/samsung-z-fold-6.png" alt="Samsung Galaxy Z Fold6">
                <div class="poster-title">Samsung Galaxy Z Fold6</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro-Fold.png" alt="Google Pixel 9 Pro Fold">
                <div class="poster-title">Google Pixel 9 Pro Fold</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro-XL.png" alt="Google Pixel 9 Pro XL">
                <div class="poster-title">Google Pixel 9 Pro XL</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9a.png" alt="Google Pixel 9a">
                <div class="poster-title">Google Pixel 9a</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9-Pro.png" alt="Google Pixel 9 Pro">
                <div class="poster-title">Google Pixel 9 Pro</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-8a.png" alt="Google Pixel 8a">
                <div class="poster-title">Google Pixel 8a</div>
            </a>
            <a href="#" class="poster-item">
                <img src="assets/Google-Pixel-9.png" alt="Google Pixel 9">
                <div class="poster-title">Google Pixel 9</div>
            </a>
        </div>
    </main>
</body>
</html>=== ./client/index_teg.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">

  <link rel="stylesheet" href="styles/style-teg-home.css"> 
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <div id="ticketek-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      </div>
  </div>
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    const api = new GeminiAPI('ws://127.0.0.1:8080/ws');
    //const api = new GeminiAPI('wss://live141-teg-agent-backend-combined-927033137380.us-central1.run.app/ws'); // Cloud Run single server, multi port setup

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // --- API Event Handlers ---

    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false;
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false);
        }
        mediaHandler.stopAll();
    };

    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();
      document.getElementById('interruptButton').style.display = 'none';
      
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // --- Robust Function Call Handler ---
    api.onFunctionCall = (data) => {
        logMessage('Function: ' + data.name);
        logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
 
        if (data.name === 'search_live_teg_catalog' && data.args) {
            // More forgiving check for the artist parameter.
            // It looks for 'Artist', then 'artist', then 'query'.
            const artistName = data.args.search_term || data.args.event.artist || data.args.query;
            logMessage(`System: Found artist "${artistName}"`);
            if (artistName) {
                const artist = artistName.toLowerCase();
                let artistFile = '';

                if (artist.includes('drake')) {
                    artistFile = 'drake.html';
                } else if (artist.includes('james blunt')) {
                    artistFile = 'james_blunt.html';
                } else if (artist.includes('harry styles')) {
                    artistFile = 'harry_styles.html';
                }

                if (artistFile) {
                    fetch(artistFile)
                        .then(response => {
                            if (!response.ok) {
                                throw new Error(`HTTP error! Status: ${response.status}`);
                            }
                            return response.text();
                        })
                        .then(html => {
                            const parser = new DOMParser();
                            const doc = parser.parseFromString(html, 'text/html');
                            document.getElementById('ticketek-home').innerHTML = doc.body.innerHTML;
                        })
                        .catch(err => {
                            document.getElementById('ticketek-home').innerHTML = `<p style="color:red;">Failed to load content for ${artistName}.</p>`;
                            console.error(`Error loading content for ${artistFile}:`, err);
                        });
                }
            } else {
                // Handle cases where no recognizable artist parameter was found
                logMessage("System Error: 'search_live_teg_catalog' was called, but a valid artist parameter (e.g., 'Artist', 'artist', 'query') was not found.");
            }
        }
    };


    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    
    api.onError = (error) => {
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };

    api.logMessage = logMessage;

    // --- UI and Core Functions ---

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) messageElement.className = 'function-name';
        else if (message.startsWith('Parameters:')) messageElement.className = 'function-params';
        else if (message.startsWith('API Response:')) messageElement.className = 'api-response';
        else if (message.startsWith('Gemini:')) messageElement.className = 'gemini-message';
        else if (message.startsWith('You:')) messageElement.className = 'user-message';
        messageElement.textContent = message;
        handled = true;
      } else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;
          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        } else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          messageElement.innerHTML = DOMPurify.sanitize(marked.parse(`API Response: ${JSON.stringify(message.data, null, 2)}`));
          output.appendChild(messageElement);
          handled = true;
        } else if (message.type === 'markdown') {
          messageElement.className = 'gemini-message';
          messageElement.innerHTML = DOMPurify.sanitize(marked.parse(message.data));
          handled = true;
        } else if (message.type === 'image') {
          messageElement.className = 'gemini-message';
          const img = document.createElement('img');
          img.src = message.data;
          img.alt = 'Image from Gemini';
          img.style.maxWidth = '100%';
          messageElement.appendChild(img);
          handled = true;
        } else if (message.type === 'text') {
          messageElement.className = 'gemini-message';
          messageElement.textContent = message.data;
          handled = true;
        }
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      if (handled && messageElement.textContent || messageElement.innerHTML) {
          output.appendChild(messageElement);
      }
      output.scrollTop = output.scrollHeight;
    }

    async function startRecording() {
      try {
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }
        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML = '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      if (sendEndMsg) {
        api.sendEndMessage();
      }
      api.isSpeaking = false;
    }

    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;
      textInput.value = '';
      logMessage('You: ' + text);
      api.sendTextMessage(text);
    }

    // --- UI Event Listeners ---

    document.getElementById('micButton').onclick = () => {
      isRecording ? stopRecording() : startRecording();
    };

    document.getElementById('sendButton').onclick = sendTextMessage;

    document.getElementById('textInput').addEventListener('keypress', (e) => {
      if (e.key === 'Enter') sendTextMessage();
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = '<span class="material-symbols-outlined">videocam</span>';
      } else {
        if (await mediaHandler.startWebcam()) {
          document.getElementById('webcamButton').innerHTML = '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => api.sendImage(base64Image));
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        if (await mediaHandler.startScreenShare()) {
          document.getElementById('screenButton').innerHTML = '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => api.sendImage(base64Image));
        }
      }
    };

    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click();
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1];
                document.getElementById('imagePreview').src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';
                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage();
    };

  </script>
  
  <script>
    // Inject custom styles
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b; font-style: italic; margin: 4px 0;
        padding: 4px 8px; border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);

    // Load initial content
    fetch('ticketek-home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        document.getElementById('ticketek-home').innerHTML = doc.body.innerHTML;
      })
      .catch(err => {
        document.getElementById('ticketek-home').innerHTML = '<p style="color:red;">Failed to load initial content.</p>';
        console.error('Error loading Ticketek content:', err);
      });
  </script>
</body>
</html>=== ./client/index_wei.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Dyson Homepage (70%) -->
    <div id="dyson-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Dyson content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    //const api = new GeminiAPI('wss://live141-agent-backend-combined-671247654914.us-central1.run.app/ws'); // Cloud Run single server, multi port setup
    const api = new GeminiAPI('ws://127.0.0.1:8080/ws');

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      if (data.name === 'show_hair_dryer_models') {
        fetch('dyson_supersonic.html')
          .then(response => response.text())
          .then(html => {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, 'text/html');
            const dysonBody = doc.body.innerHTML;
            document.getElementById('dyson-home').innerHTML = dysonBody;
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson Supersonic content.</p>';
            console.error('Error loading Dyson Supersonic content:', err);
          });
      }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Check for appointment_id and show appointment.html if present
      if (data && data.appointment_id) {
        fetch('dyson_appointment.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            // Wait for DOM to update, then set the values
            setTimeout(() => {
              if (document.getElementById('appointmentId')) {
                document.getElementById('appointmentId').textContent = data.appointment_id;
              }
              if (document.getElementById('appointmentSlot')) {
                document.getElementById('appointmentSlot').textContent = data.scheduled_slot;
              }
            }, 0);
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Appointment content.</p>';
            console.error('Error loading Appointment content:', err);
          });
      }
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('dyson_home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        const dysonBody = doc.body.innerHTML;
        document.getElementById('dyson-home').innerHTML = dysonBody;
      })
      .catch(err => {
        document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson content.</p>';
        console.error('Error loading Dyson content:', err);
      });
  </script>
</body>
</html>=== ./client/james_blunt.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Apply Inter font to the entire body */
        body {
            font-family: 'Inter', sans-serif;
        }

        /* Custom styles for the header to maintain original appearance without external CSS */
        .header {
            background-color: #000; /* Black background for header */
            color: #fff;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            flex-wrap: wrap; /* Allow header items to wrap on smaller screens */
        }
        .header-left .logo {
            height: 40px; /* Logo height */
        }
        .header-center {
            flex-grow: 1; /* Allow search bar to grow */
            display: flex;
            justify-content: center; /* Center search bar */
            min-width: 250px; /* Minimum width for search bar container */
        }
        .header-center .search-bar {
            display: flex;
            align-items: center;
            background-color: #333; /* Darker background for search bar */
            border-radius: 9999px; /* Fully rounded search bar */
            padding: 0.5rem 1rem;
            width: 100%; /* Take full width of its container */
            max-width: 500px; /* Max width for search bar */
        }
        .header-center .search-bar input {
            background: none;
            border: none;
            outline: none;
            color: #fff;
            padding: 0.25rem 0.5rem;
            flex-grow: 1; /* Input takes available space */
        }
        .header-center .search-bar input::placeholder {
            color: #bbb; /* Placeholder text color */
        }
        .header-center .search-bar button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            padding: 0.25rem;
        }
        .header-right {
            display: flex;
            gap: 0.5rem; /* Space between buttons */
            align-items: center;
        }
        .header-right button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 9999px; /* Fully rounded buttons */
            transition: background-color 0.3s ease; /* Smooth hover effect */
        }
        .header-right button:hover {
            background-color: #555; /* Darker background on hover */
        }
        .header-right svg {
            color: #fff; /* Icon color */
        }

        /* Responsive adjustments for header */
        @media (max-width: 768px) {
            .header {
                padding: 1rem;
                flex-direction: column; /* Stack items vertically */
                align-items: flex-start; /* Align items to the start */
            }
            .header-left {
                margin-bottom: 1rem; /* Space below logo */
            }
            .header-center {
                width: 100%; /* Search bar takes full width */
                margin-bottom: 1rem; /* Space below search bar */
            }
            .header-right {
                width: 100%; /* Buttons take full width */
                justify-content: space-around; /* Distribute buttons */
            }
            .header-right .login-button {
                display: none; /* Hide Sign In button on small screens to save space */
            }
            .header-right button {
                padding: 0.5rem; /* Smaller padding for buttons */
            }
        }
    </style>
</head>
<!-- Set body to be a flex column and take minimum full screen height -->
<body class="flex flex-col min-h-screen bg-gray-100">
    <header class="header">
        <div class="header-left">
            <img src="assets/Ticketek-Logo-White.svg" alt="Ticketek Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search artist, event, venue, location...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <!-- The navigation bar has been removed as per the request -->

    <!-- Main content now contains only the Drake image, filling most of the remaining space -->
    <main class="flex-grow flex items-center justify-center p-4">
        <!-- The image takes full width and height of its container, maintains aspect ratio (object-contain),
             and has a max-width and max-height for very large screens, plus rounded corners and a shadow. -->
        <img src="assets/jamesblunt.png" alt="Drake" class="w-full h-full object-contain max-w-screen-xl max-h-screen-xl rounded-lg shadow-xl">
    </main>
</body>
</html>
=== ./client/drake.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Apply Inter font to the entire body */
        body {
            font-family: 'Inter', sans-serif;
        }

        /* Custom styles for the header to maintain original appearance without external CSS */
        .header {
            background-color: #000; /* Black background for header */
            color: #fff;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            flex-wrap: wrap; /* Allow header items to wrap on smaller screens */
        }
        .header-left .logo {
            height: 40px; /* Logo height */
        }
        .header-center {
            flex-grow: 1; /* Allow search bar to grow */
            display: flex;
            justify-content: center; /* Center search bar */
            min-width: 250px; /* Minimum width for search bar container */
        }
        .header-center .search-bar {
            display: flex;
            align-items: center;
            background-color: #333; /* Darker background for search bar */
            border-radius: 9999px; /* Fully rounded search bar */
            padding: 0.5rem 1rem;
            width: 100%; /* Take full width of its container */
            max-width: 500px; /* Max width for search bar */
        }
        .header-center .search-bar input {
            background: none;
            border: none;
            outline: none;
            color: #fff;
            padding: 0.25rem 0.5rem;
            flex-grow: 1; /* Input takes available space */
        }
        .header-center .search-bar input::placeholder {
            color: #bbb; /* Placeholder text color */
        }
        .header-center .search-bar button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            padding: 0.25rem;
        }
        .header-right {
            display: flex;
            gap: 0.5rem; /* Space between buttons */
            align-items: center;
        }
        .header-right button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 9999px; /* Fully rounded buttons */
            transition: background-color 0.3s ease; /* Smooth hover effect */
        }
        .header-right button:hover {
            background-color: #555; /* Darker background on hover */
        }
        .header-right svg {
            color: #fff; /* Icon color */
        }

        /* Responsive adjustments for header */
        @media (max-width: 768px) {
            .header {
                padding: 1rem;
                flex-direction: column; /* Stack items vertically */
                align-items: flex-start; /* Align items to the start */
            }
            .header-left {
                margin-bottom: 1rem; /* Space below logo */
            }
            .header-center {
                width: 100%; /* Search bar takes full width */
                margin-bottom: 1rem; /* Space below search bar */
            }
            .header-right {
                width: 100%; /* Buttons take full width */
                justify-content: space-around; /* Distribute buttons */
            }
            .header-right .login-button {
                display: none; /* Hide Sign In button on small screens to save space */
            }
            .header-right button {
                padding: 0.5rem; /* Smaller padding for buttons */
            }
        }
    </style>
</head>
<!-- Set body to be a flex column and take minimum full screen height -->
<body class="flex flex-col min-h-screen bg-gray-100">
    <header class="header">
        <div class="header-left">
            <img src="assets/Ticketek-Logo-White.svg" alt="Ticketek Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search artist, event, venue, location...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <!-- The navigation bar has been removed as per the request -->

    <!-- Main content now contains only the Drake image, filling most of the remaining space -->
    <main class="flex-grow flex items-center justify-center p-4">
        <!-- The image takes full width and height of its container, maintains aspect ratio (object-contain),
             and has a max-width and max-height for very large screens, plus rounded corners and a shadow. -->
        <img src="assets/drake.png" alt="Drake" class="w-full h-full object-contain max-w-screen-xl max-h-screen-xl rounded-lg shadow-xl">
    </main>
</body>
</html>
=== ./client/harry_styles.html ===
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ticketek - Events, Tickets & Live Entertainment</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <!-- Tailwind CSS CDN for styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        /* Apply Inter font to the entire body */
        body {
            font-family: 'Inter', sans-serif;
        }

        /* Custom styles for the header to maintain original appearance without external CSS */
        .header {
            background-color: #000; /* Black background for header */
            color: #fff;
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 1rem 2rem;
            box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
            flex-wrap: wrap; /* Allow header items to wrap on smaller screens */
        }
        .header-left .logo {
            height: 40px; /* Logo height */
        }
        .header-center {
            flex-grow: 1; /* Allow search bar to grow */
            display: flex;
            justify-content: center; /* Center search bar */
            min-width: 250px; /* Minimum width for search bar container */
        }
        .header-center .search-bar {
            display: flex;
            align-items: center;
            background-color: #333; /* Darker background for search bar */
            border-radius: 9999px; /* Fully rounded search bar */
            padding: 0.5rem 1rem;
            width: 100%; /* Take full width of its container */
            max-width: 500px; /* Max width for search bar */
        }
        .header-center .search-bar input {
            background: none;
            border: none;
            outline: none;
            color: #fff;
            padding: 0.25rem 0.5rem;
            flex-grow: 1; /* Input takes available space */
        }
        .header-center .search-bar input::placeholder {
            color: #bbb; /* Placeholder text color */
        }
        .header-center .search-bar button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            padding: 0.25rem;
        }
        .header-right {
            display: flex;
            gap: 0.5rem; /* Space between buttons */
            align-items: center;
        }
        .header-right button {
            background: none;
            border: none;
            color: #fff;
            cursor: pointer;
            display: flex;
            align-items: center;
            gap: 0.5rem;
            padding: 0.5rem 1rem;
            border-radius: 9999px; /* Fully rounded buttons */
            transition: background-color 0.3s ease; /* Smooth hover effect */
        }
        .header-right button:hover {
            background-color: #555; /* Darker background on hover */
        }
        .header-right svg {
            color: #fff; /* Icon color */
        }

        /* Responsive adjustments for header */
        @media (max-width: 768px) {
            .header {
                padding: 1rem;
                flex-direction: column; /* Stack items vertically */
                align-items: flex-start; /* Align items to the start */
            }
            .header-left {
                margin-bottom: 1rem; /* Space below logo */
            }
            .header-center {
                width: 100%; /* Search bar takes full width */
                margin-bottom: 1rem; /* Space below search bar */
            }
            .header-right {
                width: 100%; /* Buttons take full width */
                justify-content: space-around; /* Distribute buttons */
            }
            .header-right .login-button {
                display: none; /* Hide Sign In button on small screens to save space */
            }
            .header-right button {
                padding: 0.5rem; /* Smaller padding for buttons */
            }
        }
    </style>
</head>
<!-- Set body to be a flex column and take minimum full screen height -->
<body class="flex flex-col min-h-screen bg-gray-100">
    <header class="header">
        <div class="header-left">
            <img src="assets/Ticketek-Logo-White.svg" alt="Ticketek Logo" class="logo">
        </div>
        <div class="header-center">
            <div class="search-bar">
                <input type="text" placeholder="Search artist, event, venue, location...">
                <button type="submit">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                        <path d="M10 2a8 8 0 100 16 8 8 0 000-16zM2 10a8 8 0 1116 0 8 8 0 01-16 0zm19.293 19.707a1 1 0 01-1.414 0l-5-5a1 1 0 011.414-1.414l5 5a1 1 0 010 1.414z"/>
                    </svg>
                </button>
            </div>
        </div>
        <div class="header-right">
            <button class="login-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm0 3c1.66 0 3 1.34 3 3s-1.34 3-3 3-3-1.34-3-3 1.34-3 3-3zm0 14.2c-2.5 0-4.71-1.29-6-3.22.03-1.99 4-3.08 6-3.08s5.97 1.09 6 3.08c-1.29 1.93-3.5 3.22-6 3.22z"/>
                </svg>
                Sign In
            </button>
            <button class="cart-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M7 18c-1.1 0-1.99.9-1.99 2S5.9 22 7 22s2-.9 2-2-.9-2-2-2zm10 0c-1.1 0-1.99.9-1.99 2s.89 2 1.99 2 2-.9 2-2-.9-2-2-2zm-8.7-4.42c-.44-.45-.63-1.04-.54-1.66l.76-4.57c.18-1.08 1.13-1.85 2.22-1.85h6.64c1.09 0 2.04.77 2.22 1.85l.76 4.57c.09.62-.1 1.21-.54 1.66-.45.44-1.04.63-1.66.54L7 13.58zM19 8h-2.14l-3.32-6.64c-.18-.36-.55-.56-.95-.56h-2.1c-.4 0-.77.2-.95.56L5.14 8H3c-1.1 0-2 .9-2 2s.9 2 2 2h1v4h16v-4h1c1.1 0 2-.9 2-2s-.9-2-2-2z"/>
                </svg>
            </button>
            <button class="menu-button">
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="20px" height="20px">
                    <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                </svg>
            </button>
        </div>
    </header>

    <!-- Main content now contains both images, side-by-side on larger screens, stacked on smaller screens -->
    <main class="flex-grow flex flex-col md:flex-row items-center justify-center p-4 gap-4">
        <!-- Seat Map image -->
        <img src="assets/seatmap.jpg" alt="Seat Map" class="w-full md:w-1/2 h-auto object-contain max-w-screen-md max-h-screen-md rounded-lg shadow-xl">
        <!-- Harry Styles image -->
        <img src="assets/harrystyles.jpg" alt="Harry Styles" class="w-full md:w-1/2 h-auto object-contain max-w-screen-md max-h-screen-md rounded-lg shadow-xl">
    </main>
</body>
</html>
=== ./client/dyson_supersonic.html ===
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Dyson - Shop Now</title>
        <script src="https://cdn.tailwindcss.com"></script>
        <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
        <style>
            body {
                font-family: 'Inter', sans-serif;
                background-color: #f7f7f7;
            }
        </style>
    </head>
    <body class="min-h-screen flex flex-col">

    <!-- Header Section -->
    <header class="bg-black py-4 header-shadow">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <!-- Top row of header -->
            <div class="flex items-center justify-between mb-2">
                <a href="#" class="text-2xl font-bold text-white">dyson</a>
                <nav class="hidden md:flex space-x-6 text-sm text-white">
                    <a href="#" class="hover:text-gray-300">For business</a>
                    <a href="#" class="hover:text-gray-300">Find a store</a>
                    <a href="#" class="hover:text-gray-300">Dyson Outlet</a>
                    <a href="#" class="hover:text-gray-300">Register machine</a>
                    <a href="#" class="hover:text-gray-300">Contact us</a>
                </nav>
            </div>

            <!-- Bottom row of header -->
            <div class="flex items-center justify-between">
                <nav class="hidden md:flex space-x-6 text-sm text-white">
                    <a href="#" class="hover:text-gray-300">Trade-in offer</a>
                    <a href="#" class="hover:text-gray-300">Vacuum & wet cleaners</a>
                    <a href="#" class="hover:text-gray-300">Hair care</a>
                    <a href="#" class="hover:text-gray-300">Air purifier fans</a>
                    <a href="#" class="hover:text-gray-300">Headphones</a>
                    <a href="#" class="hover:text-gray-300">Lighting</a>
                    <a href="#" class="hover:text-gray-300">Support</a>
                    <a href="#" class="hover:text-gray-300">Best sellers</a>
                </nav>
                <div class="flex items-center space-x-4">
                    <!-- Search bar with icon -->
                    <div class="relative flex items-center bg-gray-800 rounded-full px-4 py-2">
                        <svg class="w-5 h-5 text-gray-300 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 21l-6-6m2-5a7 7 0 11-14 0 7 7 0 0114 0z"></path></svg>
                        <input type="text" placeholder="Search products and parts" class="bg-transparent outline-none text-white placeholder-gray-400 text-sm w-40 md:w-auto">
                    </div>
                    <!-- Shopping Cart Icon -->
                    <svg class="w-6 h-6 text-white cursor-pointer" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M16 11V7a4 4 0 00-8 0v4M5 9h14l1 12H4L5 9z"></path></svg>
                </div>
            </div>
        </div>
    </header>

    <!-- Main Content - Comparison Section -->
    <main class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8 py-8">
        <h1 class="text-3xl md:text-4xl font-semibold mb-2">Compare Dyson technology</h1>
        <p class="text-gray-600 mb-8">Meet our hair dryer range and choose the right machine for you.</p>

        <div class="grid grid-cols-1 md:grid-cols-3 gap-6">
            <!-- Column Headers / Product Cards -->
            <div class="bg-white rounded-lg p-6 text-center card-shadow flex flex-col items-center">
                <img src="assets/supersonic_r.png" alt="Dyson Supersonic R Hair Dryer" class="w-32 h-auto mb-4">
                <h2 class="text-lg font-semibold mb-2">supersonic r</h2>
                <p class="text-sm text-gray-700 mb-4">Our most powerful, yet lightest hair dryer.</p>
            </div>

            <div class="bg-white rounded-lg p-6 text-center card-shadow flex flex-col items-center">
                <img src="assets/supersonic-nural.png" alt="Dyson Supersonic Nural Hair Dryer" class="w-32 h-auto mb-4">
                <h2 class="text-lg font-semibold mb-2">supersonic nural</h2>
                <p class="text-sm text-gray-700 mb-4">Fast, intelligent drying. Scalp health protection.</p>
            </div>

            <div class="bg-white rounded-lg p-6 text-center card-shadow flex flex-col items-center">
                <img src="assets/supersonic.png" alt="Dyson Supersonic Hair Dryer" class="w-32 h-auto mb-4">
                <h2 class="text-lg font-semibold mb-2">supersonic</h2>
                <p class="text-sm text-gray-700 mb-4">Fast drying with no extreme heat</p>
            </div>
        </div>

        <!-- Comparison Table Body -->
        <div class="mt-8 bg-white rounded-lg card-shadow overflow-hidden">
            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 bg-gray-50 text-sm font-medium text-gray-600">
                <div class="md:col-span-1">Engineered for</div>
                <div class="md:col-span-1 hidden md:block">Salon like results at home</div>
                <div class="md:col-span-1 hidden md:block">Scalp health and sensitive users</div>
                <div class="md:col-span-1 hidden md:block">Quick and fuss-free drying</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 text-sm">
                <div class="md:col-span-1 font-medium">Weight</div>
                <div class="md:col-span-1">325g</div>
                <div class="md:col-span-1">660g</div>
                <div class="md:col-span-1">660g</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 text-sm">
                <div class="md:col-span-1 font-medium">Streamlined flow heater</div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1">-</div>
                <div class="md:col-span-1">-</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 text-sm">
                <div class="md:col-span-1 font-medium">Ergonomically designed</div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1">-</div>
                <div class="md:col-span-1">-</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 text-sm">
                <div class="md:col-span-1 font-medium">Scalp protect mode</div>
                <div class="md:col-span-1">-</div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1">-</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 border-b border-gray-200 text-sm">
                <div class="md:col-span-1 font-medium">Attachment learning</div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1">-</div>
            </div>

            <div class="grid grid-cols-1 md:grid-cols-4 gap-x-6 py-4 px-6 text-sm">
                <div class="md:col-span-1 font-medium">Pause detect</div>
                <div class="md:col-span-1">-</div>
                <div class="md:col-span-1"><svg class="inline w-5 h-5 text-green-600" fill="none" stroke="currentColor" stroke-width="3" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" d="M5 13l4 4L19 7"/></svg></div>
                <div class="md:col-span-1">-</div>
            </div>
        </div>

        <!-- Shop Now Buttons -->
        <div class="grid grid-cols-1 md:grid-cols-3 gap-6 mt-8">
            <div class="flex justify-center">
                <button class="bg-green-600 hover:bg-green-700 text-white font-medium py-3 px-8 rounded-full transition duration-300 ease-in-out shadow-lg">Shop now</button>
            </div>
            <div class="flex justify-center">
                <button class="bg-green-600 hover:bg-green-700 text-white font-medium py-3 px-8 rounded-full transition duration-300 ease-in-out shadow-lg">Shop now</button>
            </div>
            <div class="flex justify-center">
                <button class="bg-green-600 hover:bg-green-700 text-white font-medium py-3 px-8 rounded-full transition duration-300 ease-in-out shadow-lg">Shop now</button>
            </div>
        </div>
    </main>

</body>
</html>
=== ./client/src/utils/utils.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export async function audioContext({ sampleRate }) {
  const context = new (window.AudioContext || window.webkitAudioContext)({ sampleRate });
  await context.resume();
  return context;
}

/**
 * Convert a base64 string to an ArrayBuffer
 * @param {string} base64 The base64 string to convert
 * @returns {ArrayBuffer} The converted ArrayBuffer
 */
export function base64ToArrayBuffer(base64) {
  const binaryString = atob(base64);
  const bytes = new Uint8Array(binaryString.length);
  for (let i = 0; i < binaryString.length; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes.buffer;
}=== ./client/src/audio/audio-recorder.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { audioContext } from "../utils/utils.js";
import { createWorkletFromSrc, registeredWorklets } from "./audioworklet-registry.js";
import AudioRecordingWorklet from "./audio-recording-worklet.js";

function arrayBufferToBase64(buffer) {
  var binary = "";
  var bytes = new Uint8Array(buffer);
  var len = bytes.byteLength;
  for (var i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return window.btoa(binary);
}

export class AudioRecorder extends EventEmitter3 {
  constructor() {
    super();
    this.sampleRate = 16000;
    this.stream = undefined;
    this.audioContext = undefined;
    this.source = undefined;
    this.recording = false;
    this.recordingWorklet = undefined;
    this.starting = null;
    this.isMuted = false;
  }

  async start() {
    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
      throw new Error("Could not request user media");
    }

    this.starting = new Promise(async (resolve, reject) => {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      this.audioContext = await audioContext({ sampleRate: this.sampleRate });
      this.source = this.audioContext.createMediaStreamSource(this.stream);

      const workletName = "audio-recorder-worklet";
      const workletSrc = AudioRecordingWorklet;

      if (!registeredWorklets.has(this.audioContext)) {
        registeredWorklets.set(this.audioContext, {});
      }

      const registry = registeredWorklets.get(this.audioContext);
      if (!registry[workletName]) {
        const src = createWorkletFromSrc(workletName, workletSrc);
        await this.audioContext.audioWorklet.addModule(src);
        registry[workletName] = {
          node: new AudioWorkletNode(this.audioContext, workletName),
          handlers: []
        };
      }

      this.recordingWorklet = registry[workletName].node;

      this.recordingWorklet.port.onmessage = async (ev) => {
        const arrayBuffer = ev.data.data.int16arrayBuffer;

        if (arrayBuffer) {
          const arrayBufferString = arrayBufferToBase64(arrayBuffer);
          this.emit("data", arrayBufferString);
        }
      };
      this.source.connect(this.recordingWorklet);

      this.recording = true;
      resolve();
      this.starting = null;
    });
  }

  stop() {
    const handleStop = () => {
      this.source?.disconnect();
      this.stream?.getTracks().forEach((track) => track.stop());
      this.stream = undefined;
      this.recordingWorklet = undefined;
    };
    if (this.starting) {
      this.starting.then(handleStop);
      return;
    }
    handleStop();
  }

  mute() {
    if (this.source && this.recordingWorklet && !this.isMuted) {
      this.source.disconnect(this.recordingWorklet);
      this.isMuted = true;
    }
  }

  unmute() {
    if (this.source && this.recordingWorklet && this.isMuted) {
      this.source.connect(this.recordingWorklet);
      this.isMuted = false;
    }
  }
}=== ./client/src/audio/audio-streamer.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export class AudioStreamer {
    constructor(audioContext) {
      this.context = audioContext;
      this.sampleRate = 24000; // Output sample rate as per API spec
      this.audioQueue = [];
      this.isPlaying = false;
      this.currentSource = null;
      this.gainNode = this.context.createGain();
      this.gainNode.connect(this.context.destination);
      this.addPCM16 = this.addPCM16.bind(this);
      this.onComplete = () => {};
      this.playbackTimeout = null;
      this.lastPlaybackTime = 0;
      this.bufferedTime = 0;
    }

    addPCM16(chunk) {
      // Convert incoming PCM16 data to float32
      const float32Array = new Float32Array(chunk.length / 2);
      const dataView = new DataView(chunk.buffer);

      for (let i = 0; i < chunk.length / 2; i++) {
        try {
          const int16 = dataView.getInt16(i * 2, true);
          float32Array[i] = int16 / 32768;
        } catch (e) {
          console.error(e);
        }
      }

      // Create and fill audio buffer
      const audioBuffer = this.context.createBuffer(1, float32Array.length, this.sampleRate);
      audioBuffer.getChannelData(0).set(float32Array);

      // Add to queue and start playing if needed
      this.audioQueue.push(audioBuffer);
      this.bufferedTime += audioBuffer.duration;
      
      // Start playing if not already playing AND we have at least 200ms of audio
      if (!this.isPlaying && this.bufferedTime >= 0.5) {
        this.isPlaying = true;
        this.lastPlaybackTime = this.context.currentTime;
        this.playNextBuffer();
      }

      // Ensure playback continues if it was interrupted
      this.checkPlaybackStatus();
    }

    checkPlaybackStatus() {
      // Clear any existing timeout
      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
      }

      // Set a new timeout to check playback status
      this.playbackTimeout = setTimeout(() => {
        const now = this.context.currentTime;
        const timeSinceLastPlayback = now - this.lastPlaybackTime;

        // If more than 1 second has passed since last playback and we have buffers to play
        if (timeSinceLastPlayback > 1 && this.audioQueue.length > 0 && this.isPlaying) {
          console.log('Playback appears to have stalled, restarting...');
          this.playNextBuffer();
        }

        // Continue checking if we're still playing
        if (this.isPlaying) {
          this.checkPlaybackStatus();
        }
      }, 1000);
    }

    playNextBuffer() {
      if (this.audioQueue.length === 0) {
        this.isPlaying = false;
        this.bufferedTime = 0; // reset buffered time
        return;
      }

      // Update last playback time
      this.lastPlaybackTime = this.context.currentTime;

      try {
        const audioBuffer = this.audioQueue.shift();
        const source = this.context.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(this.gainNode);

        // critical! subtract the played buffer's duration
        this.bufferedTime -= audioBuffer.duration;

        // Store current source for potential stopping
        if (this.currentSource) {
          try {
            this.currentSource.disconnect();
          } catch (e) {
            // Ignore disconnection errors
          }
        }
        this.currentSource = source;

        // When this buffer ends, play the next one
        source.onended = () => {
          this.lastPlaybackTime = this.context.currentTime;
          if (this.audioQueue.length > 0) {
            // Small delay to ensure smooth transition
            setTimeout(() => this.playNextBuffer(), 0);
          } else {
            this.isPlaying = false;
            this.bufferedTime = 0; // reset buffered time
            this.onComplete();
          }
        };

        // Start playing immediately
        source.start(0);
      } catch (error) {
        console.error('Error during playback:', error);
        // Try to recover by playing next buffer
        if (this.audioQueue.length > 0) {
          setTimeout(() => this.playNextBuffer(), 100);
        } else {
          this.isPlaying = false;
          this.bufferedTime = 0;
        }
      }
    }

    stop() {
      this.isPlaying = false;
      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
        this.playbackTimeout = null;
      }
      if (this.currentSource) {
        try {
          this.currentSource.stop();
          this.currentSource.disconnect();
        } catch (e) {
          // Ignore if already stopped
        }
      }
      this.audioQueue = [];
      this.bufferedTime = 0; // reset buffered time
      this.gainNode.gain.linearRampToValueAtTime(0, this.context.currentTime + 0.1);

      setTimeout(() => {
        this.gainNode.disconnect();
        this.gainNode = this.context.createGain();
        this.gainNode.connect(this.context.destination);
      }, 200);
    }

    async resume() {
      if (this.context.state === 'suspended') {
        await this.context.resume();
      }
      this.lastPlaybackTime = this.context.currentTime;
      this.gainNode.gain.setValueAtTime(1, this.context.currentTime);
      if (this.audioQueue.length > 0 && !this.isPlaying) {
        this.isPlaying = true;
        this.playNextBuffer();
      }
    }

    complete() {
      // check if we have enough audio buffered to continue playing.
      if (this.bufferedTime >= 0.2) {
        return; // don't complete, we have enough buffered.
      }

      if (this.playbackTimeout) {
        clearTimeout(this.playbackTimeout);
        this.playbackTimeout = null;
      }
      this.onComplete();
    }
  }=== ./client/src/audio/audioworklet-registry.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * A registry to map attached worklets by their audio-context
 * any module using `audioContext.audioWorklet.addModule(` should register the worklet here
 */
export const registeredWorklets = new Map();

export function createWorkletFromSrc(name, workletSrc) {
  const blob = new Blob(
    [`${workletSrc}`],
    { type: 'application/javascript' }
  );
  return URL.createObjectURL(blob);
}=== ./client/src/audio/audio-recording-worklet.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

const workletCode = `
class AudioProcessingWorklet extends AudioWorkletProcessor {
  // send and clear buffer every 2048 samples, 
  // which at 16khz is about 8 times a second
  buffer = new Int16Array(2048);

  // current write index
  bufferWriteIndex = 0;

  constructor() {
    super();
  }

  process(inputs) {
    if (inputs[0].length) {
      const channel0 = inputs[0][0];
      this.processChunk(channel0);
    }
    return true;
  }

  sendAndClearBuffer() {
    this.port.postMessage({
      event: "chunk",
      data: {
        int16arrayBuffer: this.buffer.slice(0, this.bufferWriteIndex).buffer,
      },
    });
    this.bufferWriteIndex = 0;
  }

  processChunk(float32Array) {
    const l = float32Array.length;
    
    for (let i = 0; i < l; i++) {
      // convert float32 -1 to 1 to int16 -32768 to 32767
      const int16Value = float32Array[i] * 32768;
      this.buffer[this.bufferWriteIndex++] = int16Value;
      if(this.bufferWriteIndex >= this.buffer.length) {
        this.sendAndClearBuffer();
      }
    }

    if(this.bufferWriteIndex >= this.buffer.length) {
      this.sendAndClearBuffer();
    }
  }
}

registerProcessor('audio-recorder-worklet', AudioProcessingWorklet);
`;

export default workletCode;=== ./client/src/api/gemini-api.js ===
export class GeminiAPI {
    constructor(endpoint = null) {
        // If no endpoint is provided, try to construct it from the current URL
        if (!endpoint) {
            // Use the backend URL directly
            //endpoint = 'wss://live-agent-backend-xxx-uc.a.run.app'; // remote endpoint example
            endpoint = 'ws://localhost:8081';
        }
        
        this.endpoint = endpoint;
        this.ws = null;
        this.isSpeaking = false;
        this.connect();
    }

    connect() {
        console.log('Initializing GeminiAPI with endpoint:', this.endpoint);
        this.ws = new WebSocket(this.endpoint);
        this.onReady = () => {};
        this.onConfig = () => {};
        this.onAudioData = () => {};
        this.onTextContent = () => {};
        this.onError = () => {};
        this.onClose = () => {}; // <-- ADD OR ENSURE THIS LINE EXISTS
        this.onTurnComplete = () => {};
        this.onFunctionCall = (data) => {
            console.log('Function Call:', data);
            this.logMessage({type: 'tool_call', data: data});
        };
        this.onFunctionResponse = (data) => {
            console.log('Function Response:', data);
            this.logMessage({type: 'tool_result', data: data});
        };
        this.onInterrupted = () => {};  // New callback for interruption events
        
        this.setupWebSocket();
        this.logMessage = () => {};
    }

    setupWebSocket() {
        this.ws.onopen = () => {
            console.log('WebSocket connection is opening...');
            this.onReady();
        };

        this.ws.onmessage = async (event) => {
            try {
                let response;
                if (event.data instanceof Blob) {
                    console.log('Received blob data, converting to text...');
                    const responseText = await event.data.text();
                    response = JSON.parse(responseText);
                } else {
                    response = JSON.parse(event.data);
                }
                
                console.log('WebSocket Response:', response);

                if (response.type === 'error') {
                    console.error('Server error:', response.data);
                    this.onError(response.data);
                    return;
                }

                if (response.type === 'config') {
                    console.log('Received config from server:', response.data);
                    this.clientConfig = response.data;
                    this.onConfig(response.data);
                    return;
                }

                if (response.ready) {
                    console.log('Received ready signal from server');
                    this.onReady();
                    return;
                }

                if (response.type === 'interrupted') {
                    console.log('Response interrupted:', response.data);
                    this.isSpeaking = false;
                    this.onInterrupted(response.data);
                } else if (response.type === 'audio') {
                    console.log('Received audio data');
                    this.onAudioData(response.data);
                } else if (response.type === 'text') {
                    console.log('Received text content:', response.data);
                    this.onTextContent(response.data);
                } else if (response.type === 'turn_complete') {
                    console.log('Turn complete');
                    this.onTurnComplete();
                } else if (response.type === 'tool_call') {
                    console.log('Received function call:', response.data);
                    this.onFunctionCall(response.data);
                } else if (response.type === 'tool_result') {
                    console.log('Received function response:', response.data);
                    this.onFunctionResponse(response.data);
                } else {
                    console.log('Received unknown message type:', response);
                }
            } catch (error) {
                console.error('Error parsing response:', error);
                console.error('Raw response data:', event.data);
                this.onError({
                    message: 'Error parsing response: ' + error.message,
                    error_type: 'client_error'
                });
            }
        };

        this.ws.onerror = (error) => {
            console.error('WebSocket Error:', error);
            this.onError({
                message: 'Connection error occurred',
                action: 'Please check your internet connection and try again',
                error_type: 'websocket_error'
            });
        };

        this.ws.onclose = (event) => {
            console.log('WebSocket connection closed:', {
                code: event.code,
                reason: event.reason,
                wasClean: event.wasClean
            });
            this.onClose(); // <-- ENSURE THIS CALL IS MADE
            
            // Only show error if it wasn't a clean close
            if (!event.wasClean) {
                this.onError({
                    message: 'Connection was interrupted',
                    action: 'Please refresh the page to reconnect',
                    error_type: 'connection_closed'
                });
            }
        };
    }

    sendAudioChunk(base64Audio) {
        console.log('Sending audio chunk...');
        this.sendMessage({
            type: 'audio',
            data: base64Audio
        });
    }

    sendImage(base64Image) {
        console.log('Sending image data...');
        this.sendMessage({
            type: 'image',
            data: base64Image
        });
    }

    sendEndMessage() {
        console.log('Sending end message');
        this.sendMessage({
            type: 'end'
        });
    }

    sendTextMessage(text) {
        console.log('Sending text message');
        this.sendMessage({
            type: 'text',
            data: text
        });
    }

    sendMessage(message) {
        if (this.ws.readyState === WebSocket.OPEN) {
            console.log('Sending message:', {
                type: message.type,
                dataLength: message.data ? message.data.length : 0
            });
            this.ws.send(JSON.stringify(message));
        } else {
            const states = {
                0: 'CONNECTING',
                1: 'OPEN',
                2: 'CLOSING',
                3: 'CLOSED'
            };
            console.error('WebSocket is not open. Current state:', states[this.ws.readyState]);
            this.onError(`WebSocket is not ready (State: ${states[this.ws.readyState]}). Please try again.`);
        }
    }

    sendEndSessionMessage() {
        console.log('Sending end_session message');
        this.sendMessage({
            type: 'end_session'
        });
    }

    async ensureConnected() {
        console.log('Ensuring WebSocket connection...');
        if (this.ws.readyState === WebSocket.OPEN) {
            console.log('WebSocket already connected');
            return;
        }

        return new Promise((resolve, reject) => {
            const timeout = setTimeout(() => {
                console.error('Connection timeout after 5000ms');
                reject(new Error('Connection timeout'));
            }, 5000);

            const onOpen = () => {
                console.log('WebSocket connection established');
                clearTimeout(timeout);
                this.ws.removeEventListener('open', onOpen);
                this.ws.removeEventListener('error', onError);
                resolve();
            };

            const onError = (error) => {
                console.error('WebSocket connection failed:', error);
                clearTimeout(timeout);
                this.ws.removeEventListener('open', onOpen);
                this.ws.removeEventListener('error', onError);
                reject(error);
            };

            this.ws.addEventListener('open', onOpen);
            this.ws.addEventListener('error', onError);
        });
    }
}=== ./client/src/media/media-handler.js ===
/**
 * Copyright 2024 Google LLC
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

export class MediaHandler {
  constructor() {
    this.videoElement = null;
    this.currentStream = null;
    this.isWebcamActive = false;
    this.isScreenActive = false;
    this.frameCapture = null;
    this.frameCallback = null;
    this.usingFrontCamera = true;
  }

  initialize(videoElement) {
    this.videoElement = videoElement;
  }

  async startWebcam(useFrontCamera = true) {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: 1280, 
          height: 720,
          facingMode: useFrontCamera ? "user" : "environment"
        } 
      });
      this.handleNewStream(stream);
      this.isWebcamActive = true;
      this.usingFrontCamera = useFrontCamera;
      return true;
    } catch (error) {
      console.error('Error accessing webcam:', error);
      return false;
    }
  }

  async startScreenShare() {
    try {
      const stream = await navigator.mediaDevices.getDisplayMedia({ 
        video: true 
      });
      this.handleNewStream(stream);
      this.isScreenActive = true;
      
      // Handle when user stops sharing via browser controls
      stream.getVideoTracks()[0].addEventListener('ended', () => {
        this.stopAll();
      });
      
      return true;
    } catch (error) {
      console.error('Error sharing screen:', error);
      return false;
    }
  }

  async switchCamera() {
    if (!this.isWebcamActive) return false;
    const newFacingMode = !this.usingFrontCamera;
    await this.stopAll();
    const success = await this.startWebcam(newFacingMode);
    if (success && this.frameCallback) {
      this.startFrameCapture(this.frameCallback);
    }
    return success;
  }

  handleNewStream(stream) {
    if (this.currentStream) {
      this.stopAll();
    }
    this.currentStream = stream;
    if (this.videoElement) {
      this.videoElement.srcObject = stream;
      this.videoElement.classList.remove('hidden');
    }
  }

  stopAll() {
    if (this.currentStream) {
      this.currentStream.getTracks().forEach(track => track.stop());
      this.currentStream = null;
    }
    if (this.videoElement) {
      this.videoElement.srcObject = null;
      this.videoElement.classList.add('hidden');
    }
    this.isWebcamActive = false;
    this.isScreenActive = false;
    this.stopFrameCapture();
  }

  startFrameCapture(onFrame) {
    this.frameCallback = onFrame;
    const captureFrame = () => {
      if (!this.currentStream || !this.videoElement) return;
      
      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d');
      canvas.width = this.videoElement.videoWidth;
      canvas.height = this.videoElement.videoHeight;
      
      context.drawImage(this.videoElement, 0, 0, canvas.width, canvas.height);
      
      // Convert to JPEG and base64 encode
      const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
      this.frameCallback(base64Image);
    };

    // Capture frames at 1fps
    this.frameCapture = setInterval(captureFrame, 1000);
  }

  stopFrameCapture() {
    if (this.frameCapture) {
      clearInterval(this.frameCapture);
      this.frameCapture = null;
    }
  }
} === ./client/index_dyson.html ===
<!DOCTYPE html>
<html>
<head>
  <title>Next-Gen Agent Demo</title>
  <link rel="stylesheet" href="styles/style.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <script src="https://cdn.tailwindcss.com"></script>
  
  <!-- Favicon -->
  <link rel="icon" type="image/x-icon" href="assets/favicon.ico">
</head>
<body style="margin:0;padding:0;">
  <div style="display:flex;flex-direction:row;height:100vh;width:100vw;overflow:hidden;">
    <!-- Left: Agent UI (30%) -->
    <div id="agent-ui" style="width:30vw;min-width:320px;max-width:600px;height:100vh;overflow-y:auto;background:#fff;box-shadow:2px 0 8px rgba(0,0,0,0.04);z-index:2;">
      <div class="header-section">
        <h1><strong>Next-Gen Agent Prototype</strong></h1>
        <p style="font-size: 1.0;">Speak into your microphone and optionally share your webcam or screen to engage in a multimedia conversation.</p>
      </div>
      <div class="input-container">
        <button id="micButton" disabled class="action-button">
          <span class="material-symbols-outlined">mic</span>
        </button>
        <button id="webcamButton" class="action-button">
          <span class="material-symbols-outlined">videocam</span>
        </button>
        <button id="screenButton" class="action-button">
          <span class="material-symbols-outlined">present_to_all</span>
        </button>
        <button id="imageButton" class="action-button">
          <span class="material-symbols-outlined">image</span>
        </button>
        <input type="file" id="imageInput" accept="image/*" style="display: none;">
        <div class="text-input-container">
          <input type="text" id="textInput" placeholder="Type your message..." class="text-input">
          <button id="sendButton" class="action-button">
            <span class="material-symbols-outlined">send</span>
          </button>
          <button id="interruptButton" class="action-button" style="display: none;">
            <span class="material-symbols-outlined">cancel</span>
          </button>
          <button id="endSessionButton" class="action-button" title="End Session">
            <span class="material-symbols-outlined">stop_circle</span>
          </button>
        </div>
      </div>
      <div class="video-container">
        <video id="videoPreview" autoplay playsinline class="hidden"></video>
      </div>
      <div id="imagePreviewContainer" style="display: none;">
        <img id="imagePreview" src="" alt="Image Preview" style="max-width: 100%; max-height: 200px;">
      </div>
      <div id="output"></div>
    </div>
    <!-- Right: Dyson Homepage (70%) -->
    <div id="dyson-home" style="flex:1;height:100vh;overflow:auto;z-index:1;">
      <!-- Dyson content will be loaded here -->
    </div>
  </div>
  <!-- Load EventEmitter3 first -->
  <script src="https://cdn.jsdelivr.net/npm/eventemitter3@5.0.1/dist/eventemitter3.umd.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/dompurify/dist/purify.min.js"></script>

  <script type="module">
    import { AudioRecorder } from './src/audio/audio-recorder.js';
    import { AudioStreamer } from './src/audio/audio-streamer.js';
    import { MediaHandler } from './src/media/media-handler.js';
    import { GeminiAPI } from './src/api/gemini-api.js';
    import { base64ToArrayBuffer } from './src/utils/utils.js';

    // Initialize components
    const output = document.getElementById('output');
    const audioRecorder = new AudioRecorder();
    const audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 24000 });
    const audioStreamer = new AudioStreamer(audioContext);
    const mediaHandler = new MediaHandler();
    const api = new GeminiAPI('ws://localhost:8080/ws');

    let isRecording = false;
    let hasShownSpeakingMessage = false;
    let currentTurn = 0;
    let lastAudioTurn = -1;

    // Initialize media handler
    mediaHandler.initialize(document.getElementById('videoPreview'));

    // Set up API handlers
    api.onReady = () => {
      document.getElementById('micButton').disabled = false;
      // Add these lines to enable other controls:
      document.getElementById('webcamButton').disabled = false;
      document.getElementById('screenButton').disabled = false;
      document.getElementById('imageButton').disabled = false;
      document.getElementById('sendButton').disabled = false;
      document.getElementById('textInput').disabled = false;
      document.getElementById('endSessionButton').disabled = false; // Enable end button
      logMessage("System: Connected to server.");
    };

    api.onConfig = (configData) => {
      if (configData.use_tts) {
        logMessage(`System: Using Cloud TTS Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      } else {
        logMessage(`System: Using Live API Voice: ${configData.voice}, Lang: ${configData.model_language}, Prompt: ${configData.prompt_language}`);
      }
      
    };

    api.onClose = () => {
        logMessage("System: Disconnected from server.");
        // Disable controls on disconnect
        document.getElementById('micButton').disabled = true;
        document.getElementById('webcamButton').disabled = true;
        document.getElementById('screenButton').disabled = true;
        document.getElementById('imageButton').disabled = true;
        document.getElementById('sendButton').disabled = true;
        document.getElementById('textInput').disabled = true;
        document.getElementById('endSessionButton').disabled = true;
        document.getElementById('interruptButton').style.display = 'none';
        if (isRecording) {
            stopRecording(false); // Ensure recording stops if connection drops
        }
        mediaHandler.stopAll(); // Stop media streams
    };


    api.onAudioData = async (audioData) => {
      try {
        if (!api.isSpeaking || lastAudioTurn !== currentTurn) {
          logMessage('Gemini: Speaking...');
          api.isSpeaking = true;
          lastAudioTurn = currentTurn;
          document.getElementById('interruptButton').style.display = 'inline-block';
        }
        const arrayBuffer = base64ToArrayBuffer(audioData);
        audioStreamer.addPCM16(new Uint8Array(arrayBuffer));
        audioStreamer.resume();
      } catch (error) {
        console.error('Error playing audio:', error);
      }
    };

    api.onTextContent = (text) => {
      if (text.trim()) {
        logMessage('Gemini: ' + text);
      }
    };

    api.onTurnComplete = () => {
      logMessage('Gemini: Finished speaking');
      api.isSpeaking = false;  // Reset speaking state
      audioStreamer.complete();
      document.getElementById('interruptButton').style.display = 'none';
    };

    // Add interruption handler
    api.onInterrupted = (data) => {
      logMessage('Gemini: Response interrupted');
      api.isSpeaking = false;
      audioStreamer.stop();  // Stop current playback and clear queue
      document.getElementById('interruptButton').style.display = 'none';
      
      // Show visual feedback for interruption
      const messageElement = document.createElement('p');
      messageElement.className = 'interrupted-message';
      messageElement.textContent = 'Response interrupted by user input';
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    };

    // Add function call and response handlers
    api.onFunctionCall = (data) => {
      logMessage('Function: ' + data.name);
      logMessage('Parameters: ' + JSON.stringify(data.args, null, 2));
      if (data.name === 'show_hair_dryer_models') {
        fetch('dyson_supersonic.html')
          .then(response => response.text())
          .then(html => {
            const parser = new DOMParser();
            const doc = parser.parseFromString(html, 'text/html');
            const dysonBody = doc.body.innerHTML;
            document.getElementById('dyson-home').innerHTML = dysonBody;
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson Supersonic content.</p>';
            console.error('Error loading Dyson Supersonic content:', err);
          });
      }
    };

    api.onFunctionResponse = (data) => {
      logMessage('API Response: ' + JSON.stringify(data, null, 2));
      // Check for appointment_id and show appointment.html if present
      if (data && data.appointment_id) {
        fetch('dyson_appointment.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            // Wait for DOM to update, then set the values
            setTimeout(() => {
              if (document.getElementById('appointmentId')) {
                document.getElementById('appointmentId').textContent = data.appointment_id;
              }
              if (document.getElementById('appointmentSlot')) {
                document.getElementById('appointmentSlot').textContent = data.scheduled_slot;
              }
            }, 0);
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Appointment content.</p>';
            console.error('Error loading Appointment content:', err);
          });
      } else if (data && data.video_url && data.video_url.includes('youtube.com')) {
        fetch('video.html')
          .then(response => response.text())
          .then(html => {
            document.getElementById('dyson-home').innerHTML = html;
            
            const videoUrl = new URL(data.video_url);
            const videoId = videoUrl.searchParams.get('v');

            if (videoId) {
              const embedUrl = `https://www.youtube.com/embed/${videoId}?autoplay=1&mute=1`; // Add autoplay and mute
              // Wait for DOM to update, then set the src
              setTimeout(() => {
                const iframe = document.getElementById('youtube-video');
                if (iframe) {
                  iframe.src = embedUrl;
                }
              }, 0);
            } else {
              console.error('Could not extract YouTube video ID from URL:', data.video_url);
              document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to get video ID from URL.</p>';
            }
          })
          .catch(err => {
            document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load video player.</p>';
            console.error('Error loading video.html:', err);
          });
      }
    };

    api.onMessage = (message) => {
      if (typeof message === 'object' && message !== null) {
        logMessage(message);
      }
    };
    api.onError = (error) => { // Copied for completeness
        console.error("API Error:", error);
        logMessage(`System Error: ${error.message || JSON.stringify(error)}`);
    };


    // UI Event Handlers
    async function startRecording() {
      try {
        // If model is speaking, treat this as an interruption
        if (api.isSpeaking) {
          audioStreamer.stop();
          api.isSpeaking = false;
        }

        await audioContext.resume();
        await audioRecorder.start();
        hasShownSpeakingMessage = false;
        currentTurn++;
        
        audioRecorder.on('data', (base64Data) => {
          if (!hasShownSpeakingMessage) {
            logMessage('You: Speaking...');
            hasShownSpeakingMessage = true;
          }
          api.sendAudioChunk(base64Data);
        });

        isRecording = true;
        document.getElementById('micButton').innerHTML = 
          '<span class="material-symbols-outlined">stop</span>';
      } catch (error) {
        console.error('Error starting recording:', error);
        logMessage('Error: ' + error.message);
      }
    }

    function stopRecording(sendEndMsg = true) {
      if (!isRecording) return;
      audioRecorder.stop();
      isRecording = false;
      hasShownSpeakingMessage = false;
      document.getElementById('micButton').innerHTML =
        '<span class="material-symbols-outlined">mic</span>';
      logMessage('You: Recording stopped.');
      // Conditionally send the 'end' message
      if (sendEndMsg) { // Check sessionActive too
        api.sendEndMessage(); // Signal end of user turn
      }
      api.isSpeaking = false; // Ensure speaking flag is reset
      }

    function logMessage(message) {
      const messageElement = document.createElement('div');
      let handled = false;
      
      // Add specific styling based on message content
      if (typeof message === 'string'){
        if (message.startsWith('Function:')) {
          messageElement.className = 'function-name';
        } else if (message.startsWith('Parameters:')) {
          messageElement.className = 'function-params';
        } else if (message.startsWith('API Response:')) {
          messageElement.className = 'api-response';
        } else if (message.startsWith('Gemini:')) {
          messageElement.className = 'gemini-message';
        } else if (message.startsWith('You:')) {
          messageElement.className = 'user-message';
        }
        messageElement.textContent = message;
        handled = true;
      }

      else if (typeof message == 'object' && message !== null) {
        if (message.type === 'tool_call') {
          messageElement.className = 'function-name';
          messageElement.textContent = `Function: ${message.data.name}`;

          const paramsElement = document.createElement('p');
          paramsElement.className = 'function-params';
          paramsElement.textContent = `Parameters: ${JSON.stringify(message.data.args, null, 2)}`;
          output.appendChild(messageElement);
          output.appendChild(paramsElement);
          handled = true;
        }
        else if (message.type === 'tool_result') {
          messageElement.className = 'api-response';
          if (message.data.markdown) {
            const cleanHTML = DOMPurify.sanitize(marked.parse(message.data.markdown));
            messageElement.innerHTML = cleanHTML;
          }
          else {
            messageElement.textContent = `API Response: ${JSON.stringify(message.data, null, 2)}`;
          }

          output.appendChild(messageElement)
          handled = true;
        }
      }

      // handling for markdown and images
      else if (message.type == 'markdown') {
        messageElement.className = 'gemini-message';
        const cleanHTML = DOMPurify.sanitize(marked.parse(message.data));
        messageElement.innerHTML = cleanHTML;
        handled = true;
      }

      else if (message.type === 'image') {
        messageElement.className = 'gemini-message';
        const img = document.createElement('img');
        img.src = message.data
        img.alt = 'Image from Gemini';
        img.style.maxWidth = '100%';
        messageElement.appendChild(img);
        handled = true;
      }

      else if (message.type === 'text') {
        messageElement.className = 'gemini-message';
        messageElement.textContent = message.data;
        handled = true;
      }

      if (!handled) {
        messageElement.textContent = JSON.stringify(message);
      }
      
      // messageElement.textContent = message;
      output.appendChild(messageElement);
      output.scrollTop = output.scrollHeight;
    }

    api.logMessage = logMessage;

    // Add function to send text message
    function sendTextMessage() {
      const textInput = document.getElementById('textInput');
      const text = textInput.value.trim();
      if (!text) return;

      // Clear input
      textInput.value = '';

      // Log user message
      logMessage('You: ' + text);

      // Send text message
      api.sendTextMessage(text);
    }

    // Set up button click handlers
    document.getElementById('micButton').onclick = () => {
      if (isRecording) {
        stopRecording();
      } else {
        startRecording();
      }
    };

    // Add send button handler
    document.getElementById('sendButton').onclick = sendTextMessage;

    // Add keypress handler for text input
    document.getElementById('textInput').addEventListener('keypress', function(e) {
      if (e.key === 'Enter') {
        sendTextMessage();
      }
    });

    document.getElementById('webcamButton').onclick = async () => {
      if (mediaHandler.isWebcamActive) {
        mediaHandler.stopAll();
        document.getElementById('webcamButton').innerHTML = 
          '<span class="material-symbols-outlined">videocam</span>';
      } else {
        const success = await mediaHandler.startWebcam();
        if (success) {
          document.getElementById('webcamButton').innerHTML = 
            '<span class="material-symbols-outlined">videocam_off</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    document.getElementById('screenButton').onclick = async () => {
      if (mediaHandler.isScreenActive) {
        mediaHandler.stopAll();
        document.getElementById('screenButton').innerHTML = 
          '<span class="material-symbols-outlined">present_to_all</span>';
      } else {
        const success = await mediaHandler.startScreenShare();
        if (success) {
          document.getElementById('screenButton').innerHTML = 
            '<span class="material-symbols-outlined">cancel_presentation</span>';
          mediaHandler.startFrameCapture((base64Image) => {
            api.sendImage(base64Image);
          });
        }
      }
    };

    // Image Upload Handler
    document.getElementById('imageButton').onclick = () => {
        document.getElementById('imageInput').click(); // Trigger file input
    };

    document.getElementById('imageInput').onchange = (event) => {
        const file = event.target.files[0];
        if (file) {
            const reader = new FileReader();
            reader.onload = (e) => {
                const base64Image = e.target.result.split(',')[1]; // Remove data URL prefix

                // Display image preview (optional)
                const imagePreview = document.getElementById('imagePreview');
                imagePreview.src = e.target.result;
                document.getElementById('imagePreviewContainer').style.display = 'block';

                api.sendImage(base64Image);
                logMessage('You: Sent an image.');
            };
            reader.readAsDataURL(file);
        }
    };

    // === ADD END SESSION BUTTON HANDLER ===
    document.getElementById('endSessionButton').onclick = () => {
      logMessage("System: Requesting to end session...");
      api.sendEndSessionMessage(); // Call the new API method (needs to be added in gemini-api.js)

      // Disable controls immediately for better UX
      document.getElementById('micButton').disabled = true;
      document.getElementById('webcamButton').disabled = true;
      document.getElementById('screenButton').disabled = true;
      document.getElementById('imageButton').disabled = true;
      document.getElementById('sendButton').disabled = true;
      document.getElementById('textInput').disabled = true;
      document.getElementById('endSessionButton').disabled = true;
      document.getElementById('interruptButton').style.display = 'none';

      if (isRecording) {
          stopRecording(false); // Stop recording without sending 'end' message
      }
      mediaHandler.stopAll(); // Stop media streams
      // The actual disconnect and UI update will happen via api.onClose
    };

    // Add CSS for interrupted message
    const style = document.createElement('style');
    style.textContent = `
      .interrupted-message {
        color: #ff6b6b;
        font-style: italic;
        margin: 4px 0;
        padding: 4px 8px;
        border-left: 3px solid #ff6b6b;
        background-color: rgba(255, 107, 107, 0.1);
      }
    `;
    document.head.appendChild(style);
  </script>
  <script>
    fetch('dyson_home.html')
      .then(response => response.text())
      .then(html => {
        const parser = new DOMParser();
        const doc = parser.parseFromString(html, 'text/html');
        const dysonBody = doc.body.innerHTML;
        document.getElementById('dyson-home').innerHTML = dysonBody;
      })
      .catch(err => {
        document.getElementById('dyson-home').innerHTML = '<p style="color:red;">Failed to load Dyson content.</p>';
        console.error('Error loading Dyson content:', err);
      });
  </script>
</body>
</html>